{"cells":[{"cell_type":"markdown","metadata":{"id":"NEnBiuLcukJc"},"source":["<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## RNN one-to-many"]},{"cell_type":"markdown","metadata":{"id":"i96B2RF8uqEb"},"source":["#### Datos\n","El objecto es utilizar una serie de sucuencias númericas (datos sintéticos) para poner a prueba el uso de las redes RNN. Este ejemplo se inspiró en otro artículo, lo tienen como referencia en el siguiente link:\\\n","[LINK](https://stackabuse.com/solving-sequence-problems-with-lstm-in-keras/)"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4629,"status":"ok","timestamp":1656680068284,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"Lx0HQ-1RvJw9"},"outputs":[],"source":["import re\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9954,"status":"ok","timestamp":1656680078222,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"7yONnycbZ9kZ","outputId":"390eecd7-f5de-45cd-eec9-b5dd57a73952"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchinfo in d:\\users\\juanp_schamun\\documents\\gitrepositories\\ceia\\procesamiento_lenguaje_natural\\.venv\\lib\\site-packages (1.8.0)\n"]}],"source":["# torchsummar actualmente tiene un problema con las LSTM, por eso\n","# se utiliza torchinfo, un fork del proyecto original con el bug solucionado\n","!pip3 install torchinfo\n","from torchinfo import summary"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":578,"status":"ok","timestamp":1656680078783,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"XKC5SmeuTFPv","outputId":"984a5fbc-368a-4198-d777-81572ad9b0ad"},"outputs":[],"source":["import os\n","import platform\n","\n","if os.access('torch_helpers.py', os.F_OK) is False:\n","    if platform.system() == 'Windows':\n","        !curl !wget https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py > torch_helpers.py\n","    else:\n","        !wget torch_helpers.py https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1656680078784,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"YMFLzZx7cJET"},"outputs":[],"source":["def train(model, train_loader, valid_loader, optimizer, criterion, epochs=100):\n","    # Defino listas para realizar graficas de los resultados\n","    train_loss = []\n","    valid_loss = []\n","\n","    # Defino mi loop de entrenamiento\n","\n","    for epoch in range(epochs):\n","\n","        epoch_train_loss = 0.0\n","        epoch_train_accuracy = 0.0\n","\n","        for train_data, train_target in train_loader:\n","\n","            # Seteo los gradientes en cero ya que, por defecto, PyTorch\n","            # los va acumulando\n","            optimizer.zero_grad()\n","\n","            output = model(train_data)\n","\n","            # Computo el error de la salida comparando contra las etiquetas\n","            loss = criterion(output, train_target)\n","\n","            # Almaceno el error del batch para luego tener el error promedio de la epoca\n","            epoch_train_loss += loss.item()\n","\n","            # Computo el nuevo set de gradientes a lo largo de toda la red\n","            loss.backward()\n","\n","            # Realizo el paso de optimizacion actualizando los parametros de toda la red\n","            optimizer.step()\n","\n","        # Calculo la media de error para la epoca de entrenamiento.\n","        # La longitud de train_loader es igual a la cantidad de batches dentro de una epoca.\n","        epoch_train_loss = epoch_train_loss / len(train_loader)\n","        train_loss.append(epoch_train_loss)\n","\n","        # Realizo el paso de validación computando error y accuracy, y\n","        # almacenando los valores para imprimirlos y graficarlos\n","        valid_data, valid_target = next(iter(valid_loader))\n","        output = model(valid_data)\n","        \n","        epoch_valid_loss = criterion(output, valid_target).item()\n","        valid_loss.append(epoch_valid_loss)\n","\n","        print(f\"Epoch: {epoch+1}/{epochs} - Train loss {epoch_train_loss:.3f} - Valid Loss {epoch_valid_loss:.3f}\")\n","\n","    history = {\n","        \"loss\": train_loss,\n","        \"val_loss\": valid_loss,\n","    }\n","    return history"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1656680078784,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"10bFkG1YuaD9","outputId":"130608fc-0138-4d4d-fa7d-0757d94e27c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["datos X: [1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 40, 43]\n","datos y: [[2, 3], [5, 6], [8, 9], [11, 12], [14, 15], [17, 18], [20, 21], [23, 24], [26, 27], [29, 30], [32, 33], [35, 36], [38, 39], [41, 42], [44, 45]]\n"]}],"source":["# Generar datos sintéticos\n","X = list()\n","y = list()\n","\n","# X es una lista de números de 1 al 43 que avanzan de 3 en 3\n","X = [x for x in range(1, 44, 3)]\n","\n","# \"y\" (target) se obtiene como por cada dato de entrada se\n","# se obtienen dos datos de salida como x+1 y x+2\n","y = [ [x+1, x+2] for x in X]\n","\n","print(\"datos X:\", X)\n","print(\"datos y:\", y)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1656680078785,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"Oqabd-kYvza9","outputId":"6382c72b-0068-4d3d-ac3a-69a5466ab6fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["datos X: [[[ 1]]\n","\n"," [[ 4]]\n","\n"," [[ 7]]\n","\n"," [[10]]\n","\n"," [[13]]\n","\n"," [[16]]\n","\n"," [[19]]\n","\n"," [[22]]\n","\n"," [[25]]\n","\n"," [[28]]\n","\n"," [[31]]\n","\n"," [[34]]\n","\n"," [[37]]\n","\n"," [[40]]\n","\n"," [[43]]]\n"]}],"source":["# Cada dato X lo transformarmos en una matriz de 1 fila 1 columna (1x1)\n","X = np.array(X).reshape(len(X), 1, 1)\n","print(\"datos X:\", X)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1656680078785,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"PytzYIMsUS1T","outputId":"72dc2cd3-072f-4109-c84d-9ad9848a0c24"},"outputs":[{"data":{"text/plain":["(15, 1, 1)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# (batch size, seq_len, input_size)\n","X.shape"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1656680078786,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"gYz6XpuyxBbQ","outputId":"0fe154a3-981e-4b58-941d-4dd07c0e7957"},"outputs":[{"data":{"text/plain":["(15, 2)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["y = np.asanyarray(y)\n","y.shape"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":521,"status":"ok","timestamp":1656680115352,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"QnrjCgx9TtOU","outputId":"d192bdac-5c90-4ee3-fff1-4c8ab265952c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input dim torch.Size([1, 1])\n","seq_length: 1\n","input_size: 1\n","Output dim 2\n"]}],"source":["class Data(Dataset):\n","    def __init__(self, x, y):\n","        # Convertir los arrays de numpy a tensores. \n","        # pytorch espera en general entradas 32bits\n","        self.x = torch.from_numpy(x.astype(np.float32))\n","        # las loss unfction esperan la salida float\n","        self.y = torch.from_numpy(y.astype(np.float32))\n","\n","        self.len = self.y.shape[0]\n","\n","    def __getitem__(self,index):\n","        return self.x[index], self.y[index]\n","\n","    def __len__(self):\n","        return self.len\n","\n","data_set = Data(X, y)\n","\n","input_dim = data_set.x.shape[1:]\n","seq_length = input_dim[0]\n","input_size = input_dim[1]\n","print(\"Input dim\", input_dim)\n","print(\"seq_length:\", seq_length)\n","print(\"input_size:\", input_size)\n","\n","output_dim = data_set.y.shape[1]\n","print(\"Output dim\", output_dim)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":468,"status":"ok","timestamp":1656680123339,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"6vggjoIXUIve","outputId":"1a1d2503-7c60-4905-92d5-cfc79d3c214d"},"outputs":[{"data":{"text/plain":["torch.Size([15, 1, 1])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["data_set.x.shape"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1656680126000,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"sjl1f2gXUVHU","outputId":"c4a54234-4cfc-473b-cadc-114c3be60221"},"outputs":[{"data":{"text/plain":["torch.Size([15, 2])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["data_set.y.shape"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1656680507143,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"4j2mXBQhitKg","outputId":"2f6c87be-274d-4084-bf04-9aa071b6ef95"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tamaño del conjunto de entrenamiento: 12\n","Tamaño del conjunto de validacion: 3\n"]}],"source":["torch.manual_seed(42)\n","valid_set_size = int(data_set.len * 0.2)\n","train_set_size = data_set.len - valid_set_size\n","\n","# Cuando trabajmos con una serie temporal no mezclamos (shuffle) los datos\n","train_set = torch.utils.data.Subset(data_set, range(train_set_size))\n","valid_set = torch.utils.data.Subset(data_set, range(train_set_size, data_set.len))\n","\n","print(\"Tamaño del conjunto de entrenamiento:\", len(train_set))\n","print(\"Tamaño del conjunto de validacion:\", len(valid_set))\n","\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=len(train_set), shuffle=False)\n","valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=len(valid_set), shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"VG3-d_NXwDGD"},"source":["### 2 - Entrenar el modelo"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1656680456036,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"WwEo7Sb7fY_l","outputId":"640669e0-8097-45c2-8f45-c92f8241920a"},"outputs":[{"data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","Model1                                   [1, 2]                    --\n","├─CustomLSTM: 1-1                        [1, 1, 64]                16,896\n","│    └─Sigmoid: 2-1                      [1, 64]                   --\n","│    └─Sigmoid: 2-2                      [1, 64]                   --\n","│    └─ReLU: 2-3                         [1, 64]                   --\n","│    └─Sigmoid: 2-4                      [1, 64]                   --\n","│    └─ReLU: 2-5                         [1, 64]                   --\n","├─Linear: 1-2                            [1, 2]                    130\n","==========================================================================================\n","Total params: 17,026\n","Trainable params: 17,026\n","Non-trainable params: 0\n","Total mult-adds (Units.MEGABYTES): 0.00\n","==========================================================================================\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.00\n","Estimated Total Size (MB): 0.00\n","=========================================================================================="]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["from torch_helpers import CustomLSTM\n","\n","class Model1(nn.Module):\n","    def __init__(self, input_size, output_dim):\n","        super().__init__()\n","\n","        #self.rnn1 = nn.RNN(input_size=input_size, hidden_size=64, batch_first=True) # RNN layer\n","        # Utilizamos la CustomRNN ya que para series temporales suele funcionar mejor\n","        # la activacion \"relu\" en las RNN en vez de la \"tanh\", pero por defecto la\n","        # layer de Pytorch RNN no permite modificar la funcion de activacion\n","        #self.rnn1 = CustomRNN(input_size=input_size, hidden_size=64) # RNN layer\n","        self.rnn1 = CustomLSTM(input_size=input_size, hidden_size=64, activation=nn.ReLU()) # RNN layer\n","        self.fc = nn.Linear(in_features=64, out_features=output_dim) #  # Fully connected layer\n","        \n","    def forward(self, x):\n","        lstm_output, _ = self.rnn1(x)\n","        out = self.fc(lstm_output[:,-1,:]) # take last output (last seq)\n","        return out\n","\n","model1 = Model1(input_size=input_size, output_dim=output_dim)\n","\n","# Crear el optimizador la una función de error\n","model1_optimizer = torch.optim.Adam(model1.parameters(), lr=0.01)\n","model1_criterion = nn.MSELoss()  # mean squared error\n","\n","summary(model1, input_size=(1, seq_length, input_size))"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1595,"status":"ok","timestamp":1656680514213,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"CJRYAPO6hlKO","outputId":"a652ed9a-a78d-4f69-e6af-613a101b05bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1/500 - Train loss 461.394 - Valid Loss 1645.036\n","Epoch: 2/500 - Train loss 448.813 - Valid Loss 1586.869\n","Epoch: 3/500 - Train loss 434.275 - Valid Loss 1518.657\n","Epoch: 4/500 - Train loss 417.327 - Valid Loss 1436.544\n","Epoch: 5/500 - Train loss 397.004 - Valid Loss 1339.484\n","Epoch: 6/500 - Train loss 372.932 - Valid Loss 1227.604\n","Epoch: 7/500 - Train loss 344.975 - Valid Loss 1102.000\n","Epoch: 8/500 - Train loss 313.325 - Valid Loss 965.096\n","Epoch: 9/500 - Train loss 278.395 - Valid Loss 819.937\n","Epoch: 10/500 - Train loss 240.831 - Valid Loss 670.320\n","Epoch: 11/500 - Train loss 201.510 - Valid Loss 521.028\n","Epoch: 12/500 - Train loss 161.611 - Valid Loss 377.950\n","Epoch: 13/500 - Train loss 122.564 - Valid Loss 247.920\n","Epoch: 14/500 - Train loss 86.049 - Valid Loss 138.395\n","Epoch: 15/500 - Train loss 53.971 - Valid Loss 56.862\n","Epoch: 16/500 - Train loss 28.339 - Valid Loss 9.972\n","Epoch: 17/500 - Train loss 11.060 - Valid Loss 2.093\n","Epoch: 18/500 - Train loss 3.550 - Valid Loss 32.345\n","Epoch: 19/500 - Train loss 5.989 - Valid Loss 89.485\n","Epoch: 20/500 - Train loss 16.134 - Valid Loss 151.745\n","Epoch: 21/500 - Train loss 29.053 - Valid Loss 198.358\n","Epoch: 22/500 - Train loss 39.580 - Valid Loss 218.645\n","Epoch: 23/500 - Train loss 44.721 - Valid Loss 212.398\n","Epoch: 24/500 - Train loss 44.020 - Valid Loss 185.928\n","Epoch: 25/500 - Train loss 38.715 - Valid Loss 147.978\n","Epoch: 26/500 - Train loss 30.743 - Valid Loss 106.915\n","Epoch: 27/500 - Train loss 22.036 - Valid Loss 69.200\n","Epoch: 28/500 - Train loss 14.116 - Valid Loss 38.853\n","Epoch: 29/500 - Train loss 7.946 - Valid Loss 17.575\n","Epoch: 30/500 - Train loss 3.932 - Valid Loss 5.228\n","Epoch: 31/500 - Train loss 2.026 - Valid Loss 0.430\n","Epoch: 32/500 - Train loss 1.869 - Valid Loss 1.145\n","Epoch: 33/500 - Train loss 2.935 - Valid Loss 5.168\n","Epoch: 34/500 - Train loss 4.662 - Valid Loss 10.492\n","Epoch: 35/500 - Train loss 6.541 - Valid Loss 15.522\n","Epoch: 36/500 - Train loss 8.174 - Valid Loss 19.176\n","Epoch: 37/500 - Train loss 9.297 - Valid Loss 20.882\n","Epoch: 38/500 - Train loss 9.776 - Valid Loss 20.524\n","Epoch: 39/500 - Train loss 9.597 - Valid Loss 18.351\n","Epoch: 40/500 - Train loss 8.841 - Valid Loss 14.868\n","Epoch: 41/500 - Train loss 7.654 - Valid Loss 10.735\n","Epoch: 42/500 - Train loss 6.223 - Valid Loss 6.648\n","Epoch: 43/500 - Train loss 4.747 - Valid Loss 3.246\n","Epoch: 44/500 - Train loss 3.408 - Valid Loss 1.014\n","Epoch: 45/500 - Train loss 2.351 - Valid Loss 0.221\n","Epoch: 46/500 - Train loss 1.666 - Valid Loss 0.879\n","Epoch: 47/500 - Train loss 1.376 - Valid Loss 2.750\n","Epoch: 48/500 - Train loss 1.440 - Valid Loss 5.397\n","Epoch: 49/500 - Train loss 1.760 - Valid Loss 8.271\n","Epoch: 50/500 - Train loss 2.209 - Valid Loss 10.820\n","Epoch: 51/500 - Train loss 2.652 - Valid Loss 12.598\n","Epoch: 52/500 - Train loss 2.979 - Valid Loss 13.341\n","Epoch: 53/500 - Train loss 3.120 - Valid Loss 12.996\n","Epoch: 54/500 - Train loss 3.055 - Valid Loss 11.711\n","Epoch: 55/500 - Train loss 2.813 - Valid Loss 9.769\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 56/500 - Train loss 2.455 - Valid Loss 7.517\n","Epoch: 57/500 - Train loss 2.055 - Valid Loss 5.291\n","Epoch: 58/500 - Train loss 1.686 - Valid Loss 3.350\n","Epoch: 59/500 - Train loss 1.400 - Valid Loss 1.854\n","Epoch: 60/500 - Train loss 1.225 - Valid Loss 0.851\n","Epoch: 61/500 - Train loss 1.163 - Valid Loss 0.299\n","Epoch: 62/500 - Train loss 1.193 - Valid Loss 0.093\n","Epoch: 63/500 - Train loss 1.282 - Valid Loss 0.104\n","Epoch: 64/500 - Train loss 1.393 - Valid Loss 0.207\n","Epoch: 65/500 - Train loss 1.490 - Valid Loss 0.305\n","Epoch: 66/500 - Train loss 1.549 - Valid Loss 0.345\n","Epoch: 67/500 - Train loss 1.558 - Valid Loss 0.313\n","Epoch: 68/500 - Train loss 1.516 - Valid Loss 0.232\n","Epoch: 69/500 - Train loss 1.434 - Valid Loss 0.147\n","Epoch: 70/500 - Train loss 1.330 - Valid Loss 0.109\n","Epoch: 71/500 - Train loss 1.221 - Valid Loss 0.160\n","Epoch: 72/500 - Train loss 1.127 - Valid Loss 0.322\n","Epoch: 73/500 - Train loss 1.058 - Valid Loss 0.592\n","Epoch: 74/500 - Train loss 1.020 - Valid Loss 0.941\n","Epoch: 75/500 - Train loss 1.011 - Valid Loss 1.323\n","Epoch: 76/500 - Train loss 1.023 - Valid Loss 1.683\n","Epoch: 77/500 - Train loss 1.046 - Valid Loss 1.969\n","Epoch: 78/500 - Train loss 1.069 - Valid Loss 2.143\n","Epoch: 79/500 - Train loss 1.082 - Valid Loss 2.188\n","Epoch: 80/500 - Train loss 1.080 - Valid Loss 2.106\n","Epoch: 81/500 - Train loss 1.063 - Valid Loss 1.919\n","Epoch: 82/500 - Train loss 1.033 - Valid Loss 1.662\n","Epoch: 83/500 - Train loss 0.997 - Valid Loss 1.372\n","Epoch: 84/500 - Train loss 0.960 - Valid Loss 1.084\n","Epoch: 85/500 - Train loss 0.928 - Valid Loss 0.826\n","Epoch: 86/500 - Train loss 0.905 - Valid Loss 0.613\n","Epoch: 87/500 - Train loss 0.891 - Valid Loss 0.451\n","Epoch: 88/500 - Train loss 0.885 - Valid Loss 0.337\n","Epoch: 89/500 - Train loss 0.884 - Valid Loss 0.263\n","Epoch: 90/500 - Train loss 0.885 - Valid Loss 0.219\n","Epoch: 91/500 - Train loss 0.885 - Valid Loss 0.197\n","Epoch: 92/500 - Train loss 0.880 - Valid Loss 0.192\n","Epoch: 93/500 - Train loss 0.871 - Valid Loss 0.201\n","Epoch: 94/500 - Train loss 0.859 - Valid Loss 0.225\n","Epoch: 95/500 - Train loss 0.843 - Valid Loss 0.263\n","Epoch: 96/500 - Train loss 0.827 - Valid Loss 0.315\n","Epoch: 97/500 - Train loss 0.811 - Valid Loss 0.381\n","Epoch: 98/500 - Train loss 0.798 - Valid Loss 0.454\n","Epoch: 99/500 - Train loss 0.787 - Valid Loss 0.530\n","Epoch: 100/500 - Train loss 0.780 - Valid Loss 0.599\n","Epoch: 101/500 - Train loss 0.774 - Valid Loss 0.656\n","Epoch: 102/500 - Train loss 0.769 - Valid Loss 0.693\n","Epoch: 103/500 - Train loss 0.763 - Valid Loss 0.707\n","Epoch: 104/500 - Train loss 0.757 - Valid Loss 0.699\n","Epoch: 105/500 - Train loss 0.749 - Valid Loss 0.670\n","Epoch: 106/500 - Train loss 0.740 - Valid Loss 0.625\n","Epoch: 107/500 - Train loss 0.730 - Valid Loss 0.571\n","Epoch: 108/500 - Train loss 0.720 - Valid Loss 0.512\n","Epoch: 109/500 - Train loss 0.711 - Valid Loss 0.454\n","Epoch: 110/500 - Train loss 0.702 - Valid Loss 0.402\n","Epoch: 111/500 - Train loss 0.694 - Valid Loss 0.357\n","Epoch: 112/500 - Train loss 0.687 - Valid Loss 0.321\n","Epoch: 113/500 - Train loss 0.680 - Valid Loss 0.294\n","Epoch: 114/500 - Train loss 0.674 - Valid Loss 0.276\n","Epoch: 115/500 - Train loss 0.668 - Valid Loss 0.265\n","Epoch: 116/500 - Train loss 0.661 - Valid Loss 0.261\n","Epoch: 117/500 - Train loss 0.654 - Valid Loss 0.263\n","Epoch: 118/500 - Train loss 0.646 - Valid Loss 0.270\n","Epoch: 119/500 - Train loss 0.639 - Valid Loss 0.281\n","Epoch: 120/500 - Train loss 0.631 - Valid Loss 0.294\n","Epoch: 121/500 - Train loss 0.624 - Valid Loss 0.308\n","Epoch: 122/500 - Train loss 0.617 - Valid Loss 0.322\n","Epoch: 123/500 - Train loss 0.610 - Valid Loss 0.334\n","Epoch: 124/500 - Train loss 0.604 - Valid Loss 0.342\n","Epoch: 125/500 - Train loss 0.597 - Valid Loss 0.346\n","Epoch: 126/500 - Train loss 0.591 - Valid Loss 0.345\n","Epoch: 127/500 - Train loss 0.585 - Valid Loss 0.339\n","Epoch: 128/500 - Train loss 0.579 - Valid Loss 0.329\n","Epoch: 129/500 - Train loss 0.572 - Valid Loss 0.315\n","Epoch: 130/500 - Train loss 0.566 - Valid Loss 0.299\n","Epoch: 131/500 - Train loss 0.560 - Valid Loss 0.283\n","Epoch: 132/500 - Train loss 0.553 - Valid Loss 0.266\n","Epoch: 133/500 - Train loss 0.547 - Valid Loss 0.251\n","Epoch: 134/500 - Train loss 0.541 - Valid Loss 0.238\n","Epoch: 135/500 - Train loss 0.535 - Valid Loss 0.226\n","Epoch: 136/500 - Train loss 0.530 - Valid Loss 0.218\n","Epoch: 137/500 - Train loss 0.524 - Valid Loss 0.211\n","Epoch: 138/500 - Train loss 0.518 - Valid Loss 0.206\n","Epoch: 139/500 - Train loss 0.513 - Valid Loss 0.204\n","Epoch: 140/500 - Train loss 0.507 - Valid Loss 0.203\n","Epoch: 141/500 - Train loss 0.501 - Valid Loss 0.203\n","Epoch: 142/500 - Train loss 0.496 - Valid Loss 0.203\n","Epoch: 143/500 - Train loss 0.490 - Valid Loss 0.204\n","Epoch: 144/500 - Train loss 0.485 - Valid Loss 0.205\n","Epoch: 145/500 - Train loss 0.479 - Valid Loss 0.205\n","Epoch: 146/500 - Train loss 0.474 - Valid Loss 0.204\n","Epoch: 147/500 - Train loss 0.469 - Valid Loss 0.202\n","Epoch: 148/500 - Train loss 0.464 - Valid Loss 0.200\n","Epoch: 149/500 - Train loss 0.459 - Valid Loss 0.196\n","Epoch: 150/500 - Train loss 0.454 - Valid Loss 0.191\n","Epoch: 151/500 - Train loss 0.449 - Valid Loss 0.185\n","Epoch: 152/500 - Train loss 0.444 - Valid Loss 0.179\n","Epoch: 153/500 - Train loss 0.439 - Valid Loss 0.173\n","Epoch: 154/500 - Train loss 0.434 - Valid Loss 0.167\n","Epoch: 155/500 - Train loss 0.429 - Valid Loss 0.161\n","Epoch: 156/500 - Train loss 0.424 - Valid Loss 0.156\n","Epoch: 157/500 - Train loss 0.419 - Valid Loss 0.152\n","Epoch: 158/500 - Train loss 0.415 - Valid Loss 0.148\n","Epoch: 159/500 - Train loss 0.410 - Valid Loss 0.145\n","Epoch: 160/500 - Train loss 0.406 - Valid Loss 0.142\n","Epoch: 161/500 - Train loss 0.401 - Valid Loss 0.140\n","Epoch: 162/500 - Train loss 0.397 - Valid Loss 0.138\n","Epoch: 163/500 - Train loss 0.392 - Valid Loss 0.136\n","Epoch: 164/500 - Train loss 0.388 - Valid Loss 0.135\n","Epoch: 165/500 - Train loss 0.384 - Valid Loss 0.133\n","Epoch: 166/500 - Train loss 0.379 - Valid Loss 0.132\n","Epoch: 167/500 - Train loss 0.375 - Valid Loss 0.130\n","Epoch: 168/500 - Train loss 0.371 - Valid Loss 0.128\n","Epoch: 169/500 - Train loss 0.367 - Valid Loss 0.126\n","Epoch: 170/500 - Train loss 0.363 - Valid Loss 0.124\n","Epoch: 171/500 - Train loss 0.359 - Valid Loss 0.121\n","Epoch: 172/500 - Train loss 0.355 - Valid Loss 0.119\n","Epoch: 173/500 - Train loss 0.351 - Valid Loss 0.116\n","Epoch: 174/500 - Train loss 0.347 - Valid Loss 0.114\n","Epoch: 175/500 - Train loss 0.343 - Valid Loss 0.111\n","Epoch: 176/500 - Train loss 0.339 - Valid Loss 0.109\n","Epoch: 177/500 - Train loss 0.335 - Valid Loss 0.107\n","Epoch: 178/500 - Train loss 0.332 - Valid Loss 0.105\n","Epoch: 179/500 - Train loss 0.328 - Valid Loss 0.103\n","Epoch: 180/500 - Train loss 0.324 - Valid Loss 0.101\n","Epoch: 181/500 - Train loss 0.321 - Valid Loss 0.100\n","Epoch: 182/500 - Train loss 0.317 - Valid Loss 0.098\n","Epoch: 183/500 - Train loss 0.314 - Valid Loss 0.097\n","Epoch: 184/500 - Train loss 0.310 - Valid Loss 0.096\n","Epoch: 185/500 - Train loss 0.307 - Valid Loss 0.095\n","Epoch: 186/500 - Train loss 0.303 - Valid Loss 0.094\n","Epoch: 187/500 - Train loss 0.300 - Valid Loss 0.092\n","Epoch: 188/500 - Train loss 0.297 - Valid Loss 0.091\n","Epoch: 189/500 - Train loss 0.293 - Valid Loss 0.090\n","Epoch: 190/500 - Train loss 0.290 - Valid Loss 0.089\n","Epoch: 191/500 - Train loss 0.287 - Valid Loss 0.088\n","Epoch: 192/500 - Train loss 0.284 - Valid Loss 0.087\n","Epoch: 193/500 - Train loss 0.281 - Valid Loss 0.086\n","Epoch: 194/500 - Train loss 0.278 - Valid Loss 0.085\n","Epoch: 195/500 - Train loss 0.275 - Valid Loss 0.084\n","Epoch: 196/500 - Train loss 0.272 - Valid Loss 0.083\n","Epoch: 197/500 - Train loss 0.269 - Valid Loss 0.083\n","Epoch: 198/500 - Train loss 0.266 - Valid Loss 0.082\n","Epoch: 199/500 - Train loss 0.263 - Valid Loss 0.081\n","Epoch: 200/500 - Train loss 0.260 - Valid Loss 0.081\n","Epoch: 201/500 - Train loss 0.257 - Valid Loss 0.080\n","Epoch: 202/500 - Train loss 0.254 - Valid Loss 0.080\n","Epoch: 203/500 - Train loss 0.252 - Valid Loss 0.079\n","Epoch: 204/500 - Train loss 0.249 - Valid Loss 0.079\n","Epoch: 205/500 - Train loss 0.246 - Valid Loss 0.078\n","Epoch: 206/500 - Train loss 0.243 - Valid Loss 0.078\n","Epoch: 207/500 - Train loss 0.241 - Valid Loss 0.078\n","Epoch: 208/500 - Train loss 0.238 - Valid Loss 0.078\n","Epoch: 209/500 - Train loss 0.236 - Valid Loss 0.077\n","Epoch: 210/500 - Train loss 0.233 - Valid Loss 0.077\n","Epoch: 211/500 - Train loss 0.231 - Valid Loss 0.077\n","Epoch: 212/500 - Train loss 0.228 - Valid Loss 0.077\n","Epoch: 213/500 - Train loss 0.226 - Valid Loss 0.077\n","Epoch: 214/500 - Train loss 0.223 - Valid Loss 0.077\n","Epoch: 215/500 - Train loss 0.221 - Valid Loss 0.077\n","Epoch: 216/500 - Train loss 0.219 - Valid Loss 0.077\n","Epoch: 217/500 - Train loss 0.216 - Valid Loss 0.077\n","Epoch: 218/500 - Train loss 0.214 - Valid Loss 0.077\n","Epoch: 219/500 - Train loss 0.212 - Valid Loss 0.078\n","Epoch: 220/500 - Train loss 0.210 - Valid Loss 0.078\n","Epoch: 221/500 - Train loss 0.207 - Valid Loss 0.078\n","Epoch: 222/500 - Train loss 0.205 - Valid Loss 0.078\n","Epoch: 223/500 - Train loss 0.203 - Valid Loss 0.079\n","Epoch: 224/500 - Train loss 0.201 - Valid Loss 0.079\n","Epoch: 225/500 - Train loss 0.199 - Valid Loss 0.079\n","Epoch: 226/500 - Train loss 0.197 - Valid Loss 0.080\n","Epoch: 227/500 - Train loss 0.195 - Valid Loss 0.080\n","Epoch: 228/500 - Train loss 0.193 - Valid Loss 0.081\n","Epoch: 229/500 - Train loss 0.191 - Valid Loss 0.081\n","Epoch: 230/500 - Train loss 0.189 - Valid Loss 0.082\n","Epoch: 231/500 - Train loss 0.187 - Valid Loss 0.082\n","Epoch: 232/500 - Train loss 0.185 - Valid Loss 0.083\n","Epoch: 233/500 - Train loss 0.183 - Valid Loss 0.083\n","Epoch: 234/500 - Train loss 0.181 - Valid Loss 0.084\n","Epoch: 235/500 - Train loss 0.180 - Valid Loss 0.085\n","Epoch: 236/500 - Train loss 0.178 - Valid Loss 0.085\n","Epoch: 237/500 - Train loss 0.176 - Valid Loss 0.086\n","Epoch: 238/500 - Train loss 0.174 - Valid Loss 0.087\n","Epoch: 239/500 - Train loss 0.173 - Valid Loss 0.088\n","Epoch: 240/500 - Train loss 0.171 - Valid Loss 0.088\n","Epoch: 241/500 - Train loss 0.169 - Valid Loss 0.089\n","Epoch: 242/500 - Train loss 0.168 - Valid Loss 0.090\n","Epoch: 243/500 - Train loss 0.166 - Valid Loss 0.091\n","Epoch: 244/500 - Train loss 0.164 - Valid Loss 0.092\n","Epoch: 245/500 - Train loss 0.163 - Valid Loss 0.093\n","Epoch: 246/500 - Train loss 0.161 - Valid Loss 0.093\n","Epoch: 247/500 - Train loss 0.160 - Valid Loss 0.094\n","Epoch: 248/500 - Train loss 0.158 - Valid Loss 0.095\n","Epoch: 249/500 - Train loss 0.157 - Valid Loss 0.096\n","Epoch: 250/500 - Train loss 0.155 - Valid Loss 0.097\n","Epoch: 251/500 - Train loss 0.154 - Valid Loss 0.098\n","Epoch: 252/500 - Train loss 0.152 - Valid Loss 0.099\n","Epoch: 253/500 - Train loss 0.151 - Valid Loss 0.100\n","Epoch: 254/500 - Train loss 0.149 - Valid Loss 0.101\n","Epoch: 255/500 - Train loss 0.148 - Valid Loss 0.102\n","Epoch: 256/500 - Train loss 0.147 - Valid Loss 0.104\n","Epoch: 257/500 - Train loss 0.145 - Valid Loss 0.105\n","Epoch: 258/500 - Train loss 0.144 - Valid Loss 0.106\n","Epoch: 259/500 - Train loss 0.143 - Valid Loss 0.107\n","Epoch: 260/500 - Train loss 0.141 - Valid Loss 0.108\n","Epoch: 261/500 - Train loss 0.140 - Valid Loss 0.109\n","Epoch: 262/500 - Train loss 0.139 - Valid Loss 0.110\n","Epoch: 263/500 - Train loss 0.138 - Valid Loss 0.111\n","Epoch: 264/500 - Train loss 0.136 - Valid Loss 0.113\n","Epoch: 265/500 - Train loss 0.135 - Valid Loss 0.114\n","Epoch: 266/500 - Train loss 0.134 - Valid Loss 0.115\n","Epoch: 267/500 - Train loss 0.133 - Valid Loss 0.116\n","Epoch: 268/500 - Train loss 0.132 - Valid Loss 0.117\n","Epoch: 269/500 - Train loss 0.131 - Valid Loss 0.119\n","Epoch: 270/500 - Train loss 0.130 - Valid Loss 0.120\n","Epoch: 271/500 - Train loss 0.128 - Valid Loss 0.121\n","Epoch: 272/500 - Train loss 0.127 - Valid Loss 0.122\n","Epoch: 273/500 - Train loss 0.126 - Valid Loss 0.123\n","Epoch: 274/500 - Train loss 0.125 - Valid Loss 0.125\n","Epoch: 275/500 - Train loss 0.124 - Valid Loss 0.126\n","Epoch: 276/500 - Train loss 0.123 - Valid Loss 0.127\n","Epoch: 277/500 - Train loss 0.122 - Valid Loss 0.128\n","Epoch: 278/500 - Train loss 0.121 - Valid Loss 0.130\n","Epoch: 279/500 - Train loss 0.120 - Valid Loss 0.131\n","Epoch: 280/500 - Train loss 0.119 - Valid Loss 0.132\n","Epoch: 281/500 - Train loss 0.118 - Valid Loss 0.134\n","Epoch: 282/500 - Train loss 0.117 - Valid Loss 0.135\n","Epoch: 283/500 - Train loss 0.116 - Valid Loss 0.136\n","Epoch: 284/500 - Train loss 0.116 - Valid Loss 0.137\n","Epoch: 285/500 - Train loss 0.115 - Valid Loss 0.139\n","Epoch: 286/500 - Train loss 0.114 - Valid Loss 0.140\n","Epoch: 287/500 - Train loss 0.113 - Valid Loss 0.141\n","Epoch: 288/500 - Train loss 0.112 - Valid Loss 0.143\n","Epoch: 289/500 - Train loss 0.111 - Valid Loss 0.144\n","Epoch: 290/500 - Train loss 0.110 - Valid Loss 0.145\n","Epoch: 291/500 - Train loss 0.109 - Valid Loss 0.146\n","Epoch: 292/500 - Train loss 0.109 - Valid Loss 0.148\n","Epoch: 293/500 - Train loss 0.108 - Valid Loss 0.149\n","Epoch: 294/500 - Train loss 0.107 - Valid Loss 0.150\n","Epoch: 295/500 - Train loss 0.106 - Valid Loss 0.151\n","Epoch: 296/500 - Train loss 0.106 - Valid Loss 0.153\n","Epoch: 297/500 - Train loss 0.105 - Valid Loss 0.154\n","Epoch: 298/500 - Train loss 0.104 - Valid Loss 0.155\n","Epoch: 299/500 - Train loss 0.103 - Valid Loss 0.157\n","Epoch: 300/500 - Train loss 0.103 - Valid Loss 0.158\n","Epoch: 301/500 - Train loss 0.102 - Valid Loss 0.159\n","Epoch: 302/500 - Train loss 0.101 - Valid Loss 0.160\n","Epoch: 303/500 - Train loss 0.100 - Valid Loss 0.161\n","Epoch: 304/500 - Train loss 0.100 - Valid Loss 0.163\n","Epoch: 305/500 - Train loss 0.099 - Valid Loss 0.164\n","Epoch: 306/500 - Train loss 0.098 - Valid Loss 0.165\n","Epoch: 307/500 - Train loss 0.098 - Valid Loss 0.166\n","Epoch: 308/500 - Train loss 0.097 - Valid Loss 0.168\n","Epoch: 309/500 - Train loss 0.097 - Valid Loss 0.169\n","Epoch: 310/500 - Train loss 0.096 - Valid Loss 0.170\n","Epoch: 311/500 - Train loss 0.095 - Valid Loss 0.171\n","Epoch: 312/500 - Train loss 0.095 - Valid Loss 0.172\n","Epoch: 313/500 - Train loss 0.094 - Valid Loss 0.173\n","Epoch: 314/500 - Train loss 0.093 - Valid Loss 0.175\n","Epoch: 315/500 - Train loss 0.093 - Valid Loss 0.176\n","Epoch: 316/500 - Train loss 0.092 - Valid Loss 0.177\n","Epoch: 317/500 - Train loss 0.092 - Valid Loss 0.178\n","Epoch: 318/500 - Train loss 0.091 - Valid Loss 0.179\n","Epoch: 319/500 - Train loss 0.091 - Valid Loss 0.180\n","Epoch: 320/500 - Train loss 0.090 - Valid Loss 0.181\n","Epoch: 321/500 - Train loss 0.089 - Valid Loss 0.182\n","Epoch: 322/500 - Train loss 0.089 - Valid Loss 0.184\n","Epoch: 323/500 - Train loss 0.088 - Valid Loss 0.185\n","Epoch: 324/500 - Train loss 0.088 - Valid Loss 0.186\n","Epoch: 325/500 - Train loss 0.087 - Valid Loss 0.187\n","Epoch: 326/500 - Train loss 0.087 - Valid Loss 0.188\n","Epoch: 327/500 - Train loss 0.086 - Valid Loss 0.189\n","Epoch: 328/500 - Train loss 0.086 - Valid Loss 0.190\n","Epoch: 329/500 - Train loss 0.085 - Valid Loss 0.191\n","Epoch: 330/500 - Train loss 0.085 - Valid Loss 0.192\n","Epoch: 331/500 - Train loss 0.084 - Valid Loss 0.193\n","Epoch: 332/500 - Train loss 0.084 - Valid Loss 0.194\n","Epoch: 333/500 - Train loss 0.083 - Valid Loss 0.195\n","Epoch: 334/500 - Train loss 0.083 - Valid Loss 0.196\n","Epoch: 335/500 - Train loss 0.083 - Valid Loss 0.197\n","Epoch: 336/500 - Train loss 0.082 - Valid Loss 0.197\n","Epoch: 337/500 - Train loss 0.082 - Valid Loss 0.198\n","Epoch: 338/500 - Train loss 0.081 - Valid Loss 0.199\n","Epoch: 339/500 - Train loss 0.081 - Valid Loss 0.200\n","Epoch: 340/500 - Train loss 0.080 - Valid Loss 0.201\n","Epoch: 341/500 - Train loss 0.080 - Valid Loss 0.202\n","Epoch: 342/500 - Train loss 0.079 - Valid Loss 0.203\n","Epoch: 343/500 - Train loss 0.079 - Valid Loss 0.203\n","Epoch: 344/500 - Train loss 0.079 - Valid Loss 0.204\n","Epoch: 345/500 - Train loss 0.078 - Valid Loss 0.205\n","Epoch: 346/500 - Train loss 0.078 - Valid Loss 0.206\n","Epoch: 347/500 - Train loss 0.077 - Valid Loss 0.207\n","Epoch: 348/500 - Train loss 0.077 - Valid Loss 0.207\n","Epoch: 349/500 - Train loss 0.077 - Valid Loss 0.208\n","Epoch: 350/500 - Train loss 0.076 - Valid Loss 0.209\n","Epoch: 351/500 - Train loss 0.076 - Valid Loss 0.210\n","Epoch: 352/500 - Train loss 0.075 - Valid Loss 0.210\n","Epoch: 353/500 - Train loss 0.075 - Valid Loss 0.211\n","Epoch: 354/500 - Train loss 0.075 - Valid Loss 0.212\n","Epoch: 355/500 - Train loss 0.074 - Valid Loss 0.212\n","Epoch: 356/500 - Train loss 0.074 - Valid Loss 0.213\n","Epoch: 357/500 - Train loss 0.074 - Valid Loss 0.214\n","Epoch: 358/500 - Train loss 0.073 - Valid Loss 0.214\n","Epoch: 359/500 - Train loss 0.073 - Valid Loss 0.215\n","Epoch: 360/500 - Train loss 0.073 - Valid Loss 0.215\n","Epoch: 361/500 - Train loss 0.072 - Valid Loss 0.216\n","Epoch: 362/500 - Train loss 0.072 - Valid Loss 0.217\n","Epoch: 363/500 - Train loss 0.072 - Valid Loss 0.217\n","Epoch: 364/500 - Train loss 0.071 - Valid Loss 0.218\n","Epoch: 365/500 - Train loss 0.071 - Valid Loss 0.218\n","Epoch: 366/500 - Train loss 0.071 - Valid Loss 0.219\n","Epoch: 367/500 - Train loss 0.070 - Valid Loss 0.219\n","Epoch: 368/500 - Train loss 0.070 - Valid Loss 0.220\n","Epoch: 369/500 - Train loss 0.070 - Valid Loss 0.220\n","Epoch: 370/500 - Train loss 0.069 - Valid Loss 0.221\n","Epoch: 371/500 - Train loss 0.069 - Valid Loss 0.221\n","Epoch: 372/500 - Train loss 0.069 - Valid Loss 0.221\n","Epoch: 373/500 - Train loss 0.068 - Valid Loss 0.222\n","Epoch: 374/500 - Train loss 0.068 - Valid Loss 0.222\n","Epoch: 375/500 - Train loss 0.068 - Valid Loss 0.223\n","Epoch: 376/500 - Train loss 0.067 - Valid Loss 0.223\n","Epoch: 377/500 - Train loss 0.067 - Valid Loss 0.223\n","Epoch: 378/500 - Train loss 0.067 - Valid Loss 0.224\n","Epoch: 379/500 - Train loss 0.066 - Valid Loss 0.224\n","Epoch: 380/500 - Train loss 0.066 - Valid Loss 0.224\n","Epoch: 381/500 - Train loss 0.066 - Valid Loss 0.225\n","Epoch: 382/500 - Train loss 0.066 - Valid Loss 0.225\n","Epoch: 383/500 - Train loss 0.065 - Valid Loss 0.225\n","Epoch: 384/500 - Train loss 0.065 - Valid Loss 0.226\n","Epoch: 385/500 - Train loss 0.065 - Valid Loss 0.226\n","Epoch: 386/500 - Train loss 0.064 - Valid Loss 0.226\n","Epoch: 387/500 - Train loss 0.064 - Valid Loss 0.226\n","Epoch: 388/500 - Train loss 0.064 - Valid Loss 0.226\n","Epoch: 389/500 - Train loss 0.064 - Valid Loss 0.227\n","Epoch: 390/500 - Train loss 0.063 - Valid Loss 0.227\n","Epoch: 391/500 - Train loss 0.063 - Valid Loss 0.227\n","Epoch: 392/500 - Train loss 0.063 - Valid Loss 0.227\n","Epoch: 393/500 - Train loss 0.062 - Valid Loss 0.227\n","Epoch: 394/500 - Train loss 0.062 - Valid Loss 0.228\n","Epoch: 395/500 - Train loss 0.062 - Valid Loss 0.228\n","Epoch: 396/500 - Train loss 0.062 - Valid Loss 0.228\n","Epoch: 397/500 - Train loss 0.061 - Valid Loss 0.228\n","Epoch: 398/500 - Train loss 0.061 - Valid Loss 0.228\n","Epoch: 399/500 - Train loss 0.061 - Valid Loss 0.228\n","Epoch: 400/500 - Train loss 0.061 - Valid Loss 0.228\n","Epoch: 401/500 - Train loss 0.060 - Valid Loss 0.228\n","Epoch: 402/500 - Train loss 0.060 - Valid Loss 0.228\n","Epoch: 403/500 - Train loss 0.060 - Valid Loss 0.229\n","Epoch: 404/500 - Train loss 0.060 - Valid Loss 0.229\n","Epoch: 405/500 - Train loss 0.059 - Valid Loss 0.229\n","Epoch: 406/500 - Train loss 0.059 - Valid Loss 0.229\n","Epoch: 407/500 - Train loss 0.059 - Valid Loss 0.229\n","Epoch: 408/500 - Train loss 0.059 - Valid Loss 0.229\n","Epoch: 409/500 - Train loss 0.058 - Valid Loss 0.229\n","Epoch: 410/500 - Train loss 0.058 - Valid Loss 0.229\n","Epoch: 411/500 - Train loss 0.058 - Valid Loss 0.229\n","Epoch: 412/500 - Train loss 0.058 - Valid Loss 0.229\n","Epoch: 413/500 - Train loss 0.057 - Valid Loss 0.229\n","Epoch: 414/500 - Train loss 0.057 - Valid Loss 0.229\n","Epoch: 415/500 - Train loss 0.057 - Valid Loss 0.228\n","Epoch: 416/500 - Train loss 0.057 - Valid Loss 0.228\n","Epoch: 417/500 - Train loss 0.056 - Valid Loss 0.228\n","Epoch: 418/500 - Train loss 0.056 - Valid Loss 0.228\n","Epoch: 419/500 - Train loss 0.056 - Valid Loss 0.228\n","Epoch: 420/500 - Train loss 0.056 - Valid Loss 0.228\n","Epoch: 421/500 - Train loss 0.055 - Valid Loss 0.228\n","Epoch: 422/500 - Train loss 0.055 - Valid Loss 0.228\n","Epoch: 423/500 - Train loss 0.055 - Valid Loss 0.228\n","Epoch: 424/500 - Train loss 0.055 - Valid Loss 0.228\n","Epoch: 425/500 - Train loss 0.054 - Valid Loss 0.227\n","Epoch: 426/500 - Train loss 0.054 - Valid Loss 0.227\n","Epoch: 427/500 - Train loss 0.054 - Valid Loss 0.227\n","Epoch: 428/500 - Train loss 0.054 - Valid Loss 0.227\n","Epoch: 429/500 - Train loss 0.054 - Valid Loss 0.227\n","Epoch: 430/500 - Train loss 0.053 - Valid Loss 0.227\n","Epoch: 431/500 - Train loss 0.053 - Valid Loss 0.227\n","Epoch: 432/500 - Train loss 0.053 - Valid Loss 0.226\n","Epoch: 433/500 - Train loss 0.053 - Valid Loss 0.226\n","Epoch: 434/500 - Train loss 0.052 - Valid Loss 0.226\n","Epoch: 435/500 - Train loss 0.052 - Valid Loss 0.226\n","Epoch: 436/500 - Train loss 0.052 - Valid Loss 0.226\n","Epoch: 437/500 - Train loss 0.052 - Valid Loss 0.225\n","Epoch: 438/500 - Train loss 0.052 - Valid Loss 0.225\n","Epoch: 439/500 - Train loss 0.051 - Valid Loss 0.225\n","Epoch: 440/500 - Train loss 0.051 - Valid Loss 0.225\n","Epoch: 441/500 - Train loss 0.051 - Valid Loss 0.224\n","Epoch: 442/500 - Train loss 0.051 - Valid Loss 0.224\n","Epoch: 443/500 - Train loss 0.050 - Valid Loss 0.224\n","Epoch: 444/500 - Train loss 0.050 - Valid Loss 0.224\n","Epoch: 445/500 - Train loss 0.050 - Valid Loss 0.223\n","Epoch: 446/500 - Train loss 0.050 - Valid Loss 0.223\n","Epoch: 447/500 - Train loss 0.050 - Valid Loss 0.223\n","Epoch: 448/500 - Train loss 0.049 - Valid Loss 0.223\n","Epoch: 449/500 - Train loss 0.049 - Valid Loss 0.222\n","Epoch: 450/500 - Train loss 0.049 - Valid Loss 0.222\n","Epoch: 451/500 - Train loss 0.049 - Valid Loss 0.222\n","Epoch: 452/500 - Train loss 0.049 - Valid Loss 0.221\n","Epoch: 453/500 - Train loss 0.048 - Valid Loss 0.221\n","Epoch: 454/500 - Train loss 0.048 - Valid Loss 0.221\n","Epoch: 455/500 - Train loss 0.048 - Valid Loss 0.220\n","Epoch: 456/500 - Train loss 0.048 - Valid Loss 0.220\n","Epoch: 457/500 - Train loss 0.048 - Valid Loss 0.220\n","Epoch: 458/500 - Train loss 0.047 - Valid Loss 0.220\n","Epoch: 459/500 - Train loss 0.047 - Valid Loss 0.219\n","Epoch: 460/500 - Train loss 0.047 - Valid Loss 0.219\n","Epoch: 461/500 - Train loss 0.047 - Valid Loss 0.219\n","Epoch: 462/500 - Train loss 0.046 - Valid Loss 0.218\n","Epoch: 463/500 - Train loss 0.046 - Valid Loss 0.218\n","Epoch: 464/500 - Train loss 0.046 - Valid Loss 0.217\n","Epoch: 465/500 - Train loss 0.046 - Valid Loss 0.217\n","Epoch: 466/500 - Train loss 0.046 - Valid Loss 0.217\n","Epoch: 467/500 - Train loss 0.045 - Valid Loss 0.216\n","Epoch: 468/500 - Train loss 0.045 - Valid Loss 0.216\n","Epoch: 469/500 - Train loss 0.045 - Valid Loss 0.216\n","Epoch: 470/500 - Train loss 0.045 - Valid Loss 0.215\n","Epoch: 471/500 - Train loss 0.045 - Valid Loss 0.215\n","Epoch: 472/500 - Train loss 0.045 - Valid Loss 0.215\n","Epoch: 473/500 - Train loss 0.044 - Valid Loss 0.214\n","Epoch: 474/500 - Train loss 0.044 - Valid Loss 0.214\n","Epoch: 475/500 - Train loss 0.044 - Valid Loss 0.213\n","Epoch: 476/500 - Train loss 0.044 - Valid Loss 0.213\n","Epoch: 477/500 - Train loss 0.044 - Valid Loss 0.213\n","Epoch: 478/500 - Train loss 0.043 - Valid Loss 0.212\n","Epoch: 479/500 - Train loss 0.043 - Valid Loss 0.212\n","Epoch: 480/500 - Train loss 0.043 - Valid Loss 0.211\n","Epoch: 481/500 - Train loss 0.043 - Valid Loss 0.211\n","Epoch: 482/500 - Train loss 0.043 - Valid Loss 0.211\n","Epoch: 483/500 - Train loss 0.042 - Valid Loss 0.210\n","Epoch: 484/500 - Train loss 0.042 - Valid Loss 0.210\n","Epoch: 485/500 - Train loss 0.042 - Valid Loss 0.209\n","Epoch: 486/500 - Train loss 0.042 - Valid Loss 0.209\n","Epoch: 487/500 - Train loss 0.042 - Valid Loss 0.209\n","Epoch: 488/500 - Train loss 0.041 - Valid Loss 0.208\n","Epoch: 489/500 - Train loss 0.041 - Valid Loss 0.208\n","Epoch: 490/500 - Train loss 0.041 - Valid Loss 0.207\n","Epoch: 491/500 - Train loss 0.041 - Valid Loss 0.207\n","Epoch: 492/500 - Train loss 0.041 - Valid Loss 0.206\n","Epoch: 493/500 - Train loss 0.041 - Valid Loss 0.206\n","Epoch: 494/500 - Train loss 0.040 - Valid Loss 0.205\n","Epoch: 495/500 - Train loss 0.040 - Valid Loss 0.205\n","Epoch: 496/500 - Train loss 0.040 - Valid Loss 0.205\n","Epoch: 497/500 - Train loss 0.040 - Valid Loss 0.204\n","Epoch: 498/500 - Train loss 0.040 - Valid Loss 0.204\n","Epoch: 499/500 - Train loss 0.039 - Valid Loss 0.203\n","Epoch: 500/500 - Train loss 0.039 - Valid Loss 0.203\n"]}],"source":["history1 = train(model1,\n","                train_loader,\n","                valid_loader,\n","                model1_optimizer,\n","                model1_criterion,\n","                epochs=500\n","                )"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":393,"status":"ok","timestamp":1656680519251,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"DY39Ruoahrsk","outputId":"454aaf18-fc6c-46fb-b960-a6357a5325bf"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8RUlEQVR4nO3deXxU5d3///dkkpkkQDZCNg2LgCiyiKAxbtVCCUtxqfZWoYpKodrQu4paSmsV8L7Fgl+Xelt7+23VX+/i0vZ2KypfAyhURUAgsmkECgYli4LJEELWuX5/DHNgIIEs58wk4fV8POYxM+dcc+aaozbvfq7rOsdljDECAADoRKIi3QEAAIDWIsAAAIBOhwADAAA6HQIMAADodAgwAACg0yHAAACATocAAwAAOh0CDAAA6HSiI90Bp/j9fu3du1c9evSQy+WKdHcAAEALGGN04MABZWVlKSqq+TpLlw0we/fuVXZ2dqS7AQAA2mDPnj06/fTTm93fZQNMjx49JAVOQEJCQoR7AwAAWsLn8yk7O9v6O96cLhtggsNGCQkJBBgAADqZk03/YBIvAADodAgwAACg0yHAAACATqfLzoEBAMBuxhg1NDSosbEx0l3ptNxut6Kjo9t9iRMCDAAALVBXV6eSkhJVV1dHuiudXnx8vDIzM+XxeNp8DAIMAAAn4ff7tWvXLrndbmVlZcnj8XCR1DYwxqiurk5ff/21du3apYEDB57wYnUnQoABAOAk6urq5Pf7lZ2drfj4+Eh3p1OLi4tTTEyMvvjiC9XV1Sk2NrZNx2ESLwAALdTWagFC2XEe+ScBAAA6HQIMAADodAgwAACgRfr27avHH3880t2QxCReAAC6tMsvv1znnnuuLcFj3bp16tatW/s7ZQMCTGt98pL05cfSkB9IfS6KdG8AAGgXY4waGxsVHX3ySNCrV68w9KhlGEJqrc//n7Tu/0p7CyPdEwBABBljVF3XEJGHMaZFfbzlllu0cuVKPfHEE3K5XHK5XHr++eflcrn09ttva+TIkfJ6vXr//fe1c+dOXXXVVUpPT1f37t11/vnna9myZSHHO3YIyeVy6Y9//KOuueYaxcfHa+DAgXrjjTfsPM3NogLTWvE9A8+H9ke2HwCAiDpU36jB9/+/iHz3tvl5ivec/E/4E088oc8//1xDhgzR/PnzJUlbt26VJP3yl7/UI488ojPOOEPJycnas2ePJkyYoP/8z/+U1+vVn//8Z02aNElFRUXq3bt3s98xb948LVy4UIsWLdKTTz6pKVOm6IsvvlBKSoo9P7YZVGBaK/7wP5DqfZHtBwAAJ5GYmCiPx6P4+HhlZGQoIyNDbrdbkjR//nx973vfU//+/ZWSkqLhw4frJz/5iYYMGaKBAwfqwQcfVP/+/U9aUbnlllt04403asCAAXrooYdUVVWltWvXOv7bqMC0VrACU00FBgBOZXExbm2bnxex726vUaNGhbyvqqrS3Llz9eabb6qkpEQNDQ06dOiQiouLT3icYcOGWa+7deumhIQElZeXt7t/J0OAaa04KjAAgMD8j5YM43RUx64muueee1RQUKBHHnlEAwYMUFxcnK677jrV1dWd8DgxMTEh710ul/x+v+39PVbnPfOREhxCOvRtZPsBAEALeDweNTY2nrTdBx98oFtuuUXXXHONpEBFZvfu3Q73ru2YA9NazIEBAHQiffv21Zo1a7R792598803zVZHBg4cqFdeeUWFhYX65JNPNHny5LBUUtqKANNaR8+BaeEyNgAAIuWee+6R2+3W4MGD1atXr2bntDz66KNKTk7WRRddpEmTJikvL0/nnXdemHvbci7T0sXknYzP51NiYqIqKyuVkJBg34Frq6QFpwVez/lK8na379gAgA6ppqZGu3btUr9+/RQbGxvp7nR6JzqfLf37TQWmtTzdJLc38JprwQAAEBEEmNZyuY4aRmIeDAAAkUCAaQtrIi8VGAAAIoEA0xZxyYFnAgwAABFBgGmLuKTAc01FJHsBAMApiwDTFrGJgeeaysj2AwCAUxQBpi1ikwLPVGAAAIgIAkxbBIeQDlVEshcAAJyyCDBtYVVgGEICAHRtffv21eOPP269d7lceu2115ptv3v3brlcLhUWFjraL27m2BYMIQEATlElJSVKTk6OdDcIMG3CJF4AwCkqIyMj0l2QxBBS2zAHBgDQCTzzzDPKyso67q7SV111lW677Tbt3LlTV111ldLT09W9e3edf/75WrZs2QmPeewQ0tq1azVixAjFxsZq1KhR2rhxoxM/5TgEmLZgDgwAwBip7mBkHi28D/MPf/hD7du3T++++661bf/+/Vq6dKmmTJmiqqoqTZgwQcuXL9fGjRs1btw4TZo0qdk7Vh+rqqpK3//+9zV48GCtX79ec+fO1T333NOm09laDCG1xdFDSH6/FEUOBIBTTn219FBWZL77V3sDNxc+ieTkZI0fP14vvPCCRo8eLUn6+9//rtTUVF1xxRWKiorS8OHDrfYPPvigXn31Vb3xxhuaOXPmSY//wgsvyO/3609/+pNiY2N1zjnn6Msvv9Qdd9zR9t/WQvzlbYtggJGRan0R7QoAACcyZcoU/e///q9qa2slSYsXL9YNN9ygqKgoVVVV6Z577tHZZ5+tpKQkde/eXZ9++mmLKzCffvqphg0bptjYWGtbbm6uI7/jWFRg2iImVoqOlRpqAlWY4JwYAMCpIyY+UAmJ1He30KRJk2SM0Ztvvqnzzz9f//znP/XYY49Jku655x4VFBTokUce0YABAxQXF6frrrtOdXV1TvXcNgSYtopNkqpKDy+l7hPhzgAAws7latEwTqTFxsbqBz/4gRYvXqwdO3Zo0KBBOu+88yRJH3zwgW655RZdc801kgJzWnbv3t3iY5999tn6n//5H9XU1FhVmI8++sj239CUVg8hrVq1SpMmTVJWVlaTF7O55ZZb5HK5Qh7jxo0LabN//35NmTJFCQkJSkpK0rRp01RVVRXSZtOmTbr00ksVGxur7OxsLVy4sPW/zkkspQYAdBJTpkzRm2++qWeffVZTpkyxtg8cOFCvvPKKCgsL9cknn2jy5MnHrVg6kcmTJ8vlcmn69Onatm2b3nrrLT3yyCNO/ITjtDrAHDx4UMOHD9dTTz3VbJtx48appKTEerz44osh+6dMmaKtW7eqoKBAS5Ys0apVqzRjxgxrv8/n09ixY9WnTx+tX79eixYt0ty5c/XMM8+0trvO8fYIPNdWnbgdAAAR9t3vflcpKSkqKirS5MmTre2PPvqokpOTddFFF2nSpEnKy8uzqjMt0b17d/3jH//Q5s2bNWLECP3617/Wb3/7Wyd+wnFaPYQ0fvx4jR8//oRtvF5vsxe6+fTTT7V06VKtW7dOo0aNkiQ9+eSTmjBhgh555BFlZWVp8eLFqqur07PPPiuPx6NzzjlHhYWFevTRR0OCTkRZAeZAZPsBAMBJREVFae/e4+fr9O3bVytWrAjZlp+fH/L+2CElc8wS7gsvvPC42wYc28YJjqxCeu+995SWlqZBgwbpjjvu0L59+6x9q1evVlJSkhVeJGnMmDGKiorSmjVrrDaXXXaZPB6P1SYvL09FRUX69ttvm/zO2tpa+Xy+kIejrADDKiQAAMLN9gAzbtw4/fnPf9by5cv129/+VitXrtT48ePV2NgoSSotLVVaWlrIZ6Kjo5WSkqLS0lKrTXp6ekib4Ptgm2MtWLBAiYmJ1iM7O9vunxbKmxB4pgIDAEDY2b4K6YYbbrBeDx06VMOGDVP//v313nvvWRfRccKcOXM0a9Ys673P53M2xHi7B57rmAMDAEC4OX4huzPOOEOpqanasWOHpMBNoMrLy0PaNDQ0aP/+/da8mYyMDJWVlYW0Cb5vbm6N1+tVQkJCyMNRzIEBACBiHA8wX375pfbt26fMzExJgSv0VVRUaP369VabFStWyO/3Kycnx2qzatUq1dfXW20KCgo0aNCgDnELb0kEGAAAIqjVAaaqqkqFhYXWjONdu3apsLBQxcXFqqqq0r333quPPvpIu3fv1vLly3XVVVdpwIABysvLkxS46M24ceM0ffp0rV27Vh988IFmzpypG264QVlZgXtKTJ48WR6PR9OmTdPWrVv18ssv64knnggZIoo4AgwAnHLCsbrmVGDHeWx1gPn44481YsQIjRgxQpI0a9YsjRgxQvfff7/cbrc2bdqkK6+8UmeeeaamTZumkSNH6p///Ke8Xq91jMWLF+uss87S6NGjNWHCBF1yySUh13hJTEzUO++8o127dmnkyJG6++67df/993ecJdSS5GEVEgCcKmJiYiRJ1dXVEe5J1xA8j8Hz2hYu00XjpM/nU2JioiorK52ZD1O0VHrxeilrhDTjPfuPDwDoUEpKSlRRUaG0tDTFx8fL5XJFukudjjFG1dXVKi8vV1JSkjW95Ggt/fvNvZDaiivxAsApJbiI5NiFKGi9pKSkZhfltBQBpq2YAwMApxSXy6XMzEylpaWFLDJB68TExMjtdrf7OASYtiLAAMApye122/IHGO3j+DLqLisYYOoPSv7GyPYFAIBTDAGmrYIBRqIKAwBAmBFg2iraK7kP32ySAAMAQFgRYNrDw/2QAACIBAJMe3i6BZ7ruLARAADhRIBpDyvAUIEBACCcCDDtEQww9VRgAAAIJwJMe8TEB57rDka2HwAAnGIIMO3BJF4AACKCANMeTOIFACAiCDDt4WEICQCASCDAtAdDSAAARAQBpj1YhQQAQEQQYNqDVUgAAEQEAaY9rCEkAgwAAOFEgGkPaxUSAQYAgHAiwLQHq5AAAIgIAkx7BIeQ6gkwAACEEwGmPRhCAgAgIggw7cEqJAAAIoIA0x7WKiSuAwMAQDgRYNrDGkKqkoyJbF8AADiFEGDaI7gKyTRKDbWR7QsAAKcQAkx7BOfASNxOAACAMCLAtIc7RoqKDryuPxTZvgAAcAohwLRXsArTUBPZfgAAcAohwLRXdGzgmSEkAADChgDTXjFxged6KjAAAIQLAaa9rABDBQYAgHAhwLRXMMAwBwYAgLAhwLRXcBIvFRgAAMKGANNe1iReKjAAAIQLAaa9mAMDAEDYEWDaizkwAACEHQGmvajAAAAQdgSY9ooOBhhuJQAAQLgQYNqLC9kBABB2rQ4wq1at0qRJk5SVlSWXy6XXXnvN2ldfX6/Zs2dr6NCh6tatm7KysnTzzTdr7969Icfo27evXC5XyOPhhx8OabNp0yZdeumlio2NVXZ2thYuXNi2X+g0hpAAAAi7VgeYgwcPavjw4XrqqaeO21ddXa0NGzboN7/5jTZs2KBXXnlFRUVFuvLKK49rO3/+fJWUlFiPn/3sZ9Y+n8+nsWPHqk+fPlq/fr0WLVqkuXPn6plnnmltd53HJF4AAMIuurUfGD9+vMaPH9/kvsTERBUUFIRs+6//+i9dcMEFKi4uVu/eva3tPXr0UEZGRpPHWbx4serq6vTss8/K4/HonHPOUWFhoR599FHNmDGjtV12VjQVGAAAws3xOTCVlZVyuVxKSkoK2f7www+rZ8+eGjFihBYtWqSGhgZr3+rVq3XZZZfJ4/FY2/Ly8lRUVKRvv/22ye+pra2Vz+cLeYQFc2AAAAi7VldgWqOmpkazZ8/WjTfeqISEBGv7v//7v+u8885TSkqKPvzwQ82ZM0clJSV69NFHJUmlpaXq169fyLHS09OtfcnJycd914IFCzRv3jwHf00zmAMDAEDYORZg6uvr9W//9m8yxujpp58O2Tdr1izr9bBhw+TxePSTn/xECxYskNfrbdP3zZkzJ+S4Pp9P2dnZbet8azAHBgCAsHMkwATDyxdffKEVK1aEVF+akpOTo4aGBu3evVuDBg1SRkaGysrKQtoE3zc3b8br9bY5/LRLDNeBAQAg3GyfAxMML9u3b9eyZcvUs2fPk36msLBQUVFRSktLkyTl5uZq1apVqq+vt9oUFBRo0KBBTQ4fRRQXsgMAIOxaXYGpqqrSjh07rPe7du1SYWGhUlJSlJmZqeuuu04bNmzQkiVL1NjYqNLSUklSSkqKPB6PVq9erTVr1uiKK65Qjx49tHr1at1111360Y9+ZIWTyZMna968eZo2bZpmz56tLVu26IknntBjjz1m08+2ERUYAADCzmWMMa35wHvvvacrrrjiuO1Tp07V3Llzj5t8G/Tuu+/q8ssv14YNG/TTn/5Un332mWpra9WvXz/ddNNNmjVrVsgQ0KZNm5Sfn69169YpNTVVP/vZzzR79uwW99Pn8ykxMVGVlZUnHcJql6+LpKcukOKSpdm7nfseAABOAS39+93qANNZhC3AVBRLjw+VomOl+8pO3h4AADSrpX+/uRdSe0UftQrJ749sXwAAOEUQYNorOAdGYik1AABhQoBpr6MDDBN5AQAICwJMe0W5JffhWx40EGAAAAgHAowdWEoNAEBYEWDswMXsAAAIKwKMHajAAAAQVgQYO1g3dCTAAAAQDgQYO1CBAQAgrAgwdmAODAAAYUWAsQMVGAAAwooAY4eY2MBzfXVk+wEAwCmCAGOHmPjAM7cSAAAgLAgwdogOVmAYQgIAIBwIMHYIVmAIMAAAhAUBxg5M4gUAIKwIMHbgQnYAAIQVAcYOVGAAAAgrAowdmMQLAEBYEWDswCReAADCigBjh+CF7LgODAAAYUGAsYNVgeFKvAAAhAMBxg7MgQEAIKwIMHZgDgwAAGFFgLFDtDfw3FAb2X4AAHCKIMDYIZpJvAAAhBMBxg5UYAAACCsCjB2owAAAEFYEGDsEKzCmUWpsiGxfAAA4BRBg7BCswEhUYQAACAMCjB2CFRiJeTAAAIQBAcYOUW4pKibwmgoMAACOI8DYhYm8AACEDQHGLiylBgAgbAgwdqECAwBA2BBg7EIFBgCAsCHA2CUmLvBMBQYAAMcRYOxCBQYAgLAhwNiFOTAAAIQNAcYuVGAAAAibVgeYVatWadKkScrKypLL5dJrr70Wst8Yo/vvv1+ZmZmKi4vTmDFjtH379pA2+/fv15QpU5SQkKCkpCRNmzZNVVVVIW02bdqkSy+9VLGxscrOztbChQtb/+vCiQoMAABh0+oAc/DgQQ0fPlxPPfVUk/sXLlyo3/3ud/rDH/6gNWvWqFu3bsrLy1NNzZE/7FOmTNHWrVtVUFCgJUuWaNWqVZoxY4a13+fzaezYserTp4/Wr1+vRYsWae7cuXrmmWfa8BPDhAoMAADhY9pBknn11Vet936/32RkZJhFixZZ2yoqKozX6zUvvviiMcaYbdu2GUlm3bp1Vpu3337buFwu89VXXxljjPn9739vkpOTTW1trdVm9uzZZtCgQS3uW2VlpZFkKisr2/rzWueVnxjzQIIx7z8Rnu8DAKALaunfb1vnwOzatUulpaUaM2aMtS0xMVE5OTlavXq1JGn16tVKSkrSqFGjrDZjxoxRVFSU1qxZY7W57LLL5PF4rDZ5eXkqKirSt99+2+R319bWyufzhTzCigoMAABhY2uAKS0tlSSlp6eHbE9PT7f2lZaWKi0tLWR/dHS0UlJSQto0dYyjv+NYCxYsUGJiovXIzs5u/w9qDebAAAAQNl1mFdKcOXNUWVlpPfbs2RPeDlgVGAIMAABOszXAZGRkSJLKyspCtpeVlVn7MjIyVF5eHrK/oaFB+/fvD2nT1DGO/o5jeb1eJSQkhDzCyqrAMIQEAIDTbA0w/fr1U0ZGhpYvX25t8/l8WrNmjXJzcyVJubm5qqio0Pr16602K1askN/vV05OjtVm1apVqq+vt9oUFBRo0KBBSk5OtrPL9rEqMIci2w8AAE4BrQ4wVVVVKiwsVGFhoaTAxN3CwkIVFxfL5XLpzjvv1H/8x3/ojTfe0ObNm3XzzTcrKytLV199tSTp7LPP1rhx4zR9+nStXbtWH3zwgWbOnKkbbrhBWVlZkqTJkyfL4/Fo2rRp2rp1q15++WU98cQTmjVrlm0/3HZUYAAACJvo1n7g448/1hVXXGG9D4aKqVOn6vnnn9cvfvELHTx4UDNmzFBFRYUuueQSLV26VLGxsdZnFi9erJkzZ2r06NGKiorStddeq9/97nfW/sTERL3zzjvKz8/XyJEjlZqaqvvvvz/kWjEdDnNgAAAIG5cxxkS6E07w+XxKTExUZWVleObDbPyL9Hq+NHCsNOVvzn8fAABdUEv/fneZVUgRxzJqAADChgBjFy5kBwBA2BBg7EIFBgCAsCHA2IUKDAAAYUOAsQsVGAAAwoYAYxcqMAAAhA0Bxi5UYAAACBsCjF2owAAAEDYEGLscXYHpmtcGBACgwyDA2CVYgTF+yd8Q2b4AANDFEWDsEn3kXk/MgwEAwFkEGLu4vUdeMw8GAABHEWDsEhV1JMRQgQEAwFEEGDtZE3mpwAAA4CQCjJ2iqcAAABAOBBg7cTE7AADCggBjJy5mBwBAWBBg7EQFBgCAsCDA2IkKDAAAYUGAsRMVGAAAwoIAYycqMAAAhAUBxk5UYAAACAsCjJ2owAAAEBYEGDtRgQEAICwIMHYKVmDqCTAAADiJAGMnKjAAAIQFAcZOzIEBACAsCDB2ogIDAEBYEGDsRAUGAICwIMDYyarAHIpsPwAA6OIIMHaiAgMAQFgQYOwUrMA01kW2HwAAdHEEGDtZFRgm8QIA4CQCjJ0YQgIAICwIMHayJvESYAAAcBIBxk5uT+CZAAMAgKMIMHbiQnYAAIQFAcZOwTkwrEICAMBRBBg7sQoJAICwIMDYiVVIAACEhe0Bpm/fvnK5XMc98vPzJUmXX375cftuv/32kGMUFxdr4sSJio+PV1pamu699141NDTY3VX7MQcGAICwiLb7gOvWrVNjY6P1fsuWLfre976nH/7wh9a26dOna/78+db7+Ph463VjY6MmTpyojIwMffjhhyopKdHNN9+smJgYPfTQQ3Z3117uwxUYf4Pkb5Si3JHtDwAAXZTtAaZXr14h7x9++GH1799f3/nOd6xt8fHxysjIaPLz77zzjrZt26Zly5YpPT1d5557rh588EHNnj1bc+fOlcfjsbvL9gkOIUmBYSRPfPNtAQBAmzk6B6aurk5/+ctfdNttt8nlclnbFy9erNTUVA0ZMkRz5sxRdXW1tW/16tUaOnSo0tPTrW15eXny+XzaunVrs99VW1srn88X8gi74BCSxDASAAAOsr0Cc7TXXntNFRUVuuWWW6xtkydPVp8+fZSVlaVNmzZp9uzZKioq0iuvvCJJKi0tDQkvkqz3paWlzX7XggULNG/ePPt/RGu4oyWXWzKNLKUGAMBBjgaYP/3pTxo/fryysrKsbTNmzLBeDx06VJmZmRo9erR27typ/v37t/m75syZo1mzZlnvfT6fsrOz23y8Nov2SvXVVGAAAHCQY0NIX3zxhZYtW6Yf//jHJ2yXk5MjSdqxY4ckKSMjQ2VlZSFtgu+bmzcjSV6vVwkJCSGPiGApNQAAjnMswDz33HNKS0vTxIkTT9iusLBQkpSZmSlJys3N1ebNm1VeXm61KSgoUEJCggYPHuxUd+3DDR0BAHCcI0NIfr9fzz33nKZOnaro6CNfsXPnTr3wwguaMGGCevbsqU2bNumuu+7SZZddpmHDhkmSxo4dq8GDB+umm27SwoULVVpaqvvuu0/5+fnyer3NfWXHwQ0dAQBwnCMBZtmyZSouLtZtt90Wst3j8WjZsmV6/PHHdfDgQWVnZ+vaa6/VfffdZ7Vxu91asmSJ7rjjDuXm5qpbt26aOnVqyHVjOjQuZgcAgOMcCTBjx46VMea47dnZ2Vq5cuVJP9+nTx+99dZbTnTNedYNHanAAADgFO6FZDcm8QIA4DgCjN0YQgIAwHEEGLtZFRguZAcAgFMIMHYL3tCRCgwAAI4hwNiNOTAAADiOAGM35sAAAOA4Aozdog9fyI6bOQIA4BgCjN2owAAA4DgCjN2YAwMAgOMIMHZzE2AAAHAaAcZu0SyjBgDAaQQYu1lzYKjAAADgFAKM3biZIwAAjiPA2I1JvAAAOI4AYzeWUQMA4DgCjN24mSMAAI4jwNiNmzkCAOA4AozdmAMDAIDjCDB2C86BYRUSAACOIcDYLXgzRyowAAA4hgBjN1YhAQDgOAKM3bgSLwAAjiPA2M3NEBIAAE4jwNjt6Em8xkS2LwAAdFEEGLsFl1FLVGEAAHAIAcZuRwcYllIDAOAIAozdgnNgJCowAAA4hABjN5eLpdQAADiMAOMEbugIAICjCDBO4IaOAAA4igDjBC5mBwCAowgwTggOIbEKCQAARxBgnBDNEBIAAE4iwDjBCjBUYAAAcAIBxgnMgQEAwFEEGCdwQ0cAABxFgHECF7IDAMBRBBgnMAcGAABHEWCcwDJqAAAcRYBxAsuoAQBwlO0BZu7cuXK5XCGPs846y9pfU1Oj/Px89ezZU927d9e1116rsrKykGMUFxdr4sSJio+PV1pamu699141NDTY3VXnsAoJAABHRTtx0HPOOUfLli078iXRR77mrrvu0ptvvqm//e1vSkxM1MyZM/WDH/xAH3zwgSSpsbFREydOVEZGhj788EOVlJTo5ptvVkxMjB566CEnums/ViEBAOAoRwJMdHS0MjIyjtteWVmpP/3pT3rhhRf03e9+V5L03HPP6eyzz9ZHH32kCy+8UO+88462bdumZcuWKT09Xeeee64efPBBzZ49W3PnzpXH43Giy/aiAgMAgKMcmQOzfft2ZWVl6YwzztCUKVNUXFwsSVq/fr3q6+s1ZswYq+1ZZ52l3r17a/Xq1ZKk1atXa+jQoUpPT7fa5OXlyefzaevWrc1+Z21trXw+X8gjYlhGDQCAo2wPMDk5OXr++ee1dOlSPf3009q1a5cuvfRSHThwQKWlpfJ4PEpKSgr5THp6ukpLSyVJpaWlIeEluD+4rzkLFixQYmKi9cjOzrb3h7WGtQqpLnJ9AACgC7N9CGn8+PHW62HDhiknJ0d9+vTRX//6V8XFxdn9dZY5c+Zo1qxZ1nufzxe5EMMqJAAAHOX4MuqkpCSdeeaZ2rFjhzIyMlRXV6eKioqQNmVlZdacmYyMjONWJQXfNzWvJsjr9SohISHkETFcyA4AAEc5HmCqqqq0c+dOZWZmauTIkYqJidHy5cut/UVFRSouLlZubq4kKTc3V5s3b1Z5ebnVpqCgQAkJCRo8eLDT3bUHk3gBAHCU7UNI99xzjyZNmqQ+ffpo7969euCBB+R2u3XjjTcqMTFR06ZN06xZs5SSkqKEhAT97Gc/U25uri688EJJ0tixYzV48GDddNNNWrhwoUpLS3XfffcpPz9fXq/X7u46g2XUAAA4yvYA8+WXX+rGG2/Uvn371KtXL11yySX66KOP1KtXL0nSY489pqioKF177bWqra1VXl6efv/731ufd7vdWrJkie644w7l5uaqW7dumjp1qubPn293V53DKiQAABzlMsaYSHfCCT6fT4mJiaqsrLR9Pkyj3yjKJblcrqYb7Fgu/eUHUsZQ6fb3bf1uAAC6spb+/eZeSK30WMHnuujh5fr4i2+bb8QkXgAAHEWAaaUvvz2kMl+tXi/8qvlGDCEBAOAoAkwrXXVuliTpzU0lqm/0N92ICgwAAI4iwLTSRf17KrW7R99W1+v9Hd803chNgAEAwEkEmFaKdkdp3JDABfWWbStrphEBBgAAJxFg2mDM2YF7My37tExNLuI6eg5M11zkBQBARBFg2iC3f09187hV5qvVlq+auOt19OEL2clI/oaw9g0AgFMBAaYNvNFu5fZPlaSm58EEKzASK5EAAHAAAaaNLh7QU5L04c4mAoz7qFseMA8GAADbEWDa6KLDFZh1u/ertqExdGdUFPdDAgDAQQSYNjozvbt6dvOopt6vLV9VHt/AWkrNEBIAAHYjwLSRy+XSiN7JkqSNxRXHN2ApNQAAjiHAtMOI3kmSpI17Ko7fGZzI20iAAQDAbgSYdhiRnSRJKmyyAsMcGAAAnEKAaYdh2UlyuaSvKg7pm6pjggo3dAQAwDEEmHbo7o1Wn5R4SdKnJcdc0M6aA1MX5l4BAND1EWDa6ezMBElNBBhWIQEA4BgCTDsdCTAHQnewCgkAAMcQYNppcHMVGObAAADgGAJMO52V2UOStKO8SvWN/iM7ohlCAgDAKQSYdspKjFNcjFsNfqPi/dVHdsTEBZ4JMAAA2I4A005RUS71T+smSdpZXnVkR3AIqZ4AAwCA3QgwNhjQq7skacfXTQSYhkMR6BEAAF0bAcYG/Q8HmJ3lB49sjAkGGFYhAQBgNwKMDQakNVWBOTwHpp4KDAAAdiPA2KBfr8AcmC/2NVWBYQ4MAAB2I8DYoPfh2wlUVNer8lB9YKM1iZcKDAAAdiPA2CDeE63U7oHrvuwJLqWOZg4MAABOIcDYJDslMOfFCjDWdWCowAAAYDcCjE2Cw0jWxeyCV+LlOjAAANiOAGOT4wMMV+IFAMApBBibZB8bYFiFBACAYwgwNglWYI6bxMsqJAAAbEeAsUkwwHz57SE1+g2rkAAAcBABxibpCbHyuKPU4DcqqTzEKiQAABxEgLGJO8ql05MDoaV4fzV3owYAwEEEGBtZE3n3VYfejdqYCPYKAICuhwBjo5Cl1MFVSJLUWBehHgEA0DURYGwUEmCC14GRWIkEAIDNCDA2ykoKhJaSyhrJHSPJFdjBtWAAALCV7QFmwYIFOv/889WjRw+lpaXp6quvVlFRUUibyy+/XC6XK+Rx++23h7QpLi7WxIkTFR8fr7S0NN17771qaGiwu7u2ykwKDBuVVBySXK6jViIRYAAAsFO03QdcuXKl8vPzdf7556uhoUG/+tWvNHbsWG3btk3dunWz2k2fPl3z58+33sfHx1uvGxsbNXHiRGVkZOjDDz9USUmJbr75ZsXExOihhx6yu8u2yUoMBJayA7Vq9Bu5o2Ol+mpWIgEAYDPbA8zSpUtD3j///PNKS0vT+vXrddlll1nb4+PjlZGR0eQx3nnnHW3btk3Lli1Tenq6zj33XD344IOaPXu25s6dK4/HY3e3bdGrh1fRUS41+I3KD9Qo8+iVSAAAwDaOz4GprKyUJKWkpIRsX7x4sVJTUzVkyBDNmTNH1dXV1r7Vq1dr6NChSk9Pt7bl5eXJ5/Np69atTX5PbW2tfD5fyCPc3FEupScEQsveikNH3Q+Jq/ECAGAn2yswR/P7/brzzjt18cUXa8iQIdb2yZMnq0+fPsrKytKmTZs0e/ZsFRUV6ZVXXpEklZaWhoQXSdb70tLSJr9rwYIFmjdvnkO/pOUyE2P1VcUh7a2o0cjgSiRWIQEAYCtHA0x+fr62bNmi999/P2T7jBkzrNdDhw5VZmamRo8erZ07d6p///5t+q45c+Zo1qxZ1nufz6fs7Oy2dbwdspLipC++Db2dAAEGAABbOTaENHPmTC1ZskTvvvuuTj/99BO2zcnJkSTt2LFDkpSRkaGysrKQNsH3zc2b8Xq9SkhICHlEQnAl0t6KmqMCTPUJPgEAAFrL9gBjjNHMmTP16quvasWKFerXr99JP1NYWChJyszMlCTl5uZq8+bNKi8vt9oUFBQoISFBgwcPtrvLtgquRApUYA6vrKICAwCArWwfQsrPz9cLL7yg119/XT169LDmrCQmJiouLk47d+7UCy+8oAkTJqhnz57atGmT7rrrLl122WUaNmyYJGns2LEaPHiwbrrpJi1cuFClpaW67777lJ+fL6/Xa3eXbZWZePhaMJU1UnowwFCBAQDATrZXYJ5++mlVVlbq8ssvV2ZmpvV4+eWXJUkej0fLli3T2LFjddZZZ+nuu+/Wtddeq3/84x/WMdxut5YsWSK3263c3Fz96Ec/0s033xxy3ZiOKng13sAQ0kkCTGODVPllmHoGAEDXYXsFxpzkzsvZ2dlauXLlSY/Tp08fvfXWW3Z1K2yCFZhvqmrV6I6VW2p+CGn5XOnDJ6XvPy6NujVMPQQAoPPjXkg2S+nmkTc6cFoPmsPDXXUHm2784ZOB5yV3St9+4XznAADoIggwNnO5XFYVxtdwuMDVVAWmen/o+3+963DPAADoOggwDsg8vBKp4kQB5qsNoe/LP3O4VwAAdB0EGAcErwWzry4msKG+iSGkrz4Off/1pw73CgCAroMA44DTDq9E+qb28OltqgITnPNy1vcDz18XhaFnAAB0DQQYBwSHkMprThBgqr8JPPe5OPB8oEQ6VOF85wAA6AIIMA4IDiGVVB8+vU2tQqreF3hO7islnBZ4/c125zsHAEAXQIBxgHU7gYOuwIamKjAHD1dg4ntKSb0Dryv3hKF3AAB0fgQYBwQrMN/UugMbmroSb3AZdbfUIxUY31dh6B0AAJ0fAcYBCbEx6u6NVrUOX8ju2ADTUCvVHQi8jk+REg8HmEoCDAAALUGAcUhmYqwOWQHmmCGk4PwXl1uKTZISTg+893FfJAAAWoIA45CspDgdMp7Am/pq6eh7RAUDTHxPyeU6qgJDgAEAoCUIMA7JSopTTbACY/yBYaOg4ATebqmB5wSGkAAAaA0CjENOS4rVIXmObDh6HszRFRhJSjw8hHSwPDToAACAJhFgHJKVFKcGRatBTdwP6dgAE99Tig6sXJJvb/g6CQBAJ0WAcUjW4dsJ1DS1EunYAONysZQaAIBWIMA4JHg/pCpzOMDUVR3ZefRF7IJYSg0AQIsRYBySnhArl0s6YAJBRrVHBZhgBSY4iVdiKTUAAK1AgHGIJzpKvbp7VaVggDlwZOexQ0gSS6kBAGgFAoyDspLiVGUOT849WYBhKTUAAC1GgHHQaUlxR1VgfEd2NDkHJjiERIABAOBkCDAOykqKVZU5ZgjJmGbmwDCEBABASxFgHJQVUoE5HGBqKiTTGHjdVAWmpkKqOxiuLgIA0CkRYByUlRSnA8EAE1xGXb0/8OzpIUV7jzSOTZC8CYHXzIMBAOCECDAOOi0p7vghJGsCb8rxH7AuZscwEgAAJ0KAcVBgCClektRYc3gS77E3cjwaF7MDAKBFCDAOSo6PUa07EGDqDlYGNja1hDqIibwAALQIAcZBLpdLsd2SJEkN1cEAE1xC3VQFhqvxAgDQEgQYhyUkBea6+INDSC2ZA8MQEgAAJ0SAcVjS4QDjrj+8CungCYaQErkjNQAALUGAcViv1MBQUUzD4Wu7NHURu6DE7MBzxR7J7w9D7wAA6JwIMA5L7xUIKl5TIzU2HDUHpokKTFJvyeWWGg5JB0rC2EsAADoXAozDTktPt16b2gNHzYFpogLjjpGS+wRe798Zht4BANA5EWAcdlpqog4cvpjd1+VfnXgOjCT1HBB43keAAQCgOQQYh8W4o1TpTpYklX6xXao7fEXeboEA887WUv38pY36/z7crUa/kVL6B/ZTgQEAoFnRke7AqaDGkyrV7NXBL7cENrjckjdRH/1rn366eIMa/EavF+7V3spDmtPzcIChAgMAQLOowISBv3uaJCnq622BDfE9ZVwuzf/HNjX4jaJcgc3/vfJf+rSuV+DNN59HoKcAAHQOBJgw8CZlSJKSq3YENsT31Ibib7WtxCdvdJTW3/c93XhBb0nS/I8PF8X27ZBqKiPRXQAAOjwCTBj0SA3cIuDMhsNVlcTT9NLaPZKkK4dnKbmbR/eMPVM9YqO1utSlqrjDF7TbWxiB3gIA0PERYMIgKe30kPcNyWdo6dZSSdIPRwUuXtezu1c/Hz1QkrS6JlCN0Vfrjz9Y0VLpL9dJfxwjFTxwZFUTAACnkA4dYJ566in17dtXsbGxysnJ0dq1ayPdpTaJ6pER8n57Q7oO1DQoIyFWo/okW9tvzu2rM1K7aW1dv8CGLz8OPdC7D0kvXi/tKJC+XCd98Lj035dJZVtP3omKYulfK6WSTZK/sZ2/CACAyOqwAebll1/WrFmz9MADD2jDhg0aPny48vLyVF5eHumutd7hSbxBb34VuC7M94dlKio4g1eSJzpK933/bH3oP0eS5N+xXAreBHLt/5VW/laStLPfZL3Z/37tj82WfF/K/8exMtuXNf3dX3wYqNY8PlT685XSf18q/Z9B0or/lA6U2fxDAQAIjw4bYB599FFNnz5dt956qwYPHqw//OEPio+P17PPPhvprrVeQugQ0ut74uRySTfl9jmu6RWD0tRzwPna4c9SVGONKtf/XfWfviXz9i8kSY/5r9foT7+v/K1n6YqK3+gj/9mKqq9S4+If6h9/nK/3PitTTX2jVPW19Ood0nPjpS/XyURFqz55gBpjekgHv5ZWLZR5fIj0Wn7LKjgAAHQgLmOMiXQnjlVXV6f4+Hj9/e9/19VXX21tnzp1qioqKvT6668f95na2lrV1tZa730+n7Kzs1VZWamEhIRwdPvEnh0nFa+WJJ1R8xeNG5ql308Z2WTTf31dpSVP3aN/14sh2//a8B39omGGzkjtrksGpsolafvefbqu5BH9IGqVJGmTv59KTE9d6t6ieNXIL5f+2vhd/Z/6a/W1khStBn0var2mR7+p86J2WMfeHZWtYndvVStefrlk3UrSSC4ZSUYulxQlI7eM4lSjeB1SvAk84ky1Ys0hxZoaGblU5/Kq3hVz+NmjOnkCz67gc2B7vStGcrlCfmfou+A202wbV1PtXE3vP/Kzjmx1uULfH/tJ19GfOea4Rq7QTx51rKaOGNK0iQaupj7V5IFOdnQ7tOM72vzRtn0wzF/XZif+uub/pzjM3WzRNx7732QLP9bGb2vfJ5vsa4fVmfoqJV/yY/U/9zJbj+nz+ZSYmHjSv98d8kJ233zzjRobG5V+1H2EJCk9PV2fffZZk59ZsGCB5s2bF47utc01f5D/j9/TJxqk2y8cqJ9eMaDZpmf06q4JP56nz5/foDMbiiRJ77guVtH58/XGyL4aelqiXEf99TtUe7G2v/mw+m5+QsOidmmYdkkKhJn7629VoQl8V1yMW928Xv2z/mItrcvRCH2u26Lf1vioterr36O+/j22/VyPqe9s/x0CAFrp468ulWwOMC3VISswe/fu1WmnnaYPP/xQubm51vZf/OIXWrlypdasWXPcZzp8BUaSGusDN2xsqZpK+db/TXU9stVzyBi5otwnbn+gVGb7O6ryfavy7ueoInWE4jwxSoqPUXK8R3GeI5/3+42q6hpUWV2vqn175d9bqNjKnYr218slf+D/sbiOqiS4XDJG8itKRi7Vu+NUH91N9e54NUR3s143RsdLxq+oxtqjHjXWs7uxVq7D293+wPOxjv43sqm6y9HbQisn5vhtIcdq9sDH7w8eyxz5f29H73WZ47cd3fmm/qNq6r8001zKM812s+kD2cio9f+PtU09CsP/9Lhk2vw14fofxpD+NVWWa+ozbfqisHykTcLxe0wLzy1aJ/PCH6r/OefbesxOXYFJTU2V2+1WWVnoJNOysjJlZGQ0+Rmv1yuv1xuO7rVda8KLJMUmKuHiH7e8fY8Muc67WT0k9ThJ06golxJiY5QQGyOlDJAGNl8RAgCgo+mQk3g9Ho9Gjhyp5cuXW9v8fr+WL18eUpEBAACnpg5ZgZGkWbNmaerUqRo1apQuuOACPf744zp48KBuvfXWSHcNAABEWIcNMNdff72+/vpr3X///SotLdW5556rpUuXHjexFwAAnHo65CReO7R0EhAAAOg4Wvr3u0POgQEAADgRAgwAAOh0CDAAAKDTIcAAAIBOhwADAAA6HQIMAADodAgwAACg0yHAAACATocAAwAAOp0OeyuB9gpeYNjn80W4JwAAoKWCf7dPdqOALhtgDhw4IEnKzs6OcE8AAEBrHThwQImJic3u77L3QvL7/dq7d6969Oghl8tlyzF9Pp+ys7O1Z88e7q/kMM51eHCew4dzHR6c5/Bw8jwbY3TgwAFlZWUpKqr5mS5dtgITFRWl008/3ZFjJyQk8B9GmHCuw4PzHD6c6/DgPIeHU+f5RJWXICbxAgCATocAAwAAOh0CTCt4vV498MAD8nq9ke5Kl8e5Dg/Oc/hwrsOD8xweHeE8d9lJvAAAoOuiAgMAADodAgwAAOh0CDAAAKDTIcAAAIBOhwDTCk899ZT69u2r2NhY5eTkaO3atZHuUqeyatUqTZo0SVlZWXK5XHrttddC9htjdP/99yszM1NxcXEaM2aMtm/fHtJm//79mjJlihISEpSUlKRp06apqqoqjL+i41uwYIHOP/989ejRQ2lpabr66qtVVFQU0qampkb5+fnq2bOnunfvrmuvvVZlZWUhbYqLizVx4kTFx8crLS1N9957rxoaGsL5Uzq8p59+WsOGDbMu5pWbm6u3337b2s95dsbDDz8sl8ulO++809rGuW6/uXPnyuVyhTzOOussa3+HO8cGLfLSSy8Zj8djnn32WbN161Yzffp0k5SUZMrKyiLdtU7jrbfeMr/+9a/NK6+8YiSZV199NWT/ww8/bBITE81rr71mPvnkE3PllVeafv36mUOHDlltxo0bZ4YPH24++ugj889//tMMGDDA3HjjjWH+JR1bXl6eee6558yWLVtMYWGhmTBhgundu7epqqqy2tx+++0mOzvbLF++3Hz88cfmwgsvNBdddJG1v6GhwQwZMsSMGTPGbNy40bz11lsmNTXVzJkzJxI/qcN64403zJtvvmk+//xzU1RUZH71q1+ZmJgYs2XLFmMM59kJa9euNX379jXDhg0zP//5z63tnOv2e+CBB8w555xjSkpKrMfXX39t7e9o55gA00IXXHCByc/Pt943NjaarKwss2DBggj2qvM6NsD4/X6TkZFhFi1aZG2rqKgwXq/XvPjii8YYY7Zt22YkmXXr1llt3n77beNyucxXX30Vtr53NuXl5UaSWblypTEmcF5jYmLM3/72N6vNp59+aiSZ1atXG2MCYTMqKsqUlpZabZ5++mmTkJBgamtrw/sDOpnk5GTzxz/+kfPsgAMHDpiBAweagoIC853vfMcKMJxrezzwwANm+PDhTe7riOeYIaQWqKur0/r16zVmzBhrW1RUlMaMGaPVq1dHsGddx65du1RaWhpyjhMTE5WTk2Od49WrVyspKUmjRo2y2owZM0ZRUVFas2ZN2PvcWVRWVkqSUlJSJEnr169XfX19yLk+66yz1Lt375BzPXToUKWnp1tt8vLy5PP5tHXr1jD2vvNobGzUSy+9pIMHDyo3N5fz7ID8/HxNnDgx5JxK/Dttp+3btysrK0tnnHGGpkyZouLiYkkd8xx32Zs52umbb75RY2NjyD8USUpPT9dnn30WoV51LaWlpZLU5DkO7istLVVaWlrI/ujoaKWkpFhtEMrv9+vOO+/UxRdfrCFDhkgKnEePx6OkpKSQtsee66b+WQT34YjNmzcrNzdXNTU16t69u1599VUNHjxYhYWFnGcbvfTSS9qwYYPWrVt33D7+nbZHTk6Onn/+eQ0aNEglJSWaN2+eLr30Um3ZsqVDnmMCDNCF5efna8uWLXr//fcj3ZUua9CgQSosLFRlZaX+/ve/a+rUqVq5cmWku9Wl7NmzRz//+c9VUFCg2NjYSHenyxo/frz1etiwYcrJyVGfPn3017/+VXFxcRHsWdMYQmqB1NRUud3u42Zbl5WVKSMjI0K96lqC5/FE5zgjI0Pl5eUh+xsaGrR//37+OTRh5syZWrJkid59912dfvrp1vaMjAzV1dWpoqIipP2x57qpfxbBfTjC4/FowIABGjlypBYsWKDhw4friSee4DzbaP369SovL9d5552n6OhoRUdHa+XKlfrd736n6Ohopaenc64dkJSUpDPPPFM7duzokP8+E2BawOPxaOTIkVq+fLm1ze/3a/ny5crNzY1gz7qOfv36KSMjI+Qc+3w+rVmzxjrHubm5qqio0Pr16602K1askN/vV05OTtj73FEZYzRz5ky9+uqrWrFihfr16xeyf+TIkYqJiQk510VFRSouLg4515s3bw4JjAUFBUpISNDgwYPD80M6Kb/fr9raWs6zjUaPHq3NmzersLDQeowaNUpTpkyxXnOu7VdVVaWdO3cqMzOzY/77bPu04C7qpZdeMl6v1zz//PNm27ZtZsaMGSYpKSlktjVO7MCBA2bjxo1m48aNRpJ59NFHzcaNG80XX3xhjAkso05KSjKvv/662bRpk7nqqquaXEY9YsQIs2bNGvP++++bgQMHsoz6GHfccYdJTEw07733XshyyOrqaqvN7bffbnr37m1WrFhhPv74Y5Obm2tyc3Ot/cHlkGPHjjWFhYVm6dKlplevXiw5PcYvf/lLs3LlSrNr1y6zadMm88tf/tK4XC7zzjvvGGM4z046ehWSMZxrO9x9993mvffeM7t27TIffPCBGTNmjElNTTXl5eXGmI53jgkwrfDkk0+a3r17G4/HYy644ALz0UcfRbpLncq7775rJB33mDp1qjEmsJT6N7/5jUlPTzder9eMHj3aFBUVhRxj37595sYbbzTdu3c3CQkJ5tZbbzUHDhyIwK/puJo6x5LMc889Z7U5dOiQ+elPf2qSk5NNfHy8ueaaa0xJSUnIcXbv3m3Gjx9v4uLiTGpqqrn77rtNfX19mH9Nx3bbbbeZPn36GI/HY3r16mVGjx5thRdjOM9OOjbAcK7b7/rrrzeZmZnG4/GY0047zVx//fVmx44d1v6Odo5dxhhjf10HAADAOcyBAQAAnQ4BBgAAdDoEGAAA0OkQYAAAQKdDgAEAAJ0OAQYAAHQ6BBgAANDpEGAAAECnQ4ABAACdDgEGAAB0OgQYAADQ6RBgAABAp/P/A5EYs4RnybJ2AAAAAElFTkSuQmCC","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["epoch_count = range(1, len(history1['loss']) + 1)\n","sns.lineplot(x=epoch_count,  y=history1['loss'], label='train')\n","sns.lineplot(x=epoch_count,  y=history1['val_loss'], label='valid')\n","plt.show()"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":291,"status":"ok","timestamp":1656680564721,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"88tdVCOyxcuy","outputId":"5475340d-3496-4955-a466-6d49170e2aea"},"outputs":[{"name":"stdout","output_type":"stream","text":["y_test: [11, 12]\n","y_hat: tensor([[11.1716, 12.0539]], grad_fn=<AddmmBackward0>)\n","loss: 0.4573024809360504\n"]},{"name":"stderr","output_type":"stream","text":["d:\\Users\\juanp_schamun\\Documents\\GitRepositories\\CEIA\\procesamiento_lenguaje_natural\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]}],"source":["# Ensayo\n","x_test = 10\n","y_test = [x_test + 1, x_test + 2]\n","test_input = np.array([x_test])\n","test_input = test_input.reshape((1, seq_length, input_size))\n","test_input = torch.from_numpy(test_input.astype(np.float32))\n","\n","test_target = torch.from_numpy(np.array(y_test).astype(np.int32)).float().view(-1, 1)\n","\n","y_hat = model1(test_input)\n","\n","print(\"y_test:\", y_test)\n","print(\"y_hat:\", y_hat)\n","\n","loss = model1_criterion(y_hat, test_target).item()\n","print(\"loss:\", loss)"]},{"cell_type":"markdown","metadata":{"id":"AT8b9EfGyshD"},"source":["### 3 - Multi-layer LSTM"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1656681111689,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"1xVfTMScdFqR","outputId":"b1126586-0c0e-42c4-d77b-119c677fbe81"},"outputs":[{"data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","Model2                                   [1, 2]                    --\n","├─CustomLSTM: 1-1                        [1, 1, 64]                16,896\n","├─CustomLSTM: 1-4                        --                        (recursive)\n","│    └─Sigmoid: 2-1                      [1, 64]                   --\n","│    └─Sigmoid: 2-2                      [1, 64]                   --\n","├─CustomLSTM: 1-5                        --                        (recursive)\n","│    └─ReLU: 2-3                         [1, 64]                   --\n","├─CustomLSTM: 1-4                        --                        (recursive)\n","│    └─Sigmoid: 2-4                      [1, 64]                   --\n","├─CustomLSTM: 1-5                        --                        (recursive)\n","│    └─ReLU: 2-5                         [1, 64]                   --\n","├─CustomLSTM: 1-6                        [1, 1, 64]                33,024\n","│    └─Sigmoid: 2-6                      [1, 64]                   --\n","│    └─Sigmoid: 2-7                      [1, 64]                   --\n","│    └─ReLU: 2-8                         [1, 64]                   --\n","│    └─Sigmoid: 2-9                      [1, 64]                   --\n","│    └─ReLU: 2-10                        [1, 64]                   --\n","├─Linear: 1-7                            [1, 2]                    130\n","==========================================================================================\n","Total params: 50,050\n","Trainable params: 50,050\n","Non-trainable params: 0\n","Total mult-adds (Units.MEGABYTES): 0.00\n","==========================================================================================\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.00\n","Estimated Total Size (MB): 0.00\n","=========================================================================================="]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["from torch_helpers import CustomLSTM\n","\n","# En esta oportunidad se utilizarán dos layer LSTM\n","class Model2(nn.Module):\n","    def __init__(self, input_size, output_dim):\n","        super().__init__()\n","\n","        self.lstm1 = CustomLSTM(input_size=input_size, hidden_size=64, activation=nn.ReLU()) # LSTM layer\n","        self.lstm2 = CustomLSTM(input_size=64, hidden_size=64, activation=nn.ReLU()) # LSTM layer\n","        self.fc = nn.Linear(in_features=64, out_features=output_dim) #  # Fully connected layer\n","        \n","    def forward(self, x):\n","        lstm_output, _ = self.lstm1(x)\n","        lstm_output, _ = self.lstm2(lstm_output)\n","        out = self.fc(lstm_output[:,-1,:]) # take last output (last seq)\n","        return out\n","\n","model2 = Model2(input_size=input_size, output_dim=output_dim)\n","\n","# Crear el optimizador la una función de error\n","model2_optimizer = torch.optim.Adam(model2.parameters(), lr=0.01)\n","model2_criterion = nn.MSELoss()  # mean squared error\n","\n","summary(model2, input_size=(1, seq_length, input_size))"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2666,"status":"ok","timestamp":1656681133235,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"jtoKCzXrei60","outputId":"d0ed5b25-7774-4f0e-8097-4f333dabf6a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1/500 - Train loss 467.598 - Valid Loss 1709.727\n","Epoch: 2/500 - Train loss 463.414 - Valid Loss 1687.175\n","Epoch: 3/500 - Train loss 458.040 - Valid Loss 1650.086\n","Epoch: 4/500 - Train loss 449.783 - Valid Loss 1583.337\n","Epoch: 5/500 - Train loss 435.823 - Valid Loss 1469.646\n","Epoch: 6/500 - Train loss 412.395 - Valid Loss 1295.293\n","Epoch: 7/500 - Train loss 375.383 - Valid Loss 1058.281\n","Epoch: 8/500 - Train loss 321.707 - Valid Loss 775.773\n","Epoch: 9/500 - Train loss 251.206 - Valid Loss 476.871\n","Epoch: 10/500 - Train loss 169.264 - Valid Loss 201.293\n","Epoch: 11/500 - Train loss 87.447 - Valid Loss 19.359\n","Epoch: 12/500 - Train loss 24.891 - Valid Loss 60.612\n","Epoch: 13/500 - Train loss 11.843 - Valid Loss 368.619\n","Epoch: 14/500 - Train loss 62.978 - Valid Loss 535.252\n","Epoch: 15/500 - Train loss 97.301 - Valid Loss 446.657\n","Epoch: 16/500 - Train loss 82.606 - Valid Loss 259.280\n","Epoch: 17/500 - Train loss 47.589 - Valid Loss 100.376\n","Epoch: 18/500 - Train loss 18.429 - Valid Loss 17.294\n","Epoch: 19/500 - Train loss 5.160 - Valid Loss 0.822\n","Epoch: 20/500 - Train loss 5.711 - Valid Loss 21.126\n","Epoch: 21/500 - Train loss 13.466 - Valid Loss 51.412\n","Epoch: 22/500 - Train loss 22.356 - Valid Loss 73.850\n","Epoch: 23/500 - Train loss 28.466 - Valid Loss 81.459\n","Epoch: 24/500 - Train loss 30.348 - Valid Loss 73.354\n","Epoch: 25/500 - Train loss 27.845 - Valid Loss 53.721\n","Epoch: 26/500 - Train loss 21.992 - Valid Loss 29.307\n","Epoch: 27/500 - Train loss 14.475 - Valid Loss 8.777\n","Epoch: 28/500 - Train loss 7.463 - Valid Loss 0.460\n","Epoch: 29/500 - Train loss 3.160 - Valid Loss 8.935\n","Epoch: 30/500 - Train loss 3.005 - Valid Loss 30.241\n","Epoch: 31/500 - Train loss 6.450 - Valid Loss 50.927\n","Epoch: 32/500 - Train loss 10.516 - Valid Loss 58.924\n","Epoch: 33/500 - Train loss 12.248 - Valid Loss 51.546\n","Epoch: 34/500 - Train loss 10.825 - Valid Loss 34.471\n","Epoch: 35/500 - Train loss 7.429 - Valid Loss 16.484\n","Epoch: 36/500 - Train loss 4.010 - Valid Loss 4.288\n","Epoch: 37/500 - Train loss 2.037 - Valid Loss 0.088\n","Epoch: 38/500 - Train loss 1.917 - Valid Loss 1.997\n","Epoch: 39/500 - Train loss 3.077 - Valid Loss 5.992\n","Epoch: 40/500 - Train loss 4.463 - Valid Loss 8.741\n","Epoch: 41/500 - Train loss 5.264 - Valid Loss 8.836\n","Epoch: 42/500 - Train loss 5.171 - Valid Loss 6.565\n","Epoch: 43/500 - Train loss 4.309 - Valid Loss 3.304\n","Epoch: 44/500 - Train loss 3.078 - Valid Loss 0.750\n","Epoch: 45/500 - Train loss 1.961 - Valid Loss 0.166\n","Epoch: 46/500 - Train loss 1.331 - Valid Loss 1.834\n","Epoch: 47/500 - Train loss 1.313 - Valid Loss 4.931\n","Epoch: 48/500 - Train loss 1.747 - Valid Loss 7.937\n","Epoch: 49/500 - Train loss 2.282 - Valid Loss 9.408\n","Epoch: 50/500 - Train loss 2.566 - Valid Loss 8.778\n","Epoch: 51/500 - Train loss 2.441 - Valid Loss 6.510\n","Epoch: 52/500 - Train loss 1.992 - Valid Loss 3.692\n","Epoch: 53/500 - Train loss 1.455 - Valid Loss 1.411\n","Epoch: 54/500 - Train loss 1.068 - Valid Loss 0.251\n","Epoch: 55/500 - Train loss 0.946 - Valid Loss 0.164\n","Epoch: 56/500 - Train loss 1.055 - Valid Loss 0.662\n","Epoch: 57/500 - Train loss 1.261 - Valid Loss 1.176\n","Epoch: 58/500 - Train loss 1.417 - Valid Loss 1.326\n","Epoch: 59/500 - Train loss 1.429 - Valid Loss 1.043\n","Epoch: 60/500 - Train loss 1.291 - Valid Loss 0.528\n","Epoch: 61/500 - Train loss 1.069 - Valid Loss 0.105\n","Epoch: 62/500 - Train loss 0.858 - Valid Loss 0.028\n","Epoch: 63/500 - Train loss 0.739 - Valid Loss 0.344\n","Epoch: 64/500 - Train loss 0.733 - Valid Loss 0.881\n","Epoch: 65/500 - Train loss 0.806 - Valid Loss 1.346\n","Epoch: 66/500 - Train loss 0.885 - Valid Loss 1.502\n","Epoch: 67/500 - Train loss 0.906 - Valid Loss 1.288\n","Epoch: 68/500 - Train loss 0.850 - Valid Loss 0.837\n","Epoch: 69/500 - Train loss 0.742 - Valid Loss 0.379\n","Epoch: 70/500 - Train loss 0.634 - Valid Loss 0.102\n","Epoch: 71/500 - Train loss 0.568 - Valid Loss 0.068\n","Epoch: 72/500 - Train loss 0.558 - Valid Loss 0.208\n","Epoch: 73/500 - Train loss 0.584 - Valid Loss 0.387\n","Epoch: 74/500 - Train loss 0.613 - Valid Loss 0.485\n","Epoch: 75/500 - Train loss 0.616 - Valid Loss 0.454\n","Epoch: 76/500 - Train loss 0.585 - Valid Loss 0.328\n","Epoch: 77/500 - Train loss 0.531 - Valid Loss 0.185\n","Epoch: 78/500 - Train loss 0.477 - Valid Loss 0.096\n","Epoch: 79/500 - Train loss 0.443 - Valid Loss 0.087\n","Epoch: 80/500 - Train loss 0.434 - Valid Loss 0.129\n","Epoch: 81/500 - Train loss 0.442 - Valid Loss 0.170\n","Epoch: 82/500 - Train loss 0.449 - Valid Loss 0.168\n","Epoch: 83/500 - Train loss 0.443 - Valid Loss 0.122\n","Epoch: 84/500 - Train loss 0.421 - Valid Loss 0.066\n","Epoch: 85/500 - Train loss 0.390 - Valid Loss 0.044\n","Epoch: 86/500 - Train loss 0.363 - Valid Loss 0.081\n","Epoch: 87/500 - Train loss 0.348 - Valid Loss 0.165\n","Epoch: 88/500 - Train loss 0.344 - Valid Loss 0.262\n","Epoch: 89/500 - Train loss 0.345 - Valid Loss 0.329\n","Epoch: 90/500 - Train loss 0.343 - Valid Loss 0.343\n","Epoch: 91/500 - Train loss 0.334 - Valid Loss 0.305\n","Epoch: 92/500 - Train loss 0.318 - Valid Loss 0.237\n","Epoch: 93/500 - Train loss 0.301 - Valid Loss 0.167\n","Epoch: 94/500 - Train loss 0.288 - Valid Loss 0.114\n","Epoch: 95/500 - Train loss 0.281 - Valid Loss 0.085\n","Epoch: 96/500 - Train loss 0.278 - Valid Loss 0.074\n","Epoch: 97/500 - Train loss 0.276 - Valid Loss 0.077\n","Epoch: 98/500 - Train loss 0.272 - Valid Loss 0.092\n","Epoch: 99/500 - Train loss 0.263 - Valid Loss 0.125\n","Epoch: 100/500 - Train loss 0.253 - Valid Loss 0.178\n","Epoch: 101/500 - Train loss 0.244 - Valid Loss 0.247\n","Epoch: 102/500 - Train loss 0.238 - Valid Loss 0.319\n","Epoch: 103/500 - Train loss 0.235 - Valid Loss 0.379\n","Epoch: 104/500 - Train loss 0.232 - Valid Loss 0.411\n","Epoch: 105/500 - Train loss 0.229 - Valid Loss 0.411\n","Epoch: 106/500 - Train loss 0.224 - Valid Loss 0.383\n","Epoch: 107/500 - Train loss 0.218 - Valid Loss 0.339\n","Epoch: 108/500 - Train loss 0.212 - Valid Loss 0.293\n","Epoch: 109/500 - Train loss 0.208 - Valid Loss 0.255\n","Epoch: 110/500 - Train loss 0.205 - Valid Loss 0.231\n","Epoch: 111/500 - Train loss 0.202 - Valid Loss 0.224\n","Epoch: 112/500 - Train loss 0.200 - Valid Loss 0.233\n","Epoch: 113/500 - Train loss 0.196 - Valid Loss 0.259\n","Epoch: 114/500 - Train loss 0.193 - Valid Loss 0.297\n","Epoch: 115/500 - Train loss 0.189 - Valid Loss 0.343\n","Epoch: 116/500 - Train loss 0.186 - Valid Loss 0.388\n","Epoch: 117/500 - Train loss 0.183 - Valid Loss 0.424\n","Epoch: 118/500 - Train loss 0.181 - Valid Loss 0.445\n","Epoch: 119/500 - Train loss 0.179 - Valid Loss 0.447\n","Epoch: 120/500 - Train loss 0.177 - Valid Loss 0.434\n","Epoch: 121/500 - Train loss 0.174 - Valid Loss 0.410\n","Epoch: 122/500 - Train loss 0.171 - Valid Loss 0.383\n","Epoch: 123/500 - Train loss 0.169 - Valid Loss 0.360\n","Epoch: 124/500 - Train loss 0.167 - Valid Loss 0.345\n","Epoch: 125/500 - Train loss 0.165 - Valid Loss 0.340\n","Epoch: 126/500 - Train loss 0.163 - Valid Loss 0.345\n","Epoch: 127/500 - Train loss 0.161 - Valid Loss 0.359\n","Epoch: 128/500 - Train loss 0.159 - Valid Loss 0.380\n","Epoch: 129/500 - Train loss 0.157 - Valid Loss 0.402\n","Epoch: 130/500 - Train loss 0.155 - Valid Loss 0.422\n","Epoch: 131/500 - Train loss 0.153 - Valid Loss 0.434\n","Epoch: 132/500 - Train loss 0.151 - Valid Loss 0.437\n","Epoch: 133/500 - Train loss 0.149 - Valid Loss 0.431\n","Epoch: 134/500 - Train loss 0.148 - Valid Loss 0.418\n","Epoch: 135/500 - Train loss 0.146 - Valid Loss 0.401\n","Epoch: 136/500 - Train loss 0.144 - Valid Loss 0.383\n","Epoch: 137/500 - Train loss 0.142 - Valid Loss 0.369\n","Epoch: 138/500 - Train loss 0.141 - Valid Loss 0.360\n","Epoch: 139/500 - Train loss 0.139 - Valid Loss 0.357\n","Epoch: 140/500 - Train loss 0.137 - Valid Loss 0.360\n","Epoch: 141/500 - Train loss 0.136 - Valid Loss 0.367\n","Epoch: 142/500 - Train loss 0.134 - Valid Loss 0.375\n","Epoch: 143/500 - Train loss 0.132 - Valid Loss 0.383\n","Epoch: 144/500 - Train loss 0.131 - Valid Loss 0.388\n","Epoch: 145/500 - Train loss 0.129 - Valid Loss 0.389\n","Epoch: 146/500 - Train loss 0.128 - Valid Loss 0.384\n","Epoch: 147/500 - Train loss 0.126 - Valid Loss 0.376\n","Epoch: 148/500 - Train loss 0.124 - Valid Loss 0.365\n","Epoch: 149/500 - Train loss 0.123 - Valid Loss 0.354\n","Epoch: 150/500 - Train loss 0.121 - Valid Loss 0.344\n","Epoch: 151/500 - Train loss 0.120 - Valid Loss 0.336\n","Epoch: 152/500 - Train loss 0.118 - Valid Loss 0.332\n","Epoch: 153/500 - Train loss 0.117 - Valid Loss 0.330\n","Epoch: 154/500 - Train loss 0.116 - Valid Loss 0.330\n","Epoch: 155/500 - Train loss 0.114 - Valid Loss 0.332\n","Epoch: 156/500 - Train loss 0.113 - Valid Loss 0.333\n","Epoch: 157/500 - Train loss 0.111 - Valid Loss 0.333\n","Epoch: 158/500 - Train loss 0.110 - Valid Loss 0.331\n","Epoch: 159/500 - Train loss 0.108 - Valid Loss 0.327\n","Epoch: 160/500 - Train loss 0.107 - Valid Loss 0.321\n","Epoch: 161/500 - Train loss 0.106 - Valid Loss 0.314\n","Epoch: 162/500 - Train loss 0.104 - Valid Loss 0.306\n","Epoch: 163/500 - Train loss 0.103 - Valid Loss 0.300\n","Epoch: 164/500 - Train loss 0.102 - Valid Loss 0.294\n","Epoch: 165/500 - Train loss 0.100 - Valid Loss 0.291\n","Epoch: 166/500 - Train loss 0.099 - Valid Loss 0.289\n","Epoch: 167/500 - Train loss 0.098 - Valid Loss 0.287\n","Epoch: 168/500 - Train loss 0.097 - Valid Loss 0.287\n","Epoch: 169/500 - Train loss 0.095 - Valid Loss 0.286\n","Epoch: 170/500 - Train loss 0.094 - Valid Loss 0.284\n","Epoch: 171/500 - Train loss 0.093 - Valid Loss 0.281\n","Epoch: 172/500 - Train loss 0.092 - Valid Loss 0.277\n","Epoch: 173/500 - Train loss 0.091 - Valid Loss 0.272\n","Epoch: 174/500 - Train loss 0.089 - Valid Loss 0.267\n","Epoch: 175/500 - Train loss 0.088 - Valid Loss 0.262\n","Epoch: 176/500 - Train loss 0.087 - Valid Loss 0.258\n","Epoch: 177/500 - Train loss 0.086 - Valid Loss 0.254\n","Epoch: 178/500 - Train loss 0.085 - Valid Loss 0.251\n","Epoch: 179/500 - Train loss 0.084 - Valid Loss 0.249\n","Epoch: 180/500 - Train loss 0.083 - Valid Loss 0.247\n","Epoch: 181/500 - Train loss 0.082 - Valid Loss 0.245\n","Epoch: 182/500 - Train loss 0.080 - Valid Loss 0.243\n","Epoch: 183/500 - Train loss 0.079 - Valid Loss 0.241\n","Epoch: 184/500 - Train loss 0.078 - Valid Loss 0.238\n","Epoch: 185/500 - Train loss 0.077 - Valid Loss 0.235\n","Epoch: 186/500 - Train loss 0.076 - Valid Loss 0.231\n","Epoch: 187/500 - Train loss 0.075 - Valid Loss 0.227\n","Epoch: 188/500 - Train loss 0.074 - Valid Loss 0.224\n","Epoch: 189/500 - Train loss 0.073 - Valid Loss 0.221\n","Epoch: 190/500 - Train loss 0.072 - Valid Loss 0.218\n","Epoch: 191/500 - Train loss 0.071 - Valid Loss 0.216\n","Epoch: 192/500 - Train loss 0.070 - Valid Loss 0.214\n","Epoch: 193/500 - Train loss 0.069 - Valid Loss 0.212\n","Epoch: 194/500 - Train loss 0.068 - Valid Loss 0.210\n","Epoch: 195/500 - Train loss 0.067 - Valid Loss 0.207\n","Epoch: 196/500 - Train loss 0.066 - Valid Loss 0.205\n","Epoch: 197/500 - Train loss 0.066 - Valid Loss 0.202\n","Epoch: 198/500 - Train loss 0.065 - Valid Loss 0.199\n","Epoch: 199/500 - Train loss 0.064 - Valid Loss 0.196\n","Epoch: 200/500 - Train loss 0.063 - Valid Loss 0.193\n","Epoch: 201/500 - Train loss 0.062 - Valid Loss 0.191\n","Epoch: 202/500 - Train loss 0.061 - Valid Loss 0.188\n","Epoch: 203/500 - Train loss 0.060 - Valid Loss 0.186\n","Epoch: 204/500 - Train loss 0.059 - Valid Loss 0.184\n","Epoch: 205/500 - Train loss 0.059 - Valid Loss 0.182\n","Epoch: 206/500 - Train loss 0.058 - Valid Loss 0.180\n","Epoch: 207/500 - Train loss 0.057 - Valid Loss 0.178\n","Epoch: 208/500 - Train loss 0.056 - Valid Loss 0.175\n","Epoch: 209/500 - Train loss 0.055 - Valid Loss 0.173\n","Epoch: 210/500 - Train loss 0.055 - Valid Loss 0.171\n","Epoch: 211/500 - Train loss 0.054 - Valid Loss 0.168\n","Epoch: 212/500 - Train loss 0.053 - Valid Loss 0.166\n","Epoch: 213/500 - Train loss 0.052 - Valid Loss 0.163\n","Epoch: 214/500 - Train loss 0.051 - Valid Loss 0.161\n","Epoch: 215/500 - Train loss 0.051 - Valid Loss 0.159\n","Epoch: 216/500 - Train loss 0.050 - Valid Loss 0.157\n","Epoch: 217/500 - Train loss 0.049 - Valid Loss 0.155\n","Epoch: 218/500 - Train loss 0.049 - Valid Loss 0.153\n","Epoch: 219/500 - Train loss 0.048 - Valid Loss 0.151\n","Epoch: 220/500 - Train loss 0.047 - Valid Loss 0.149\n","Epoch: 221/500 - Train loss 0.046 - Valid Loss 0.147\n","Epoch: 222/500 - Train loss 0.046 - Valid Loss 0.145\n","Epoch: 223/500 - Train loss 0.045 - Valid Loss 0.143\n","Epoch: 224/500 - Train loss 0.044 - Valid Loss 0.141\n","Epoch: 225/500 - Train loss 0.044 - Valid Loss 0.139\n","Epoch: 226/500 - Train loss 0.043 - Valid Loss 0.137\n","Epoch: 227/500 - Train loss 0.043 - Valid Loss 0.135\n","Epoch: 228/500 - Train loss 0.042 - Valid Loss 0.133\n","Epoch: 229/500 - Train loss 0.041 - Valid Loss 0.131\n","Epoch: 230/500 - Train loss 0.041 - Valid Loss 0.130\n","Epoch: 231/500 - Train loss 0.040 - Valid Loss 0.128\n","Epoch: 232/500 - Train loss 0.039 - Valid Loss 0.126\n","Epoch: 233/500 - Train loss 0.039 - Valid Loss 0.124\n","Epoch: 234/500 - Train loss 0.038 - Valid Loss 0.122\n","Epoch: 235/500 - Train loss 0.038 - Valid Loss 0.120\n","Epoch: 236/500 - Train loss 0.037 - Valid Loss 0.118\n","Epoch: 237/500 - Train loss 0.037 - Valid Loss 0.117\n","Epoch: 238/500 - Train loss 0.036 - Valid Loss 0.115\n","Epoch: 239/500 - Train loss 0.035 - Valid Loss 0.113\n","Epoch: 240/500 - Train loss 0.035 - Valid Loss 0.112\n","Epoch: 241/500 - Train loss 0.034 - Valid Loss 0.110\n","Epoch: 242/500 - Train loss 0.034 - Valid Loss 0.108\n","Epoch: 243/500 - Train loss 0.033 - Valid Loss 0.107\n","Epoch: 244/500 - Train loss 0.033 - Valid Loss 0.105\n","Epoch: 245/500 - Train loss 0.032 - Valid Loss 0.103\n","Epoch: 246/500 - Train loss 0.032 - Valid Loss 0.102\n","Epoch: 247/500 - Train loss 0.031 - Valid Loss 0.100\n","Epoch: 248/500 - Train loss 0.031 - Valid Loss 0.099\n","Epoch: 249/500 - Train loss 0.030 - Valid Loss 0.097\n","Epoch: 250/500 - Train loss 0.030 - Valid Loss 0.096\n","Epoch: 251/500 - Train loss 0.029 - Valid Loss 0.094\n","Epoch: 252/500 - Train loss 0.029 - Valid Loss 0.093\n","Epoch: 253/500 - Train loss 0.029 - Valid Loss 0.091\n","Epoch: 254/500 - Train loss 0.028 - Valid Loss 0.090\n","Epoch: 255/500 - Train loss 0.028 - Valid Loss 0.088\n","Epoch: 256/500 - Train loss 0.027 - Valid Loss 0.087\n","Epoch: 257/500 - Train loss 0.027 - Valid Loss 0.085\n","Epoch: 258/500 - Train loss 0.026 - Valid Loss 0.084\n","Epoch: 259/500 - Train loss 0.026 - Valid Loss 0.083\n","Epoch: 260/500 - Train loss 0.026 - Valid Loss 0.081\n","Epoch: 261/500 - Train loss 0.025 - Valid Loss 0.080\n","Epoch: 262/500 - Train loss 0.025 - Valid Loss 0.079\n","Epoch: 263/500 - Train loss 0.024 - Valid Loss 0.077\n","Epoch: 264/500 - Train loss 0.024 - Valid Loss 0.076\n","Epoch: 265/500 - Train loss 0.024 - Valid Loss 0.075\n","Epoch: 266/500 - Train loss 0.023 - Valid Loss 0.074\n","Epoch: 267/500 - Train loss 0.023 - Valid Loss 0.072\n","Epoch: 268/500 - Train loss 0.023 - Valid Loss 0.071\n","Epoch: 269/500 - Train loss 0.022 - Valid Loss 0.070\n","Epoch: 270/500 - Train loss 0.022 - Valid Loss 0.069\n","Epoch: 271/500 - Train loss 0.021 - Valid Loss 0.068\n","Epoch: 272/500 - Train loss 0.021 - Valid Loss 0.067\n","Epoch: 273/500 - Train loss 0.021 - Valid Loss 0.065\n","Epoch: 274/500 - Train loss 0.020 - Valid Loss 0.064\n","Epoch: 275/500 - Train loss 0.020 - Valid Loss 0.063\n","Epoch: 276/500 - Train loss 0.020 - Valid Loss 0.062\n","Epoch: 277/500 - Train loss 0.020 - Valid Loss 0.061\n","Epoch: 278/500 - Train loss 0.019 - Valid Loss 0.060\n","Epoch: 279/500 - Train loss 0.019 - Valid Loss 0.059\n","Epoch: 280/500 - Train loss 0.019 - Valid Loss 0.058\n","Epoch: 281/500 - Train loss 0.018 - Valid Loss 0.057\n","Epoch: 282/500 - Train loss 0.018 - Valid Loss 0.056\n","Epoch: 283/500 - Train loss 0.018 - Valid Loss 0.055\n","Epoch: 284/500 - Train loss 0.017 - Valid Loss 0.054\n","Epoch: 285/500 - Train loss 0.017 - Valid Loss 0.053\n","Epoch: 286/500 - Train loss 0.017 - Valid Loss 0.052\n","Epoch: 287/500 - Train loss 0.017 - Valid Loss 0.051\n","Epoch: 288/500 - Train loss 0.016 - Valid Loss 0.051\n","Epoch: 289/500 - Train loss 0.016 - Valid Loss 0.050\n","Epoch: 290/500 - Train loss 0.016 - Valid Loss 0.049\n","Epoch: 291/500 - Train loss 0.016 - Valid Loss 0.048\n","Epoch: 292/500 - Train loss 0.015 - Valid Loss 0.047\n","Epoch: 293/500 - Train loss 0.015 - Valid Loss 0.046\n","Epoch: 294/500 - Train loss 0.015 - Valid Loss 0.045\n","Epoch: 295/500 - Train loss 0.015 - Valid Loss 0.045\n","Epoch: 296/500 - Train loss 0.014 - Valid Loss 0.044\n","Epoch: 297/500 - Train loss 0.014 - Valid Loss 0.043\n","Epoch: 298/500 - Train loss 0.014 - Valid Loss 0.042\n","Epoch: 299/500 - Train loss 0.014 - Valid Loss 0.042\n","Epoch: 300/500 - Train loss 0.014 - Valid Loss 0.041\n","Epoch: 301/500 - Train loss 0.013 - Valid Loss 0.040\n","Epoch: 302/500 - Train loss 0.013 - Valid Loss 0.040\n","Epoch: 303/500 - Train loss 0.013 - Valid Loss 0.039\n","Epoch: 304/500 - Train loss 0.013 - Valid Loss 0.038\n","Epoch: 305/500 - Train loss 0.013 - Valid Loss 0.037\n","Epoch: 306/500 - Train loss 0.012 - Valid Loss 0.037\n","Epoch: 307/500 - Train loss 0.012 - Valid Loss 0.036\n","Epoch: 308/500 - Train loss 0.012 - Valid Loss 0.036\n","Epoch: 309/500 - Train loss 0.012 - Valid Loss 0.035\n","Epoch: 310/500 - Train loss 0.012 - Valid Loss 0.034\n","Epoch: 311/500 - Train loss 0.011 - Valid Loss 0.034\n","Epoch: 312/500 - Train loss 0.011 - Valid Loss 0.033\n","Epoch: 313/500 - Train loss 0.011 - Valid Loss 0.033\n","Epoch: 314/500 - Train loss 0.011 - Valid Loss 0.032\n","Epoch: 315/500 - Train loss 0.011 - Valid Loss 0.031\n","Epoch: 316/500 - Train loss 0.011 - Valid Loss 0.031\n","Epoch: 317/500 - Train loss 0.010 - Valid Loss 0.030\n","Epoch: 318/500 - Train loss 0.010 - Valid Loss 0.030\n","Epoch: 319/500 - Train loss 0.010 - Valid Loss 0.029\n","Epoch: 320/500 - Train loss 0.010 - Valid Loss 0.029\n","Epoch: 321/500 - Train loss 0.010 - Valid Loss 0.028\n","Epoch: 322/500 - Train loss 0.010 - Valid Loss 0.028\n","Epoch: 323/500 - Train loss 0.010 - Valid Loss 0.027\n","Epoch: 324/500 - Train loss 0.009 - Valid Loss 0.027\n","Epoch: 325/500 - Train loss 0.009 - Valid Loss 0.026\n","Epoch: 326/500 - Train loss 0.009 - Valid Loss 0.026\n","Epoch: 327/500 - Train loss 0.009 - Valid Loss 0.026\n","Epoch: 328/500 - Train loss 0.009 - Valid Loss 0.025\n","Epoch: 329/500 - Train loss 0.009 - Valid Loss 0.025\n","Epoch: 330/500 - Train loss 0.009 - Valid Loss 0.024\n","Epoch: 331/500 - Train loss 0.009 - Valid Loss 0.024\n","Epoch: 332/500 - Train loss 0.008 - Valid Loss 0.023\n","Epoch: 333/500 - Train loss 0.008 - Valid Loss 0.023\n","Epoch: 334/500 - Train loss 0.008 - Valid Loss 0.023\n","Epoch: 335/500 - Train loss 0.008 - Valid Loss 0.022\n","Epoch: 336/500 - Train loss 0.008 - Valid Loss 0.022\n","Epoch: 337/500 - Train loss 0.008 - Valid Loss 0.022\n","Epoch: 338/500 - Train loss 0.008 - Valid Loss 0.021\n","Epoch: 339/500 - Train loss 0.008 - Valid Loss 0.021\n","Epoch: 340/500 - Train loss 0.008 - Valid Loss 0.020\n","Epoch: 341/500 - Train loss 0.007 - Valid Loss 0.020\n","Epoch: 342/500 - Train loss 0.007 - Valid Loss 0.020\n","Epoch: 343/500 - Train loss 0.007 - Valid Loss 0.019\n","Epoch: 344/500 - Train loss 0.007 - Valid Loss 0.019\n","Epoch: 345/500 - Train loss 0.007 - Valid Loss 0.019\n","Epoch: 346/500 - Train loss 0.007 - Valid Loss 0.019\n","Epoch: 347/500 - Train loss 0.007 - Valid Loss 0.018\n","Epoch: 348/500 - Train loss 0.007 - Valid Loss 0.018\n","Epoch: 349/500 - Train loss 0.007 - Valid Loss 0.018\n","Epoch: 350/500 - Train loss 0.007 - Valid Loss 0.017\n","Epoch: 351/500 - Train loss 0.007 - Valid Loss 0.017\n","Epoch: 352/500 - Train loss 0.006 - Valid Loss 0.017\n","Epoch: 353/500 - Train loss 0.006 - Valid Loss 0.017\n","Epoch: 354/500 - Train loss 0.006 - Valid Loss 0.016\n","Epoch: 355/500 - Train loss 0.006 - Valid Loss 0.016\n","Epoch: 356/500 - Train loss 0.006 - Valid Loss 0.016\n","Epoch: 357/500 - Train loss 0.006 - Valid Loss 0.016\n","Epoch: 358/500 - Train loss 0.006 - Valid Loss 0.015\n","Epoch: 359/500 - Train loss 0.006 - Valid Loss 0.015\n","Epoch: 360/500 - Train loss 0.006 - Valid Loss 0.015\n","Epoch: 361/500 - Train loss 0.006 - Valid Loss 0.015\n","Epoch: 362/500 - Train loss 0.006 - Valid Loss 0.014\n","Epoch: 363/500 - Train loss 0.006 - Valid Loss 0.014\n","Epoch: 364/500 - Train loss 0.006 - Valid Loss 0.014\n","Epoch: 365/500 - Train loss 0.006 - Valid Loss 0.014\n","Epoch: 366/500 - Train loss 0.005 - Valid Loss 0.014\n","Epoch: 367/500 - Train loss 0.005 - Valid Loss 0.013\n","Epoch: 368/500 - Train loss 0.005 - Valid Loss 0.013\n","Epoch: 369/500 - Train loss 0.005 - Valid Loss 0.013\n","Epoch: 370/500 - Train loss 0.005 - Valid Loss 0.013\n","Epoch: 371/500 - Train loss 0.005 - Valid Loss 0.013\n","Epoch: 372/500 - Train loss 0.005 - Valid Loss 0.012\n","Epoch: 373/500 - Train loss 0.005 - Valid Loss 0.012\n","Epoch: 374/500 - Train loss 0.005 - Valid Loss 0.012\n","Epoch: 375/500 - Train loss 0.005 - Valid Loss 0.012\n","Epoch: 376/500 - Train loss 0.005 - Valid Loss 0.012\n","Epoch: 377/500 - Train loss 0.005 - Valid Loss 0.012\n","Epoch: 378/500 - Train loss 0.005 - Valid Loss 0.011\n","Epoch: 379/500 - Train loss 0.005 - Valid Loss 0.011\n","Epoch: 380/500 - Train loss 0.005 - Valid Loss 0.011\n","Epoch: 381/500 - Train loss 0.005 - Valid Loss 0.011\n","Epoch: 382/500 - Train loss 0.005 - Valid Loss 0.011\n","Epoch: 383/500 - Train loss 0.005 - Valid Loss 0.011\n","Epoch: 384/500 - Train loss 0.005 - Valid Loss 0.011\n","Epoch: 385/500 - Train loss 0.004 - Valid Loss 0.010\n","Epoch: 386/500 - Train loss 0.004 - Valid Loss 0.010\n","Epoch: 387/500 - Train loss 0.004 - Valid Loss 0.010\n","Epoch: 388/500 - Train loss 0.004 - Valid Loss 0.010\n","Epoch: 389/500 - Train loss 0.004 - Valid Loss 0.010\n","Epoch: 390/500 - Train loss 0.004 - Valid Loss 0.010\n","Epoch: 391/500 - Train loss 0.004 - Valid Loss 0.010\n","Epoch: 392/500 - Train loss 0.004 - Valid Loss 0.010\n","Epoch: 393/500 - Train loss 0.004 - Valid Loss 0.009\n","Epoch: 394/500 - Train loss 0.004 - Valid Loss 0.009\n","Epoch: 395/500 - Train loss 0.004 - Valid Loss 0.009\n","Epoch: 396/500 - Train loss 0.004 - Valid Loss 0.009\n","Epoch: 397/500 - Train loss 0.004 - Valid Loss 0.009\n","Epoch: 398/500 - Train loss 0.004 - Valid Loss 0.009\n","Epoch: 399/500 - Train loss 0.004 - Valid Loss 0.009\n","Epoch: 400/500 - Train loss 0.004 - Valid Loss 0.009\n","Epoch: 401/500 - Train loss 0.004 - Valid Loss 0.009\n","Epoch: 402/500 - Train loss 0.004 - Valid Loss 0.008\n","Epoch: 403/500 - Train loss 0.004 - Valid Loss 0.008\n","Epoch: 404/500 - Train loss 0.004 - Valid Loss 0.008\n","Epoch: 405/500 - Train loss 0.004 - Valid Loss 0.008\n","Epoch: 406/500 - Train loss 0.004 - Valid Loss 0.008\n","Epoch: 407/500 - Train loss 0.004 - Valid Loss 0.008\n","Epoch: 408/500 - Train loss 0.004 - Valid Loss 0.008\n","Epoch: 409/500 - Train loss 0.004 - Valid Loss 0.008\n","Epoch: 410/500 - Train loss 0.004 - Valid Loss 0.008\n","Epoch: 411/500 - Train loss 0.004 - Valid Loss 0.008\n","Epoch: 412/500 - Train loss 0.004 - Valid Loss 0.008\n","Epoch: 413/500 - Train loss 0.004 - Valid Loss 0.007\n","Epoch: 414/500 - Train loss 0.003 - Valid Loss 0.007\n","Epoch: 415/500 - Train loss 0.003 - Valid Loss 0.007\n","Epoch: 416/500 - Train loss 0.003 - Valid Loss 0.007\n","Epoch: 417/500 - Train loss 0.003 - Valid Loss 0.007\n","Epoch: 418/500 - Train loss 0.003 - Valid Loss 0.007\n","Epoch: 419/500 - Train loss 0.003 - Valid Loss 0.007\n","Epoch: 420/500 - Train loss 0.003 - Valid Loss 0.007\n","Epoch: 421/500 - Train loss 0.003 - Valid Loss 0.007\n","Epoch: 422/500 - Train loss 0.003 - Valid Loss 0.007\n","Epoch: 423/500 - Train loss 0.003 - Valid Loss 0.007\n","Epoch: 424/500 - Train loss 0.003 - Valid Loss 0.007\n","Epoch: 425/500 - Train loss 0.003 - Valid Loss 0.007\n","Epoch: 426/500 - Train loss 0.003 - Valid Loss 0.007\n","Epoch: 427/500 - Train loss 0.003 - Valid Loss 0.007\n","Epoch: 428/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 429/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 430/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 431/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 432/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 433/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 434/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 435/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 436/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 437/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 438/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 439/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 440/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 441/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 442/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 443/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 444/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 445/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 446/500 - Train loss 0.003 - Valid Loss 0.006\n","Epoch: 447/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 448/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 449/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 450/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 451/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 452/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 453/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 454/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 455/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 456/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 457/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 458/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 459/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 460/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 461/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 462/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 463/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 464/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 465/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 466/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 467/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 468/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 469/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 470/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 471/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 472/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 473/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 474/500 - Train loss 0.003 - Valid Loss 0.005\n","Epoch: 475/500 - Train loss 0.003 - Valid Loss 0.004\n","Epoch: 476/500 - Train loss 0.003 - Valid Loss 0.004\n","Epoch: 477/500 - Train loss 0.003 - Valid Loss 0.004\n","Epoch: 478/500 - Train loss 0.003 - Valid Loss 0.004\n","Epoch: 479/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 480/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 481/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 482/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 483/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 484/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 485/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 486/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 487/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 488/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 489/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 490/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 491/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 492/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 493/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 494/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 495/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 496/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 497/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 498/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 499/500 - Train loss 0.002 - Valid Loss 0.004\n","Epoch: 500/500 - Train loss 0.002 - Valid Loss 0.004\n"]}],"source":["history2 = train(model2,\n","                train_loader,\n","                valid_loader,\n","                model2_optimizer,\n","                model2_criterion,\n","                epochs=500\n","                )"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":1422,"status":"ok","timestamp":1656681148996,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"0KOSVDSBeo1A","outputId":"88a89fd2-fde5-4860-993a-0419c4dfa2c1"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["epoch_count = range(1, len(history2['loss']) + 1)\n","sns.lineplot(x=epoch_count,  y=history2['loss'], label='train')\n","sns.lineplot(x=epoch_count,  y=history2['val_loss'], label='valid')\n","plt.show()"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":400,"status":"ok","timestamp":1656681164007,"user":{"displayName":"Hernán Contigiani","userId":"01142101934719343059"},"user_tz":180},"id":"FveVOv2xzfkC","outputId":"fa6e8b2f-719d-436b-e19e-57c2c5a93850"},"outputs":[{"name":"stdout","output_type":"stream","text":["y_test: [11, 12]\n","y_hat: tensor([[11.0494, 12.0359]], grad_fn=<AddmmBackward0>)\n","loss: 0.4951225519180298\n"]},{"name":"stderr","output_type":"stream","text":["d:\\Users\\juanp_schamun\\Documents\\GitRepositories\\CEIA\\procesamiento_lenguaje_natural\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]}],"source":["# Ensayo\n","x_test = 10\n","y_test = [x_test + 1, x_test + 2]\n","test_input = np.array([x_test])\n","test_input = test_input.reshape((1, seq_length, input_size))\n","test_input = torch.from_numpy(test_input.astype(np.float32))\n","\n","test_target = torch.from_numpy(np.array(y_test).astype(np.int32)).float().view(-1, 1)\n","\n","y_hat = model2(test_input)\n","\n","print(\"y_test:\", y_test)\n","print(\"y_hat:\", y_hat)\n","\n","loss = model2_criterion(y_hat, test_target).item()\n","print(\"loss:\", loss)"]},{"cell_type":"markdown","metadata":{"id":"zd1g5MZfz5qB"},"source":["### 4 - Conclusión\n","La unica diferencia que se debe tener en cuenta cuando hay más de una salida es que la cantidad de neuronas de la última capa debe coincidir con el tamaño de la secuencia de salida.\n","En este ejemplo, donde el problema es más complejo, hubo una diferencia apreciable entre utilizar una sola capa o varias LSTM."]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP5Jfak4WbM+yEndU6ANyPU","collapsed_sections":[],"name":"4b - one-to-many.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
