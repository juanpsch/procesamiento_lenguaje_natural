{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEnBiuLcukJc"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## RNN one-to-one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i96B2RF8uqEb"
      },
      "source": [
        "#### Datos\n",
        "El objecto es utilizar una serie de sucuencias númericas (datos sintéticos) para poner a prueba el uso de las redes RNN. Este ejemplo se inspiró en otro artículo, lo tienen como referencia en el siguiente link:\\\n",
        "[LINK](https://stackabuse.com/solving-sequence-problems-with-lstm-in-keras/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Lx0HQ-1RvJw9"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yONnycbZ9kZ",
        "outputId": "a332a4e5-0a23-499a-f5bd-63598b9e0530"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Obtaining dependency information for torchinfo from https://files.pythonhosted.org/packages/72/25/973bd6128381951b23cdcd8a9870c6dcfc5606cb864df8eabd82e529f9c1/torchinfo-1.8.0-py3-none-any.whl.metadata\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "# torchsummar actualmente tiene un problema con las LSTM, por eso\n",
        "# se utiliza torchinfo, un fork del proyecto original con el bug solucionado\n",
        "!pip3 install torchinfo\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKC5SmeuTFPv",
        "outputId": "6996b8dc-23f9-4b7a-b9e8-f504c4a99625"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "curl: (3) URL using bad/illegal format or missing URL\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            " 34 23883   34  8226    0     0   8890      0  0:00:02 --:--:--  0:00:02  8921\n",
            "100 23883  100 23883    0     0  25025      0 --:--:-- --:--:-- --:--:-- 25113\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "if os.access('torch_helpers.py', os.F_OK) is False:\n",
        "    if platform.system() == 'Windows':\n",
        "        !curl !wget https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py > torch_helpers.py\n",
        "    else:\n",
        "        !wget torch_helpers.py https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YMFLzZx7cJET"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, valid_loader, optimizer, criterion, epochs=100):\n",
        "    # Defino listas para realizar graficas de los resultados\n",
        "    train_loss = []\n",
        "    valid_loss = []\n",
        "\n",
        "    # Defino mi loop de entrenamiento\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        epoch_train_loss = 0.0\n",
        "        epoch_train_accuracy = 0.0\n",
        "\n",
        "        for train_data, train_target in train_loader:\n",
        "\n",
        "            # Seteo los gradientes en cero ya que, por defecto, PyTorch\n",
        "            # los va acumulando\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(train_data)\n",
        "\n",
        "            # Computo el error de la salida comparando contra las etiquetas\n",
        "            loss = criterion(output, train_target)\n",
        "\n",
        "            # Almaceno el error del batch para luego tener el error promedio de la epoca\n",
        "            epoch_train_loss += loss.item()\n",
        "\n",
        "            # Computo el nuevo set de gradientes a lo largo de toda la red\n",
        "            loss.backward()\n",
        "\n",
        "            # Realizo el paso de optimizacion actualizando los parametros de toda la red\n",
        "            optimizer.step()\n",
        "\n",
        "        # Calculo la media de error para la epoca de entrenamiento.\n",
        "        # La longitud de train_loader es igual a la cantidad de batches dentro de una epoca.\n",
        "        epoch_train_loss = epoch_train_loss / len(train_loader)\n",
        "        train_loss.append(epoch_train_loss)\n",
        "\n",
        "        # Realizo el paso de validación computando error y accuracy, y\n",
        "        # almacenando los valores para imprimirlos y graficarlos\n",
        "        valid_data, valid_target = next(iter(valid_loader))\n",
        "        output = model(valid_data)\n",
        "        \n",
        "        epoch_valid_loss = criterion(output, valid_target).item()\n",
        "        valid_loss.append(epoch_valid_loss)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}/{epochs} - Train loss {epoch_train_loss:.3f} - Valid Loss {epoch_valid_loss:.3f}\")\n",
        "\n",
        "    history = {\n",
        "        \"loss\": train_loss,\n",
        "        \"val_loss\": valid_loss,\n",
        "    }\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10bFkG1YuaD9",
        "outputId": "3722e580-d7c1-4c8b-dff7-65f4fcb262e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "datos X: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "datos y: [15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 195, 210, 225, 240, 255, 270, 285, 300]\n"
          ]
        }
      ],
      "source": [
        "# Generar datos sintéticos\n",
        "X = list()\n",
        "y = list()\n",
        "X = [x+1 for x in range(20)]\n",
        "\n",
        "# \"y\" (target) se obtiene como cada dato de entrada multiplicado por 15\n",
        "y = [x * 15 for x in X]\n",
        "\n",
        "print(\"datos X:\", X)\n",
        "print(\"datos y:\", y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqabd-kYvza9",
        "outputId": "e6327459-cee3-41f1-a560-907d3d8abf53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "datos X: [[[ 1]]\n",
            "\n",
            " [[ 2]]\n",
            "\n",
            " [[ 3]]\n",
            "\n",
            " [[ 4]]\n",
            "\n",
            " [[ 5]]\n",
            "\n",
            " [[ 6]]\n",
            "\n",
            " [[ 7]]\n",
            "\n",
            " [[ 8]]\n",
            "\n",
            " [[ 9]]\n",
            "\n",
            " [[10]]\n",
            "\n",
            " [[11]]\n",
            "\n",
            " [[12]]\n",
            "\n",
            " [[13]]\n",
            "\n",
            " [[14]]\n",
            "\n",
            " [[15]]\n",
            "\n",
            " [[16]]\n",
            "\n",
            " [[17]]\n",
            "\n",
            " [[18]]\n",
            "\n",
            " [[19]]\n",
            "\n",
            " [[20]]]\n"
          ]
        }
      ],
      "source": [
        "# Cada dato X lo transformarmos en una matriz de 1 fila 1 columna (1x1)\n",
        "X = np.array(X).reshape(len(X), 1, 1)\n",
        "print(\"datos X:\", X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PytzYIMsUS1T",
        "outputId": "32c554b6-1483-4645-85f3-b89d4a9091b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20, 1, 1)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# (batch size, seq_len, input_size)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYz6XpuyxBbQ",
        "outputId": "ef9c900d-25a4-41dd-b0d0-3b4882d75ed2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20,)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = np.asanyarray(y)\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnrjCgx9TtOU",
        "outputId": "f92f58f5-033b-44f1-a73e-9ec59cfaf102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input dim torch.Size([1, 1])\n",
            "seq_length: 1\n",
            "input_size: 1\n",
            "Output dim 1\n"
          ]
        }
      ],
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        # Convertir los arrays de numpy a tensores. \n",
        "        # pytorch espera en general entradas 32bits\n",
        "        self.x = torch.from_numpy(x.astype(np.float32))\n",
        "        # las loss unfction esperan la salida float\n",
        "        self.y = torch.from_numpy(y.astype(np.int32)).float().view(-1, 1)\n",
        "\n",
        "        self.len = self.y.shape[0]\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "data_set = Data(X, y)\n",
        "\n",
        "input_dim = data_set.x.shape[1:]\n",
        "seq_length = input_dim[0]\n",
        "input_size = input_dim[1]\n",
        "print(\"Input dim\", input_dim)\n",
        "print(\"seq_length:\", seq_length)\n",
        "print(\"input_size:\", input_size)\n",
        "\n",
        "output_dim = data_set.y.shape[1]\n",
        "print(\"Output dim\", output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vggjoIXUIve",
        "outputId": "f67086aa-eb0b-4a5a-9c82-13b49b7faf24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 1, 1])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_set.x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjl1f2gXUVHU",
        "outputId": "c4f7028d-52eb-49b7-b5b8-3a29959becc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 1])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_set.y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j2mXBQhitKg",
        "outputId": "ba5c14b3-916a-452f-a044-263231b9e1e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamaño del conjunto de entrenamiento: 16\n",
            "Tamaño del conjunto de validacion: 4\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "valid_set_size = int(data_set.len * 0.2)\n",
        "train_set_size = data_set.len - valid_set_size\n",
        "\n",
        "# Cuando trabajmos con una serie temporal no mezclamos (shuffle) los datos\n",
        "train_set = torch.utils.data.Subset(data_set, range(train_set_size))\n",
        "valid_set = torch.utils.data.Subset(data_set, range(train_set_size, data_set.len))\n",
        "\n",
        "print(\"Tamaño del conjunto de entrenamiento:\", len(train_set))\n",
        "print(\"Tamaño del conjunto de validacion:\", len(valid_set))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=len(train_set), shuffle=False)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=len(valid_set), shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG3-d_NXwDGD"
      },
      "source": [
        "### 2 - Entrenar el modelo (RNN y LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwEo7Sb7fY_l",
        "outputId": "f37fa063-4679-4aba-f558-b755219bfded"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Model1                                   [1, 1]                    --\n",
              "├─CustomRNN: 1-1                         [1, 1, 64]                4,224\n",
              "│    └─ReLU: 2-1                         [1, 64]                   --\n",
              "├─Linear: 1-2                            [1, 1]                    65\n",
              "==========================================================================================\n",
              "Total params: 4,289\n",
              "Trainable params: 4,289\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch_helpers import CustomRNN\n",
        "\n",
        "class Model1(nn.Module):\n",
        "    def __init__(self, input_size, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        #self.rnn1 = nn.RNN(input_size=input_size, hidden_size=64, batch_first=True) # RNN layer\n",
        "        # Utilizamos la CustomRNN ya que para series temporales suele funcionar mejor\n",
        "        # la activacion \"relu\" en las RNN en vez de la \"tanh\", pero por defecto la\n",
        "        # layer de Pytorch RNN no permite modificar la funcion de activacion\n",
        "        #self.rnn1 = CustomRNN(input_size=input_size, hidden_size=64) # RNN layer\n",
        "        self.rnn1 = CustomRNN(input_size=input_size, hidden_size=64, activation=nn.ReLU()) # RNN layer\n",
        "        self.fc = nn.Linear(in_features=64, out_features=output_dim) #  # Fully connected layer\n",
        "        \n",
        "    def forward(self, x):\n",
        "        lstm_output, _ = self.rnn1(x)\n",
        "        out = self.fc(lstm_output[:,-1,:]) # take last output (last seq)\n",
        "        return out\n",
        "\n",
        "model1 = Model1(input_size=input_size, output_dim=output_dim)\n",
        "\n",
        "# Crear el optimizador la una función de error\n",
        "model1_optimizer = torch.optim.Adam(model1.parameters(), lr=0.01)\n",
        "model1_criterion = nn.MSELoss()  # mean squared error\n",
        "\n",
        "summary(model1, input_size=(1, seq_length, input_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJRYAPO6hlKO",
        "outputId": "aea4b31a-1981-4842-95e4-bc6c09a3b852"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/500 - Train loss 21055.309 - Valid Loss 76896.086\n",
            "Epoch: 2/500 - Train loss 20922.094 - Valid Loss 76426.508\n",
            "Epoch: 3/500 - Train loss 20790.615 - Valid Loss 75947.938\n",
            "Epoch: 4/500 - Train loss 20654.363 - Valid Loss 75444.773\n",
            "Epoch: 5/500 - Train loss 20511.916 - Valid Loss 74911.000\n",
            "Epoch: 6/500 - Train loss 20361.346 - Valid Loss 74343.531\n",
            "Epoch: 7/500 - Train loss 20200.094 - Valid Loss 73724.578\n",
            "Epoch: 8/500 - Train loss 20024.904 - Valid Loss 73053.656\n",
            "Epoch: 9/500 - Train loss 19835.967 - Valid Loss 72327.805\n",
            "Epoch: 10/500 - Train loss 19631.406 - Valid Loss 71543.961\n",
            "Epoch: 11/500 - Train loss 19410.629 - Valid Loss 70700.086\n",
            "Epoch: 12/500 - Train loss 19172.973 - Valid Loss 69792.797\n",
            "Epoch: 13/500 - Train loss 18917.514 - Valid Loss 68820.148\n",
            "Epoch: 14/500 - Train loss 18643.729 - Valid Loss 67781.375\n",
            "Epoch: 15/500 - Train loss 18351.445 - Valid Loss 66675.812\n",
            "Epoch: 16/500 - Train loss 18040.500 - Valid Loss 65503.141\n",
            "Epoch: 17/500 - Train loss 17710.822 - Valid Loss 64263.359\n",
            "Epoch: 18/500 - Train loss 17362.438 - Valid Loss 62956.758\n",
            "Epoch: 19/500 - Train loss 16995.451 - Valid Loss 61583.887\n",
            "Epoch: 20/500 - Train loss 16610.055 - Valid Loss 60145.586\n",
            "Epoch: 21/500 - Train loss 16206.518 - Valid Loss 58642.969\n",
            "Epoch: 22/500 - Train loss 15785.188 - Valid Loss 57077.500\n",
            "Epoch: 23/500 - Train loss 15346.514 - Valid Loss 55450.945\n",
            "Epoch: 24/500 - Train loss 14891.035 - Valid Loss 53765.512\n",
            "Epoch: 25/500 - Train loss 14419.415 - Valid Loss 52023.797\n",
            "Epoch: 26/500 - Train loss 13932.429 - Valid Loss 50228.848\n",
            "Epoch: 27/500 - Train loss 13430.982 - Valid Loss 48384.180\n",
            "Epoch: 28/500 - Train loss 12916.114 - Valid Loss 46493.781\n",
            "Epoch: 29/500 - Train loss 12388.997 - Valid Loss 44562.094\n",
            "Epoch: 30/500 - Train loss 11850.939 - Valid Loss 42594.047\n",
            "Epoch: 31/500 - Train loss 11303.381 - Valid Loss 40595.047\n",
            "Epoch: 32/500 - Train loss 10747.900 - Valid Loss 38570.930\n",
            "Epoch: 33/500 - Train loss 10186.198 - Valid Loss 36527.984\n",
            "Epoch: 34/500 - Train loss 9620.105 - Valid Loss 34472.918\n",
            "Epoch: 35/500 - Train loss 9051.567 - Valid Loss 32412.830\n",
            "Epoch: 36/500 - Train loss 8482.641 - Valid Loss 30355.180\n",
            "Epoch: 37/500 - Train loss 7915.480 - Valid Loss 28307.750\n",
            "Epoch: 38/500 - Train loss 7352.331 - Valid Loss 26278.604\n",
            "Epoch: 39/500 - Train loss 6795.514 - Valid Loss 24276.004\n",
            "Epoch: 40/500 - Train loss 6247.401 - Valid Loss 22308.391\n",
            "Epoch: 41/500 - Train loss 5710.410 - Valid Loss 20384.266\n",
            "Epoch: 42/500 - Train loss 5186.969 - Valid Loss 18512.143\n",
            "Epoch: 43/500 - Train loss 4679.494 - Valid Loss 16700.412\n",
            "Epoch: 44/500 - Train loss 4190.367 - Valid Loss 14957.269\n",
            "Epoch: 45/500 - Train loss 3721.895 - Valid Loss 13290.571\n",
            "Epoch: 46/500 - Train loss 3276.281 - Valid Loss 11707.730\n",
            "Epoch: 47/500 - Train loss 2855.584 - Valid Loss 10215.561\n",
            "Epoch: 48/500 - Train loss 2461.678 - Valid Loss 8820.139\n",
            "Epoch: 49/500 - Train loss 2096.208 - Valid Loss 7526.666\n",
            "Epoch: 50/500 - Train loss 1760.554 - Valid Loss 6339.307\n",
            "Epoch: 51/500 - Train loss 1455.780 - Valid Loss 5261.061\n",
            "Epoch: 52/500 - Train loss 1182.596 - Valid Loss 4293.623\n",
            "Epoch: 53/500 - Train loss 941.323 - Valid Loss 3437.276\n",
            "Epoch: 54/500 - Train loss 731.858 - Valid Loss 2690.821\n",
            "Epoch: 55/500 - Train loss 553.655 - Valid Loss 2051.505\n",
            "Epoch: 56/500 - Train loss 405.709 - Valid Loss 1515.048\n",
            "Epoch: 57/500 - Train loss 286.564 - Valid Loss 1075.685\n",
            "Epoch: 58/500 - Train loss 194.329 - Valid Loss 726.273\n",
            "Epoch: 59/500 - Train loss 126.715 - Valid Loss 458.474\n",
            "Epoch: 60/500 - Train loss 81.091 - Valid Loss 262.985\n",
            "Epoch: 61/500 - Train loss 54.552 - Valid Loss 129.824\n",
            "Epoch: 62/500 - Train loss 44.017 - Valid Loss 48.652\n",
            "Epoch: 63/500 - Train loss 46.317 - Valid Loss 9.125\n",
            "Epoch: 64/500 - Train loss 58.312 - Valid Loss 1.239\n",
            "Epoch: 65/500 - Train loss 76.986 - Valid Loss 15.659\n",
            "Epoch: 66/500 - Train loss 99.556 - Valid Loss 43.999\n",
            "Epoch: 67/500 - Train loss 123.546 - Valid Loss 79.046\n",
            "Epoch: 68/500 - Train loss 146.861 - Valid Loss 114.902\n",
            "Epoch: 69/500 - Train loss 167.822 - Valid Loss 147.052\n",
            "Epoch: 70/500 - Train loss 185.190 - Valid Loss 172.349\n",
            "Epoch: 71/500 - Train loss 198.153 - Valid Loss 188.931\n",
            "Epoch: 72/500 - Train loss 206.302 - Valid Loss 196.076\n",
            "Epoch: 73/500 - Train loss 209.583 - Valid Loss 194.016\n",
            "Epoch: 74/500 - Train loss 208.240 - Valid Loss 183.737\n",
            "Epoch: 75/500 - Train loss 202.749 - Valid Loss 166.750\n",
            "Epoch: 76/500 - Train loss 193.748 - Valid Loss 144.897\n",
            "Epoch: 77/500 - Train loss 181.978 - Valid Loss 120.154\n",
            "Epoch: 78/500 - Train loss 168.217 - Valid Loss 94.467\n",
            "Epoch: 79/500 - Train loss 153.234 - Valid Loss 69.633\n",
            "Epoch: 80/500 - Train loss 137.747 - Valid Loss 47.194\n",
            "Epoch: 81/500 - Train loss 122.392 - Valid Loss 28.383\n",
            "Epoch: 82/500 - Train loss 107.702 - Valid Loss 14.088\n",
            "Epoch: 83/500 - Train loss 94.100 - Valid Loss 4.850\n",
            "Epoch: 84/500 - Train loss 81.892 - Valid Loss 0.879\n",
            "Epoch: 85/500 - Train loss 71.274 - Valid Loss 2.085\n",
            "Epoch: 86/500 - Train loss 62.341 - Valid Loss 8.128\n",
            "Epoch: 87/500 - Train loss 55.097 - Valid Loss 18.462\n",
            "Epoch: 88/500 - Train loss 49.476 - Valid Loss 32.397\n",
            "Epoch: 89/500 - Train loss 45.351 - Valid Loss 49.144\n",
            "Epoch: 90/500 - Train loss 42.555 - Valid Loss 67.871\n",
            "Epoch: 91/500 - Train loss 40.896 - Valid Loss 87.743\n",
            "Epoch: 92/500 - Train loss 40.168 - Valid Loss 107.961\n",
            "Epoch: 93/500 - Train loss 40.162 - Valid Loss 127.791\n",
            "Epoch: 94/500 - Train loss 40.681 - Valid Loss 146.589\n",
            "Epoch: 95/500 - Train loss 41.543 - Valid Loss 163.813\n",
            "Epoch: 96/500 - Train loss 42.586 - Valid Loss 179.034\n",
            "Epoch: 97/500 - Train loss 43.675 - Valid Loss 191.936\n",
            "Epoch: 98/500 - Train loss 44.701 - Valid Loss 202.317\n",
            "Epoch: 99/500 - Train loss 45.580 - Valid Loss 210.079\n",
            "Epoch: 100/500 - Train loss 46.256 - Valid Loss 215.219\n",
            "Epoch: 101/500 - Train loss 46.696 - Valid Loss 217.818\n",
            "Epoch: 102/500 - Train loss 46.885 - Valid Loss 218.025\n",
            "Epoch: 103/500 - Train loss 46.828 - Valid Loss 216.045\n",
            "Epoch: 104/500 - Train loss 46.544 - Valid Loss 212.123\n",
            "Epoch: 105/500 - Train loss 46.062 - Valid Loss 206.532\n",
            "Epoch: 106/500 - Train loss 45.417 - Valid Loss 199.556\n",
            "Epoch: 107/500 - Train loss 44.649 - Valid Loss 191.486\n",
            "Epoch: 108/500 - Train loss 43.797 - Valid Loss 182.602\n",
            "Epoch: 109/500 - Train loss 42.902 - Valid Loss 173.170\n",
            "Epoch: 110/500 - Train loss 41.999 - Valid Loss 163.437\n",
            "Epoch: 111/500 - Train loss 41.120 - Valid Loss 153.621\n",
            "Epoch: 112/500 - Train loss 40.289 - Valid Loss 143.912\n",
            "Epoch: 113/500 - Train loss 39.528 - Valid Loss 134.471\n",
            "Epoch: 114/500 - Train loss 38.849 - Valid Loss 125.428\n",
            "Epoch: 115/500 - Train loss 38.261 - Valid Loss 116.886\n",
            "Epoch: 116/500 - Train loss 37.764 - Valid Loss 108.919\n",
            "Epoch: 117/500 - Train loss 37.357 - Valid Loss 101.576\n",
            "Epoch: 118/500 - Train loss 37.033 - Valid Loss 94.891\n",
            "Epoch: 119/500 - Train loss 36.783 - Valid Loss 88.871\n",
            "Epoch: 120/500 - Train loss 36.595 - Valid Loss 83.517\n",
            "Epoch: 121/500 - Train loss 36.458 - Valid Loss 78.812\n",
            "Epoch: 122/500 - Train loss 36.358 - Valid Loss 74.735\n",
            "Epoch: 123/500 - Train loss 36.284 - Valid Loss 71.256\n",
            "Epoch: 124/500 - Train loss 36.224 - Valid Loss 68.343\n",
            "Epoch: 125/500 - Train loss 36.170 - Valid Loss 65.960\n",
            "Epoch: 126/500 - Train loss 36.111 - Valid Loss 64.070\n",
            "Epoch: 127/500 - Train loss 36.044 - Valid Loss 62.638\n",
            "Epoch: 128/500 - Train loss 35.963 - Valid Loss 61.625\n",
            "Epoch: 129/500 - Train loss 35.866 - Valid Loss 60.997\n",
            "Epoch: 130/500 - Train loss 35.752 - Valid Loss 60.718\n",
            "Epoch: 131/500 - Train loss 35.622 - Valid Loss 60.755\n",
            "Epoch: 132/500 - Train loss 35.477 - Valid Loss 61.073\n",
            "Epoch: 133/500 - Train loss 35.319 - Valid Loss 61.639\n",
            "Epoch: 134/500 - Train loss 35.151 - Valid Loss 62.420\n",
            "Epoch: 135/500 - Train loss 34.976 - Valid Loss 63.382\n",
            "Epoch: 136/500 - Train loss 34.797 - Valid Loss 64.494\n",
            "Epoch: 137/500 - Train loss 34.616 - Valid Loss 65.722\n",
            "Epoch: 138/500 - Train loss 34.437 - Valid Loss 67.036\n",
            "Epoch: 139/500 - Train loss 34.261 - Valid Loss 68.404\n",
            "Epoch: 140/500 - Train loss 34.090 - Valid Loss 69.795\n",
            "Epoch: 141/500 - Train loss 33.925 - Valid Loss 71.183\n",
            "Epoch: 142/500 - Train loss 33.766 - Valid Loss 72.540\n",
            "Epoch: 143/500 - Train loss 33.613 - Valid Loss 73.840\n",
            "Epoch: 144/500 - Train loss 33.466 - Valid Loss 75.064\n",
            "Epoch: 145/500 - Train loss 33.325 - Valid Loss 76.189\n",
            "Epoch: 146/500 - Train loss 33.189 - Valid Loss 77.202\n",
            "Epoch: 147/500 - Train loss 33.057 - Valid Loss 78.088\n",
            "Epoch: 148/500 - Train loss 32.928 - Valid Loss 78.838\n",
            "Epoch: 149/500 - Train loss 32.801 - Valid Loss 79.445\n",
            "Epoch: 150/500 - Train loss 32.675 - Valid Loss 79.904\n",
            "Epoch: 151/500 - Train loss 32.549 - Valid Loss 80.217\n",
            "Epoch: 152/500 - Train loss 32.424 - Valid Loss 80.385\n",
            "Epoch: 153/500 - Train loss 32.298 - Valid Loss 80.412\n",
            "Epoch: 154/500 - Train loss 32.170 - Valid Loss 80.307\n",
            "Epoch: 155/500 - Train loss 32.042 - Valid Loss 80.077\n",
            "Epoch: 156/500 - Train loss 31.912 - Valid Loss 79.734\n",
            "Epoch: 157/500 - Train loss 31.782 - Valid Loss 79.289\n",
            "Epoch: 158/500 - Train loss 31.650 - Valid Loss 78.754\n",
            "Epoch: 159/500 - Train loss 31.517 - Valid Loss 78.143\n",
            "Epoch: 160/500 - Train loss 31.384 - Valid Loss 77.469\n",
            "Epoch: 161/500 - Train loss 31.250 - Valid Loss 76.744\n",
            "Epoch: 162/500 - Train loss 31.117 - Valid Loss 75.982\n",
            "Epoch: 163/500 - Train loss 30.983 - Valid Loss 75.195\n",
            "Epoch: 164/500 - Train loss 30.850 - Valid Loss 74.393\n",
            "Epoch: 165/500 - Train loss 30.717 - Valid Loss 73.589\n",
            "Epoch: 166/500 - Train loss 30.584 - Valid Loss 72.790\n",
            "Epoch: 167/500 - Train loss 30.453 - Valid Loss 72.005\n",
            "Epoch: 168/500 - Train loss 30.321 - Valid Loss 71.242\n",
            "Epoch: 169/500 - Train loss 30.191 - Valid Loss 70.506\n",
            "Epoch: 170/500 - Train loss 30.061 - Valid Loss 69.803\n",
            "Epoch: 171/500 - Train loss 29.931 - Valid Loss 69.137\n",
            "Epoch: 172/500 - Train loss 29.802 - Valid Loss 68.510\n",
            "Epoch: 173/500 - Train loss 29.673 - Valid Loss 67.924\n",
            "Epoch: 174/500 - Train loss 29.545 - Valid Loss 67.381\n",
            "Epoch: 175/500 - Train loss 29.417 - Valid Loss 66.880\n",
            "Epoch: 176/500 - Train loss 29.289 - Valid Loss 66.421\n",
            "Epoch: 177/500 - Train loss 29.161 - Valid Loss 66.002\n",
            "Epoch: 178/500 - Train loss 29.033 - Valid Loss 65.622\n",
            "Epoch: 179/500 - Train loss 28.905 - Valid Loss 65.278\n",
            "Epoch: 180/500 - Train loss 28.778 - Valid Loss 64.968\n",
            "Epoch: 181/500 - Train loss 28.650 - Valid Loss 64.687\n",
            "Epoch: 182/500 - Train loss 28.523 - Valid Loss 64.434\n",
            "Epoch: 183/500 - Train loss 28.395 - Valid Loss 64.204\n",
            "Epoch: 184/500 - Train loss 28.268 - Valid Loss 63.994\n",
            "Epoch: 185/500 - Train loss 28.141 - Valid Loss 63.800\n",
            "Epoch: 186/500 - Train loss 28.013 - Valid Loss 63.618\n",
            "Epoch: 187/500 - Train loss 27.887 - Valid Loss 63.446\n",
            "Epoch: 188/500 - Train loss 27.760 - Valid Loss 63.280\n",
            "Epoch: 189/500 - Train loss 27.633 - Valid Loss 63.117\n",
            "Epoch: 190/500 - Train loss 27.507 - Valid Loss 62.953\n",
            "Epoch: 191/500 - Train loss 27.381 - Valid Loss 62.788\n",
            "Epoch: 192/500 - Train loss 27.255 - Valid Loss 62.617\n",
            "Epoch: 193/500 - Train loss 27.130 - Valid Loss 62.439\n",
            "Epoch: 194/500 - Train loss 27.004 - Valid Loss 62.253\n",
            "Epoch: 195/500 - Train loss 26.879 - Valid Loss 62.058\n",
            "Epoch: 196/500 - Train loss 26.754 - Valid Loss 61.852\n",
            "Epoch: 197/500 - Train loss 26.630 - Valid Loss 61.634\n",
            "Epoch: 198/500 - Train loss 26.506 - Valid Loss 61.405\n",
            "Epoch: 199/500 - Train loss 26.381 - Valid Loss 61.164\n",
            "Epoch: 200/500 - Train loss 26.258 - Valid Loss 60.911\n",
            "Epoch: 201/500 - Train loss 26.134 - Valid Loss 60.647\n",
            "Epoch: 202/500 - Train loss 26.010 - Valid Loss 60.373\n",
            "Epoch: 203/500 - Train loss 25.887 - Valid Loss 60.089\n",
            "Epoch: 204/500 - Train loss 25.764 - Valid Loss 59.795\n",
            "Epoch: 205/500 - Train loss 25.641 - Valid Loss 59.494\n",
            "Epoch: 206/500 - Train loss 25.519 - Valid Loss 59.187\n",
            "Epoch: 207/500 - Train loss 25.396 - Valid Loss 58.873\n",
            "Epoch: 208/500 - Train loss 25.274 - Valid Loss 58.554\n",
            "Epoch: 209/500 - Train loss 25.152 - Valid Loss 58.233\n",
            "Epoch: 210/500 - Train loss 25.031 - Valid Loss 57.909\n",
            "Epoch: 211/500 - Train loss 24.909 - Valid Loss 57.583\n",
            "Epoch: 212/500 - Train loss 24.788 - Valid Loss 57.258\n",
            "Epoch: 213/500 - Train loss 24.668 - Valid Loss 56.933\n",
            "Epoch: 214/500 - Train loss 24.547 - Valid Loss 56.610\n",
            "Epoch: 215/500 - Train loss 24.427 - Valid Loss 56.288\n",
            "Epoch: 216/500 - Train loss 24.307 - Valid Loss 55.970\n",
            "Epoch: 217/500 - Train loss 24.187 - Valid Loss 55.655\n",
            "Epoch: 218/500 - Train loss 24.067 - Valid Loss 55.344\n",
            "Epoch: 219/500 - Train loss 23.948 - Valid Loss 55.037\n",
            "Epoch: 220/500 - Train loss 23.829 - Valid Loss 54.734\n",
            "Epoch: 221/500 - Train loss 23.710 - Valid Loss 54.436\n",
            "Epoch: 222/500 - Train loss 23.592 - Valid Loss 54.143\n",
            "Epoch: 223/500 - Train loss 23.474 - Valid Loss 53.853\n",
            "Epoch: 224/500 - Train loss 23.356 - Valid Loss 53.568\n",
            "Epoch: 225/500 - Train loss 23.238 - Valid Loss 53.287\n",
            "Epoch: 226/500 - Train loss 23.121 - Valid Loss 53.010\n",
            "Epoch: 227/500 - Train loss 23.004 - Valid Loss 52.736\n",
            "Epoch: 228/500 - Train loss 22.887 - Valid Loss 52.465\n",
            "Epoch: 229/500 - Train loss 22.771 - Valid Loss 52.198\n",
            "Epoch: 230/500 - Train loss 22.655 - Valid Loss 51.933\n",
            "Epoch: 231/500 - Train loss 22.539 - Valid Loss 51.671\n",
            "Epoch: 232/500 - Train loss 22.423 - Valid Loss 51.410\n",
            "Epoch: 233/500 - Train loss 22.308 - Valid Loss 51.151\n",
            "Epoch: 234/500 - Train loss 22.193 - Valid Loss 50.892\n",
            "Epoch: 235/500 - Train loss 22.078 - Valid Loss 50.635\n",
            "Epoch: 236/500 - Train loss 21.964 - Valid Loss 50.378\n",
            "Epoch: 237/500 - Train loss 21.850 - Valid Loss 50.122\n",
            "Epoch: 238/500 - Train loss 21.736 - Valid Loss 49.866\n",
            "Epoch: 239/500 - Train loss 21.623 - Valid Loss 49.610\n",
            "Epoch: 240/500 - Train loss 21.510 - Valid Loss 49.353\n",
            "Epoch: 241/500 - Train loss 21.397 - Valid Loss 49.097\n",
            "Epoch: 242/500 - Train loss 21.284 - Valid Loss 48.840\n",
            "Epoch: 243/500 - Train loss 21.172 - Valid Loss 48.582\n",
            "Epoch: 244/500 - Train loss 21.060 - Valid Loss 48.325\n",
            "Epoch: 245/500 - Train loss 20.949 - Valid Loss 48.066\n",
            "Epoch: 246/500 - Train loss 20.837 - Valid Loss 47.808\n",
            "Epoch: 247/500 - Train loss 20.726 - Valid Loss 47.549\n",
            "Epoch: 248/500 - Train loss 20.616 - Valid Loss 47.291\n",
            "Epoch: 249/500 - Train loss 20.505 - Valid Loss 47.032\n",
            "Epoch: 250/500 - Train loss 20.396 - Valid Loss 46.772\n",
            "Epoch: 251/500 - Train loss 20.286 - Valid Loss 46.514\n",
            "Epoch: 252/500 - Train loss 20.177 - Valid Loss 46.255\n",
            "Epoch: 253/500 - Train loss 20.068 - Valid Loss 45.997\n",
            "Epoch: 254/500 - Train loss 19.959 - Valid Loss 45.739\n",
            "Epoch: 255/500 - Train loss 19.851 - Valid Loss 45.481\n",
            "Epoch: 256/500 - Train loss 19.742 - Valid Loss 45.225\n",
            "Epoch: 257/500 - Train loss 19.635 - Valid Loss 44.969\n",
            "Epoch: 258/500 - Train loss 19.527 - Valid Loss 44.714\n",
            "Epoch: 259/500 - Train loss 19.420 - Valid Loss 44.461\n",
            "Epoch: 260/500 - Train loss 19.314 - Valid Loss 44.208\n",
            "Epoch: 261/500 - Train loss 19.207 - Valid Loss 43.956\n",
            "Epoch: 262/500 - Train loss 19.101 - Valid Loss 43.706\n",
            "Epoch: 263/500 - Train loss 18.996 - Valid Loss 43.456\n",
            "Epoch: 264/500 - Train loss 18.890 - Valid Loss 43.208\n",
            "Epoch: 265/500 - Train loss 18.785 - Valid Loss 42.961\n",
            "Epoch: 266/500 - Train loss 18.681 - Valid Loss 42.715\n",
            "Epoch: 267/500 - Train loss 18.576 - Valid Loss 42.471\n",
            "Epoch: 268/500 - Train loss 18.472 - Valid Loss 42.227\n",
            "Epoch: 269/500 - Train loss 18.369 - Valid Loss 41.985\n",
            "Epoch: 270/500 - Train loss 18.265 - Valid Loss 41.744\n",
            "Epoch: 271/500 - Train loss 18.162 - Valid Loss 41.504\n",
            "Epoch: 272/500 - Train loss 18.060 - Valid Loss 41.266\n",
            "Epoch: 273/500 - Train loss 17.958 - Valid Loss 41.028\n",
            "Epoch: 274/500 - Train loss 17.856 - Valid Loss 40.791\n",
            "Epoch: 275/500 - Train loss 17.754 - Valid Loss 40.555\n",
            "Epoch: 276/500 - Train loss 17.653 - Valid Loss 40.320\n",
            "Epoch: 277/500 - Train loss 17.552 - Valid Loss 40.087\n",
            "Epoch: 278/500 - Train loss 17.452 - Valid Loss 39.853\n",
            "Epoch: 279/500 - Train loss 17.351 - Valid Loss 39.621\n",
            "Epoch: 280/500 - Train loss 17.252 - Valid Loss 39.390\n",
            "Epoch: 281/500 - Train loss 17.152 - Valid Loss 39.159\n",
            "Epoch: 282/500 - Train loss 17.053 - Valid Loss 38.929\n",
            "Epoch: 283/500 - Train loss 16.954 - Valid Loss 38.700\n",
            "Epoch: 284/500 - Train loss 16.856 - Valid Loss 38.472\n",
            "Epoch: 285/500 - Train loss 16.758 - Valid Loss 38.244\n",
            "Epoch: 286/500 - Train loss 16.660 - Valid Loss 38.017\n",
            "Epoch: 287/500 - Train loss 16.563 - Valid Loss 37.791\n",
            "Epoch: 288/500 - Train loss 16.466 - Valid Loss 37.566\n",
            "Epoch: 289/500 - Train loss 16.369 - Valid Loss 37.341\n",
            "Epoch: 290/500 - Train loss 16.273 - Valid Loss 37.117\n",
            "Epoch: 291/500 - Train loss 16.177 - Valid Loss 36.894\n",
            "Epoch: 292/500 - Train loss 16.081 - Valid Loss 36.672\n",
            "Epoch: 293/500 - Train loss 15.986 - Valid Loss 36.450\n",
            "Epoch: 294/500 - Train loss 15.891 - Valid Loss 36.230\n",
            "Epoch: 295/500 - Train loss 15.797 - Valid Loss 36.010\n",
            "Epoch: 296/500 - Train loss 15.703 - Valid Loss 35.791\n",
            "Epoch: 297/500 - Train loss 15.609 - Valid Loss 35.573\n",
            "Epoch: 298/500 - Train loss 15.516 - Valid Loss 35.355\n",
            "Epoch: 299/500 - Train loss 15.423 - Valid Loss 35.139\n",
            "Epoch: 300/500 - Train loss 15.330 - Valid Loss 34.923\n",
            "Epoch: 301/500 - Train loss 15.238 - Valid Loss 34.708\n",
            "Epoch: 302/500 - Train loss 15.146 - Valid Loss 34.495\n",
            "Epoch: 303/500 - Train loss 15.054 - Valid Loss 34.282\n",
            "Epoch: 304/500 - Train loss 14.963 - Valid Loss 34.070\n",
            "Epoch: 305/500 - Train loss 14.872 - Valid Loss 33.859\n",
            "Epoch: 306/500 - Train loss 14.781 - Valid Loss 33.649\n",
            "Epoch: 307/500 - Train loss 14.691 - Valid Loss 33.439\n",
            "Epoch: 308/500 - Train loss 14.601 - Valid Loss 33.231\n",
            "Epoch: 309/500 - Train loss 14.512 - Valid Loss 33.024\n",
            "Epoch: 310/500 - Train loss 14.423 - Valid Loss 32.817\n",
            "Epoch: 311/500 - Train loss 14.334 - Valid Loss 32.612\n",
            "Epoch: 312/500 - Train loss 14.246 - Valid Loss 32.407\n",
            "Epoch: 313/500 - Train loss 14.158 - Valid Loss 32.203\n",
            "Epoch: 314/500 - Train loss 14.070 - Valid Loss 32.001\n",
            "Epoch: 315/500 - Train loss 13.983 - Valid Loss 31.799\n",
            "Epoch: 316/500 - Train loss 13.896 - Valid Loss 31.598\n",
            "Epoch: 317/500 - Train loss 13.810 - Valid Loss 31.397\n",
            "Epoch: 318/500 - Train loss 13.723 - Valid Loss 31.198\n",
            "Epoch: 319/500 - Train loss 13.638 - Valid Loss 31.000\n",
            "Epoch: 320/500 - Train loss 13.552 - Valid Loss 30.802\n",
            "Epoch: 321/500 - Train loss 13.467 - Valid Loss 30.605\n",
            "Epoch: 322/500 - Train loss 13.382 - Valid Loss 30.409\n",
            "Epoch: 323/500 - Train loss 13.298 - Valid Loss 30.214\n",
            "Epoch: 324/500 - Train loss 13.214 - Valid Loss 30.020\n",
            "Epoch: 325/500 - Train loss 13.130 - Valid Loss 29.827\n",
            "Epoch: 326/500 - Train loss 13.047 - Valid Loss 29.634\n",
            "Epoch: 327/500 - Train loss 12.964 - Valid Loss 29.443\n",
            "Epoch: 328/500 - Train loss 12.882 - Valid Loss 29.252\n",
            "Epoch: 329/500 - Train loss 12.799 - Valid Loss 29.062\n",
            "Epoch: 330/500 - Train loss 12.718 - Valid Loss 28.873\n",
            "Epoch: 331/500 - Train loss 12.636 - Valid Loss 28.685\n",
            "Epoch: 332/500 - Train loss 12.555 - Valid Loss 28.498\n",
            "Epoch: 333/500 - Train loss 12.474 - Valid Loss 28.312\n",
            "Epoch: 334/500 - Train loss 12.394 - Valid Loss 28.126\n",
            "Epoch: 335/500 - Train loss 12.314 - Valid Loss 27.941\n",
            "Epoch: 336/500 - Train loss 12.234 - Valid Loss 27.757\n",
            "Epoch: 337/500 - Train loss 12.155 - Valid Loss 27.574\n",
            "Epoch: 338/500 - Train loss 12.076 - Valid Loss 27.392\n",
            "Epoch: 339/500 - Train loss 11.997 - Valid Loss 27.211\n",
            "Epoch: 340/500 - Train loss 11.919 - Valid Loss 27.030\n",
            "Epoch: 341/500 - Train loss 11.841 - Valid Loss 26.850\n",
            "Epoch: 342/500 - Train loss 11.764 - Valid Loss 26.672\n",
            "Epoch: 343/500 - Train loss 11.686 - Valid Loss 26.494\n",
            "Epoch: 344/500 - Train loss 11.610 - Valid Loss 26.317\n",
            "Epoch: 345/500 - Train loss 11.533 - Valid Loss 26.141\n",
            "Epoch: 346/500 - Train loss 11.457 - Valid Loss 25.965\n",
            "Epoch: 347/500 - Train loss 11.381 - Valid Loss 25.791\n",
            "Epoch: 348/500 - Train loss 11.306 - Valid Loss 25.617\n",
            "Epoch: 349/500 - Train loss 11.231 - Valid Loss 25.444\n",
            "Epoch: 350/500 - Train loss 11.156 - Valid Loss 25.272\n",
            "Epoch: 351/500 - Train loss 11.082 - Valid Loss 25.101\n",
            "Epoch: 352/500 - Train loss 11.008 - Valid Loss 24.931\n",
            "Epoch: 353/500 - Train loss 10.934 - Valid Loss 24.762\n",
            "Epoch: 354/500 - Train loss 10.861 - Valid Loss 24.593\n",
            "Epoch: 355/500 - Train loss 10.788 - Valid Loss 24.425\n",
            "Epoch: 356/500 - Train loss 10.716 - Valid Loss 24.259\n",
            "Epoch: 357/500 - Train loss 10.643 - Valid Loss 24.093\n",
            "Epoch: 358/500 - Train loss 10.572 - Valid Loss 23.927\n",
            "Epoch: 359/500 - Train loss 10.500 - Valid Loss 23.763\n",
            "Epoch: 360/500 - Train loss 10.429 - Valid Loss 23.599\n",
            "Epoch: 361/500 - Train loss 10.358 - Valid Loss 23.436\n",
            "Epoch: 362/500 - Train loss 10.288 - Valid Loss 23.275\n",
            "Epoch: 363/500 - Train loss 10.217 - Valid Loss 23.114\n",
            "Epoch: 364/500 - Train loss 10.148 - Valid Loss 22.953\n",
            "Epoch: 365/500 - Train loss 10.078 - Valid Loss 22.794\n",
            "Epoch: 366/500 - Train loss 10.009 - Valid Loss 22.635\n",
            "Epoch: 367/500 - Train loss 9.940 - Valid Loss 22.478\n",
            "Epoch: 368/500 - Train loss 9.872 - Valid Loss 22.321\n",
            "Epoch: 369/500 - Train loss 9.804 - Valid Loss 22.165\n",
            "Epoch: 370/500 - Train loss 9.736 - Valid Loss 22.009\n",
            "Epoch: 371/500 - Train loss 9.669 - Valid Loss 21.854\n",
            "Epoch: 372/500 - Train loss 9.602 - Valid Loss 21.701\n",
            "Epoch: 373/500 - Train loss 9.535 - Valid Loss 21.548\n",
            "Epoch: 374/500 - Train loss 9.469 - Valid Loss 21.396\n",
            "Epoch: 375/500 - Train loss 9.403 - Valid Loss 21.244\n",
            "Epoch: 376/500 - Train loss 9.337 - Valid Loss 21.094\n",
            "Epoch: 377/500 - Train loss 9.272 - Valid Loss 20.944\n",
            "Epoch: 378/500 - Train loss 9.207 - Valid Loss 20.795\n",
            "Epoch: 379/500 - Train loss 9.142 - Valid Loss 20.647\n",
            "Epoch: 380/500 - Train loss 9.078 - Valid Loss 20.500\n",
            "Epoch: 381/500 - Train loss 9.014 - Valid Loss 20.353\n",
            "Epoch: 382/500 - Train loss 8.951 - Valid Loss 20.207\n",
            "Epoch: 383/500 - Train loss 8.887 - Valid Loss 20.062\n",
            "Epoch: 384/500 - Train loss 8.824 - Valid Loss 19.918\n",
            "Epoch: 385/500 - Train loss 8.762 - Valid Loss 19.775\n",
            "Epoch: 386/500 - Train loss 8.699 - Valid Loss 19.632\n",
            "Epoch: 387/500 - Train loss 8.637 - Valid Loss 19.490\n",
            "Epoch: 388/500 - Train loss 8.576 - Valid Loss 19.349\n",
            "Epoch: 389/500 - Train loss 8.514 - Valid Loss 19.209\n",
            "Epoch: 390/500 - Train loss 8.453 - Valid Loss 19.070\n",
            "Epoch: 391/500 - Train loss 8.393 - Valid Loss 18.931\n",
            "Epoch: 392/500 - Train loss 8.333 - Valid Loss 18.793\n",
            "Epoch: 393/500 - Train loss 8.273 - Valid Loss 18.656\n",
            "Epoch: 394/500 - Train loss 8.213 - Valid Loss 18.519\n",
            "Epoch: 395/500 - Train loss 8.153 - Valid Loss 18.384\n",
            "Epoch: 396/500 - Train loss 8.094 - Valid Loss 18.249\n",
            "Epoch: 397/500 - Train loss 8.036 - Valid Loss 18.115\n",
            "Epoch: 398/500 - Train loss 7.977 - Valid Loss 17.981\n",
            "Epoch: 399/500 - Train loss 7.919 - Valid Loss 17.848\n",
            "Epoch: 400/500 - Train loss 7.862 - Valid Loss 17.717\n",
            "Epoch: 401/500 - Train loss 7.804 - Valid Loss 17.585\n",
            "Epoch: 402/500 - Train loss 7.747 - Valid Loss 17.455\n",
            "Epoch: 403/500 - Train loss 7.690 - Valid Loss 17.326\n",
            "Epoch: 404/500 - Train loss 7.634 - Valid Loss 17.197\n",
            "Epoch: 405/500 - Train loss 7.578 - Valid Loss 17.069\n",
            "Epoch: 406/500 - Train loss 7.522 - Valid Loss 16.941\n",
            "Epoch: 407/500 - Train loss 7.466 - Valid Loss 16.815\n",
            "Epoch: 408/500 - Train loss 7.411 - Valid Loss 16.689\n",
            "Epoch: 409/500 - Train loss 7.356 - Valid Loss 16.563\n",
            "Epoch: 410/500 - Train loss 7.302 - Valid Loss 16.439\n",
            "Epoch: 411/500 - Train loss 7.248 - Valid Loss 16.315\n",
            "Epoch: 412/500 - Train loss 7.194 - Valid Loss 16.192\n",
            "Epoch: 413/500 - Train loss 7.140 - Valid Loss 16.070\n",
            "Epoch: 414/500 - Train loss 7.087 - Valid Loss 15.948\n",
            "Epoch: 415/500 - Train loss 7.034 - Valid Loss 15.827\n",
            "Epoch: 416/500 - Train loss 6.981 - Valid Loss 15.707\n",
            "Epoch: 417/500 - Train loss 6.928 - Valid Loss 15.588\n",
            "Epoch: 418/500 - Train loss 6.876 - Valid Loss 15.469\n",
            "Epoch: 419/500 - Train loss 6.825 - Valid Loss 15.351\n",
            "Epoch: 420/500 - Train loss 6.773 - Valid Loss 15.234\n",
            "Epoch: 421/500 - Train loss 6.722 - Valid Loss 15.117\n",
            "Epoch: 422/500 - Train loss 6.671 - Valid Loss 15.001\n",
            "Epoch: 423/500 - Train loss 6.620 - Valid Loss 14.886\n",
            "Epoch: 424/500 - Train loss 6.570 - Valid Loss 14.772\n",
            "Epoch: 425/500 - Train loss 6.520 - Valid Loss 14.658\n",
            "Epoch: 426/500 - Train loss 6.470 - Valid Loss 14.545\n",
            "Epoch: 427/500 - Train loss 6.421 - Valid Loss 14.432\n",
            "Epoch: 428/500 - Train loss 6.372 - Valid Loss 14.320\n",
            "Epoch: 429/500 - Train loss 6.323 - Valid Loss 14.209\n",
            "Epoch: 430/500 - Train loss 6.275 - Valid Loss 14.099\n",
            "Epoch: 431/500 - Train loss 6.226 - Valid Loss 13.989\n",
            "Epoch: 432/500 - Train loss 6.178 - Valid Loss 13.880\n",
            "Epoch: 433/500 - Train loss 6.131 - Valid Loss 13.772\n",
            "Epoch: 434/500 - Train loss 6.083 - Valid Loss 13.664\n",
            "Epoch: 435/500 - Train loss 6.036 - Valid Loss 13.557\n",
            "Epoch: 436/500 - Train loss 5.989 - Valid Loss 13.451\n",
            "Epoch: 437/500 - Train loss 5.943 - Valid Loss 13.345\n",
            "Epoch: 438/500 - Train loss 5.897 - Valid Loss 13.240\n",
            "Epoch: 439/500 - Train loss 5.851 - Valid Loss 13.136\n",
            "Epoch: 440/500 - Train loss 5.805 - Valid Loss 13.032\n",
            "Epoch: 441/500 - Train loss 5.760 - Valid Loss 12.929\n",
            "Epoch: 442/500 - Train loss 5.715 - Valid Loss 12.827\n",
            "Epoch: 443/500 - Train loss 5.670 - Valid Loss 12.725\n",
            "Epoch: 444/500 - Train loss 5.625 - Valid Loss 12.624\n",
            "Epoch: 445/500 - Train loss 5.581 - Valid Loss 12.523\n",
            "Epoch: 446/500 - Train loss 5.537 - Valid Loss 12.423\n",
            "Epoch: 447/500 - Train loss 5.493 - Valid Loss 12.324\n",
            "Epoch: 448/500 - Train loss 5.450 - Valid Loss 12.226\n",
            "Epoch: 449/500 - Train loss 5.407 - Valid Loss 12.128\n",
            "Epoch: 450/500 - Train loss 5.364 - Valid Loss 12.031\n",
            "Epoch: 451/500 - Train loss 5.321 - Valid Loss 11.934\n",
            "Epoch: 452/500 - Train loss 5.279 - Valid Loss 11.838\n",
            "Epoch: 453/500 - Train loss 5.237 - Valid Loss 11.742\n",
            "Epoch: 454/500 - Train loss 5.195 - Valid Loss 11.648\n",
            "Epoch: 455/500 - Train loss 5.153 - Valid Loss 11.553\n",
            "Epoch: 456/500 - Train loss 5.112 - Valid Loss 11.460\n",
            "Epoch: 457/500 - Train loss 5.071 - Valid Loss 11.367\n",
            "Epoch: 458/500 - Train loss 5.030 - Valid Loss 11.275\n",
            "Epoch: 459/500 - Train loss 4.990 - Valid Loss 11.183\n",
            "Epoch: 460/500 - Train loss 4.950 - Valid Loss 11.092\n",
            "Epoch: 461/500 - Train loss 4.910 - Valid Loss 11.001\n",
            "Epoch: 462/500 - Train loss 4.870 - Valid Loss 10.911\n",
            "Epoch: 463/500 - Train loss 4.830 - Valid Loss 10.822\n",
            "Epoch: 464/500 - Train loss 4.791 - Valid Loss 10.733\n",
            "Epoch: 465/500 - Train loss 4.752 - Valid Loss 10.645\n",
            "Epoch: 466/500 - Train loss 4.714 - Valid Loss 10.557\n",
            "Epoch: 467/500 - Train loss 4.675 - Valid Loss 10.470\n",
            "Epoch: 468/500 - Train loss 4.637 - Valid Loss 10.384\n",
            "Epoch: 469/500 - Train loss 4.599 - Valid Loss 10.298\n",
            "Epoch: 470/500 - Train loss 4.561 - Valid Loss 10.213\n",
            "Epoch: 471/500 - Train loss 4.524 - Valid Loss 10.128\n",
            "Epoch: 472/500 - Train loss 4.487 - Valid Loss 10.044\n",
            "Epoch: 473/500 - Train loss 4.450 - Valid Loss 9.961\n",
            "Epoch: 474/500 - Train loss 4.413 - Valid Loss 9.878\n",
            "Epoch: 475/500 - Train loss 4.377 - Valid Loss 9.795\n",
            "Epoch: 476/500 - Train loss 4.341 - Valid Loss 9.713\n",
            "Epoch: 477/500 - Train loss 4.305 - Valid Loss 9.632\n",
            "Epoch: 478/500 - Train loss 4.269 - Valid Loss 9.552\n",
            "Epoch: 479/500 - Train loss 4.234 - Valid Loss 9.471\n",
            "Epoch: 480/500 - Train loss 4.198 - Valid Loss 9.392\n",
            "Epoch: 481/500 - Train loss 4.163 - Valid Loss 9.313\n",
            "Epoch: 482/500 - Train loss 4.129 - Valid Loss 9.234\n",
            "Epoch: 483/500 - Train loss 4.094 - Valid Loss 9.156\n",
            "Epoch: 484/500 - Train loss 4.060 - Valid Loss 9.079\n",
            "Epoch: 485/500 - Train loss 4.026 - Valid Loss 9.002\n",
            "Epoch: 486/500 - Train loss 3.992 - Valid Loss 8.926\n",
            "Epoch: 487/500 - Train loss 3.958 - Valid Loss 8.850\n",
            "Epoch: 488/500 - Train loss 3.925 - Valid Loss 8.775\n",
            "Epoch: 489/500 - Train loss 3.892 - Valid Loss 8.700\n",
            "Epoch: 490/500 - Train loss 3.859 - Valid Loss 8.626\n",
            "Epoch: 491/500 - Train loss 3.826 - Valid Loss 8.552\n",
            "Epoch: 492/500 - Train loss 3.794 - Valid Loss 8.479\n",
            "Epoch: 493/500 - Train loss 3.762 - Valid Loss 8.406\n",
            "Epoch: 494/500 - Train loss 3.730 - Valid Loss 8.334\n",
            "Epoch: 495/500 - Train loss 3.698 - Valid Loss 8.262\n",
            "Epoch: 496/500 - Train loss 3.666 - Valid Loss 8.191\n",
            "Epoch: 497/500 - Train loss 3.635 - Valid Loss 8.121\n",
            "Epoch: 498/500 - Train loss 3.604 - Valid Loss 8.050\n",
            "Epoch: 499/500 - Train loss 3.573 - Valid Loss 7.981\n",
            "Epoch: 500/500 - Train loss 3.542 - Valid Loss 7.912\n"
          ]
        }
      ],
      "source": [
        "history1 = train(model1,\n",
        "                train_loader,\n",
        "                valid_loader,\n",
        "                model1_optimizer,\n",
        "                model1_criterion,\n",
        "                epochs=500\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY39Ruoahrsk",
        "outputId": "519cfd1d-a024-4d18-c155-ebeaad665cd2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epoch_count = range(1, len(history1['loss']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history1['loss'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history1['val_loss'], label='valid')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88tdVCOyxcuy",
        "outputId": "f938373d-89e1-4bee-e54c-d96890a49736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_test: 450\n",
            "y_hat: tensor([[443.0439]], grad_fn=<AddmmBackward0>)\n",
            "loss: 48.387969970703125\n"
          ]
        }
      ],
      "source": [
        "# Ensayo\n",
        "# x = 30\n",
        "# y_test = x * 15\n",
        "\n",
        "x_test = 30\n",
        "y_test = x_test * 15\n",
        "test_input = np.array([x_test])\n",
        "test_input = test_input.reshape((1, seq_length, input_size))\n",
        "test_input = torch.from_numpy(test_input.astype(np.float32))\n",
        "\n",
        "test_target = torch.from_numpy(np.array(y_test).astype(np.int32)).float().view(-1, 1)\n",
        "\n",
        "y_hat = model1(test_input)\n",
        "\n",
        "print(\"y_test:\", y_test)\n",
        "print(\"y_hat:\", y_hat)\n",
        "\n",
        "loss = model1_criterion(y_hat, test_target).item()\n",
        "print(\"loss:\", loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxAPmVk_WoXo",
        "outputId": "10fdb4af-bce7-498f-ff5d-bc949574c886"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Model2                                   [1, 1]                    --\n",
              "├─CustomLSTM: 1-1                        [1, 1, 64]                16,896\n",
              "│    └─Sigmoid: 2-1                      [1, 64]                   --\n",
              "│    └─Sigmoid: 2-2                      [1, 64]                   --\n",
              "│    └─ReLU: 2-3                         [1, 64]                   --\n",
              "│    └─Sigmoid: 2-4                      [1, 64]                   --\n",
              "│    └─ReLU: 2-5                         [1, 64]                   --\n",
              "├─Linear: 1-2                            [1, 1]                    65\n",
              "==========================================================================================\n",
              "Total params: 16,961\n",
              "Trainable params: 16,961\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch_helpers import CustomLSTM\n",
        "\n",
        "class Model2(nn.Module):\n",
        "    def __init__(self, input_size, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        #self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=64, batch_first=True) # LSTM layer\n",
        "        # Utilizamos la CustomLSTM ya que para series temporales suele funcionar mejor\n",
        "        # la activacion \"relu\" en las LSTM en vez de la \"tanh\", pero por defecto la\n",
        "        # layer de Pytorch LSTM no permite modificar la funcion de activacion\n",
        "        self.lstm1 = CustomLSTM(input_size=input_size, hidden_size=64, activation=nn.ReLU()) # LSTM layer\n",
        "        self.fc = nn.Linear(in_features=64, out_features=output_dim) #  # Fully connected layer\n",
        "        \n",
        "    def forward(self, x):\n",
        "        lstm_output, _ = self.lstm1(x)\n",
        "        out = self.fc(lstm_output[:,-1,:]) # take last output (last seq)\n",
        "        return out\n",
        "\n",
        "model2 = Model2(input_size=input_size, output_dim=output_dim)\n",
        "\n",
        "# Crear el optimizador la una función de error\n",
        "model2_optimizer = torch.optim.Adam(model2.parameters(), lr=0.01)\n",
        "model2_criterion = nn.MSELoss()  # mean squared error\n",
        "\n",
        "summary(model2, input_size=(1, seq_length, input_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72MoqYZObz2V",
        "outputId": "70d60579-8b35-4a24-8f37-8780f4b925fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/500 - Train loss 21066.238 - Valid Loss 77210.188\n",
            "Epoch: 2/500 - Train loss 21021.455 - Valid Loss 77020.969\n",
            "Epoch: 3/500 - Train loss 20973.658 - Valid Loss 76810.289\n",
            "Epoch: 4/500 - Train loss 20920.668 - Valid Loss 76561.188\n",
            "Epoch: 5/500 - Train loss 20858.859 - Valid Loss 76265.078\n",
            "Epoch: 6/500 - Train loss 20787.156 - Valid Loss 75918.555\n",
            "Epoch: 7/500 - Train loss 20703.875 - Valid Loss 75515.391\n",
            "Epoch: 8/500 - Train loss 20607.242 - Valid Loss 75048.805\n",
            "Epoch: 9/500 - Train loss 20495.682 - Valid Loss 74514.375\n",
            "Epoch: 10/500 - Train loss 20367.816 - Valid Loss 73908.453\n",
            "Epoch: 11/500 - Train loss 20222.318 - Valid Loss 73228.125\n",
            "Epoch: 12/500 - Train loss 20057.967 - Valid Loss 72471.617\n",
            "Epoch: 13/500 - Train loss 19873.768 - Valid Loss 71638.234\n",
            "Epoch: 14/500 - Train loss 19668.932 - Valid Loss 70728.258\n",
            "Epoch: 15/500 - Train loss 19442.809 - Valid Loss 69742.562\n",
            "Epoch: 16/500 - Train loss 19194.949 - Valid Loss 68682.812\n",
            "Epoch: 17/500 - Train loss 18925.117 - Valid Loss 67551.047\n",
            "Epoch: 18/500 - Train loss 18633.248 - Valid Loss 66349.555\n",
            "Epoch: 19/500 - Train loss 18319.453 - Valid Loss 65080.695\n",
            "Epoch: 20/500 - Train loss 17983.994 - Valid Loss 63746.773\n",
            "Epoch: 21/500 - Train loss 17627.270 - Valid Loss 62349.996\n",
            "Epoch: 22/500 - Train loss 17249.809 - Valid Loss 60892.531\n",
            "Epoch: 23/500 - Train loss 16852.242 - Valid Loss 59376.531\n",
            "Epoch: 24/500 - Train loss 16435.295 - Valid Loss 57804.250\n",
            "Epoch: 25/500 - Train loss 15999.784 - Valid Loss 56178.133\n",
            "Epoch: 26/500 - Train loss 15546.618 - Valid Loss 54500.844\n",
            "Epoch: 27/500 - Train loss 15076.765 - Valid Loss 52775.281\n",
            "Epoch: 28/500 - Train loss 14591.283 - Valid Loss 51004.555\n",
            "Epoch: 29/500 - Train loss 14091.293 - Valid Loss 49191.988\n",
            "Epoch: 30/500 - Train loss 13577.985 - Valid Loss 47341.000\n",
            "Epoch: 31/500 - Train loss 13052.609 - Valid Loss 45455.172\n",
            "Epoch: 32/500 - Train loss 12516.479 - Valid Loss 43538.172\n",
            "Epoch: 33/500 - Train loss 11970.955 - Valid Loss 41593.848\n",
            "Epoch: 34/500 - Train loss 11417.471 - Valid Loss 39626.195\n",
            "Epoch: 35/500 - Train loss 10857.512 - Valid Loss 37639.469\n",
            "Epoch: 36/500 - Train loss 10292.637 - Valid Loss 35638.238\n",
            "Epoch: 37/500 - Train loss 9724.476 - Valid Loss 33627.484\n",
            "Epoch: 38/500 - Train loss 9154.747 - Valid Loss 31612.723\n",
            "Epoch: 39/500 - Train loss 8585.259 - Valid Loss 29600.164\n",
            "Epoch: 40/500 - Train loss 8017.925 - Valid Loss 27596.789\n",
            "Epoch: 41/500 - Train loss 7454.771 - Valid Loss 25610.393\n",
            "Epoch: 42/500 - Train loss 6897.932 - Valid Loss 23649.484\n",
            "Epoch: 43/500 - Train loss 6349.647 - Valid Loss 21723.037\n",
            "Epoch: 44/500 - Train loss 5812.231 - Valid Loss 19840.188\n",
            "Epoch: 45/500 - Train loss 5288.052 - Valid Loss 18009.926\n",
            "Epoch: 46/500 - Train loss 4779.481 - Valid Loss 16240.815\n",
            "Epoch: 47/500 - Train loss 4288.851 - Valid Loss 14540.865\n",
            "Epoch: 48/500 - Train loss 3818.412 - Valid Loss 12917.448\n",
            "Epoch: 49/500 - Train loss 3370.293 - Valid Loss 11377.277\n",
            "Epoch: 50/500 - Train loss 2946.462 - Valid Loss 9926.389\n",
            "Epoch: 51/500 - Train loss 2548.693 - Valid Loss 8570.094\n",
            "Epoch: 52/500 - Train loss 2178.539 - Valid Loss 7312.919\n",
            "Epoch: 53/500 - Train loss 1837.298 - Valid Loss 6158.501\n",
            "Epoch: 54/500 - Train loss 1525.986 - Valid Loss 5109.481\n",
            "Epoch: 55/500 - Train loss 1245.303 - Valid Loss 4167.388\n",
            "Epoch: 56/500 - Train loss 995.603 - Valid Loss 3332.529\n",
            "Epoch: 57/500 - Train loss 776.870 - Valid Loss 2603.891\n",
            "Epoch: 58/500 - Train loss 588.691 - Valid Loss 1979.090\n",
            "Epoch: 59/500 - Train loss 430.246 - Valid Loss 1454.339\n",
            "Epoch: 60/500 - Train loss 300.302 - Valid Loss 1024.463\n",
            "Epoch: 61/500 - Train loss 197.221 - Valid Loss 682.979\n",
            "Epoch: 62/500 - Train loss 118.985 - Valid Loss 422.220\n",
            "Epoch: 63/500 - Train loss 63.237 - Valid Loss 233.512\n",
            "Epoch: 64/500 - Train loss 27.332 - Valid Loss 107.422\n",
            "Epoch: 65/500 - Train loss 8.418 - Valid Loss 34.040\n",
            "Epoch: 66/500 - Train loss 3.511 - Valid Loss 3.291\n",
            "Epoch: 67/500 - Train loss 9.598 - Valid Loss 5.272\n",
            "Epoch: 68/500 - Train loss 23.731 - Valid Loss 30.579\n",
            "Epoch: 69/500 - Train loss 43.126 - Valid Loss 70.603\n",
            "Epoch: 70/500 - Train loss 65.250 - Valid Loss 117.785\n",
            "Epoch: 71/500 - Train loss 87.896 - Valid Loss 165.795\n",
            "Epoch: 72/500 - Train loss 109.235 - Valid Loss 209.641\n",
            "Epoch: 73/500 - Train loss 127.846 - Valid Loss 245.698\n",
            "Epoch: 74/500 - Train loss 142.725 - Valid Loss 271.656\n",
            "Epoch: 75/500 - Train loss 153.268 - Valid Loss 286.408\n",
            "Epoch: 76/500 - Train loss 159.233 - Valid Loss 289.884\n",
            "Epoch: 77/500 - Train loss 160.693 - Valid Loss 282.856\n",
            "Epoch: 78/500 - Train loss 157.977 - Valid Loss 266.730\n",
            "Epoch: 79/500 - Train loss 151.602 - Valid Loss 243.331\n",
            "Epoch: 80/500 - Train loss 142.213 - Valid Loss 214.708\n",
            "Epoch: 81/500 - Train loss 130.524 - Valid Loss 182.965\n",
            "Epoch: 82/500 - Train loss 117.263 - Valid Loss 150.116\n",
            "Epoch: 83/500 - Train loss 103.130 - Valid Loss 117.974\n",
            "Epoch: 84/500 - Train loss 88.766 - Valid Loss 88.077\n",
            "Epoch: 85/500 - Train loss 74.725 - Valid Loss 61.642\n",
            "Epoch: 86/500 - Train loss 61.460 - Valid Loss 39.539\n",
            "Epoch: 87/500 - Train loss 49.321 - Valid Loss 22.306\n",
            "Epoch: 88/500 - Train loss 38.552 - Valid Loss 10.165\n",
            "Epoch: 89/500 - Train loss 29.296 - Valid Loss 3.058\n",
            "Epoch: 90/500 - Train loss 21.609 - Valid Loss 0.696\n",
            "Epoch: 91/500 - Train loss 15.468 - Valid Loss 2.605\n",
            "Epoch: 92/500 - Train loss 10.792 - Valid Loss 8.175\n",
            "Epoch: 93/500 - Train loss 7.450 - Valid Loss 16.715\n",
            "Epoch: 94/500 - Train loss 5.280 - Valid Loss 27.490\n",
            "Epoch: 95/500 - Train loss 4.099 - Valid Loss 39.766\n",
            "Epoch: 96/500 - Train loss 3.717 - Valid Loss 52.841\n",
            "Epoch: 97/500 - Train loss 3.947 - Valid Loss 66.069\n",
            "Epoch: 98/500 - Train loss 4.611 - Valid Loss 78.883\n",
            "Epoch: 99/500 - Train loss 5.550 - Valid Loss 90.803\n",
            "Epoch: 100/500 - Train loss 6.622 - Valid Loss 101.448\n",
            "Epoch: 101/500 - Train loss 7.712 - Valid Loss 110.534\n",
            "Epoch: 102/500 - Train loss 8.725 - Valid Loss 117.872\n",
            "Epoch: 103/500 - Train loss 9.594 - Valid Loss 123.362\n",
            "Epoch: 104/500 - Train loss 10.272 - Valid Loss 126.984\n",
            "Epoch: 105/500 - Train loss 10.733 - Valid Loss 128.787\n",
            "Epoch: 106/500 - Train loss 10.969 - Valid Loss 128.879\n",
            "Epoch: 107/500 - Train loss 10.987 - Valid Loss 127.410\n",
            "Epoch: 108/500 - Train loss 10.804 - Valid Loss 124.565\n",
            "Epoch: 109/500 - Train loss 10.449 - Valid Loss 120.548\n",
            "Epoch: 110/500 - Train loss 9.954 - Valid Loss 115.577\n",
            "Epoch: 111/500 - Train loss 9.354 - Valid Loss 109.868\n",
            "Epoch: 112/500 - Train loss 8.685 - Valid Loss 103.630\n",
            "Epoch: 113/500 - Train loss 7.982 - Valid Loss 97.062\n",
            "Epoch: 114/500 - Train loss 7.276 - Valid Loss 90.341\n",
            "Epoch: 115/500 - Train loss 6.594 - Valid Loss 83.625\n",
            "Epoch: 116/500 - Train loss 5.959 - Valid Loss 77.048\n",
            "Epoch: 117/500 - Train loss 5.387 - Valid Loss 70.720\n",
            "Epoch: 118/500 - Train loss 4.889 - Valid Loss 64.726\n",
            "Epoch: 119/500 - Train loss 4.472 - Valid Loss 59.131\n",
            "Epoch: 120/500 - Train loss 4.137 - Valid Loss 53.976\n",
            "Epoch: 121/500 - Train loss 3.882 - Valid Loss 49.287\n",
            "Epoch: 122/500 - Train loss 3.700 - Valid Loss 45.073\n",
            "Epoch: 123/500 - Train loss 3.584 - Valid Loss 41.332\n",
            "Epoch: 124/500 - Train loss 3.523 - Valid Loss 38.051\n",
            "Epoch: 125/500 - Train loss 3.507 - Valid Loss 35.208\n",
            "Epoch: 126/500 - Train loss 3.524 - Valid Loss 32.781\n",
            "Epoch: 127/500 - Train loss 3.565 - Valid Loss 30.742\n",
            "Epoch: 128/500 - Train loss 3.618 - Valid Loss 29.061\n",
            "Epoch: 129/500 - Train loss 3.676 - Valid Loss 27.711\n",
            "Epoch: 130/500 - Train loss 3.732 - Valid Loss 26.664\n",
            "Epoch: 131/500 - Train loss 3.780 - Valid Loss 25.893\n",
            "Epoch: 132/500 - Train loss 3.817 - Valid Loss 25.375\n",
            "Epoch: 133/500 - Train loss 3.840 - Valid Loss 25.086\n",
            "Epoch: 134/500 - Train loss 3.849 - Valid Loss 25.005\n",
            "Epoch: 135/500 - Train loss 3.843 - Valid Loss 25.113\n",
            "Epoch: 136/500 - Train loss 3.824 - Valid Loss 25.391\n",
            "Epoch: 137/500 - Train loss 3.794 - Valid Loss 25.820\n",
            "Epoch: 138/500 - Train loss 3.755 - Valid Loss 26.383\n",
            "Epoch: 139/500 - Train loss 3.709 - Valid Loss 27.061\n",
            "Epoch: 140/500 - Train loss 3.660 - Valid Loss 27.837\n",
            "Epoch: 141/500 - Train loss 3.609 - Valid Loss 28.693\n",
            "Epoch: 142/500 - Train loss 3.560 - Valid Loss 29.611\n",
            "Epoch: 143/500 - Train loss 3.512 - Valid Loss 30.572\n",
            "Epoch: 144/500 - Train loss 3.469 - Valid Loss 31.559\n",
            "Epoch: 145/500 - Train loss 3.430 - Valid Loss 32.555\n",
            "Epoch: 146/500 - Train loss 3.397 - Valid Loss 33.541\n",
            "Epoch: 147/500 - Train loss 3.369 - Valid Loss 34.503\n",
            "Epoch: 148/500 - Train loss 3.347 - Valid Loss 35.425\n",
            "Epoch: 149/500 - Train loss 3.330 - Valid Loss 36.294\n",
            "Epoch: 150/500 - Train loss 3.317 - Valid Loss 37.099\n",
            "Epoch: 151/500 - Train loss 3.307 - Valid Loss 37.830\n",
            "Epoch: 152/500 - Train loss 3.301 - Valid Loss 38.480\n",
            "Epoch: 153/500 - Train loss 3.296 - Valid Loss 39.041\n",
            "Epoch: 154/500 - Train loss 3.293 - Valid Loss 39.512\n",
            "Epoch: 155/500 - Train loss 3.291 - Valid Loss 39.889\n",
            "Epoch: 156/500 - Train loss 3.288 - Valid Loss 40.174\n",
            "Epoch: 157/500 - Train loss 3.285 - Valid Loss 40.368\n",
            "Epoch: 158/500 - Train loss 3.282 - Valid Loss 40.475\n",
            "Epoch: 159/500 - Train loss 3.277 - Valid Loss 40.500\n",
            "Epoch: 160/500 - Train loss 3.271 - Valid Loss 40.449\n",
            "Epoch: 161/500 - Train loss 3.264 - Valid Loss 40.329\n",
            "Epoch: 162/500 - Train loss 3.257 - Valid Loss 40.147\n",
            "Epoch: 163/500 - Train loss 3.248 - Valid Loss 39.913\n",
            "Epoch: 164/500 - Train loss 3.239 - Valid Loss 39.633\n",
            "Epoch: 165/500 - Train loss 3.230 - Valid Loss 39.317\n",
            "Epoch: 166/500 - Train loss 3.220 - Valid Loss 38.972\n",
            "Epoch: 167/500 - Train loss 3.210 - Valid Loss 38.607\n",
            "Epoch: 168/500 - Train loss 3.200 - Valid Loss 38.229\n",
            "Epoch: 169/500 - Train loss 3.191 - Valid Loss 37.845\n",
            "Epoch: 170/500 - Train loss 3.182 - Valid Loss 37.461\n",
            "Epoch: 171/500 - Train loss 3.173 - Valid Loss 37.084\n",
            "Epoch: 172/500 - Train loss 3.165 - Valid Loss 36.717\n",
            "Epoch: 173/500 - Train loss 3.157 - Valid Loss 36.366\n",
            "Epoch: 174/500 - Train loss 3.150 - Valid Loss 36.033\n",
            "Epoch: 175/500 - Train loss 3.143 - Valid Loss 35.723\n",
            "Epoch: 176/500 - Train loss 3.136 - Valid Loss 35.436\n",
            "Epoch: 177/500 - Train loss 3.129 - Valid Loss 35.175\n",
            "Epoch: 178/500 - Train loss 3.123 - Valid Loss 34.940\n",
            "Epoch: 179/500 - Train loss 3.117 - Valid Loss 34.732\n",
            "Epoch: 180/500 - Train loss 3.111 - Valid Loss 34.551\n",
            "Epoch: 181/500 - Train loss 3.105 - Valid Loss 34.396\n",
            "Epoch: 182/500 - Train loss 3.099 - Valid Loss 34.267\n",
            "Epoch: 183/500 - Train loss 3.093 - Valid Loss 34.162\n",
            "Epoch: 184/500 - Train loss 3.087 - Valid Loss 34.078\n",
            "Epoch: 185/500 - Train loss 3.081 - Valid Loss 34.016\n",
            "Epoch: 186/500 - Train loss 3.075 - Valid Loss 33.973\n",
            "Epoch: 187/500 - Train loss 3.069 - Valid Loss 33.946\n",
            "Epoch: 188/500 - Train loss 3.063 - Valid Loss 33.934\n",
            "Epoch: 189/500 - Train loss 3.057 - Valid Loss 33.934\n",
            "Epoch: 190/500 - Train loss 3.051 - Valid Loss 33.944\n",
            "Epoch: 191/500 - Train loss 3.044 - Valid Loss 33.961\n",
            "Epoch: 192/500 - Train loss 3.038 - Valid Loss 33.984\n",
            "Epoch: 193/500 - Train loss 3.032 - Valid Loss 34.011\n",
            "Epoch: 194/500 - Train loss 3.026 - Valid Loss 34.038\n",
            "Epoch: 195/500 - Train loss 3.020 - Valid Loss 34.066\n",
            "Epoch: 196/500 - Train loss 3.014 - Valid Loss 34.092\n",
            "Epoch: 197/500 - Train loss 3.008 - Valid Loss 34.114\n",
            "Epoch: 198/500 - Train loss 3.003 - Valid Loss 34.132\n",
            "Epoch: 199/500 - Train loss 2.997 - Valid Loss 34.144\n",
            "Epoch: 200/500 - Train loss 2.991 - Valid Loss 34.149\n",
            "Epoch: 201/500 - Train loss 2.986 - Valid Loss 34.148\n",
            "Epoch: 202/500 - Train loss 2.980 - Valid Loss 34.139\n",
            "Epoch: 203/500 - Train loss 2.974 - Valid Loss 34.122\n",
            "Epoch: 204/500 - Train loss 2.969 - Valid Loss 34.098\n",
            "Epoch: 205/500 - Train loss 2.964 - Valid Loss 34.066\n",
            "Epoch: 206/500 - Train loss 2.958 - Valid Loss 34.026\n",
            "Epoch: 207/500 - Train loss 2.953 - Valid Loss 33.979\n",
            "Epoch: 208/500 - Train loss 2.947 - Valid Loss 33.925\n",
            "Epoch: 209/500 - Train loss 2.942 - Valid Loss 33.866\n",
            "Epoch: 210/500 - Train loss 2.937 - Valid Loss 33.800\n",
            "Epoch: 211/500 - Train loss 2.931 - Valid Loss 33.730\n",
            "Epoch: 212/500 - Train loss 2.926 - Valid Loss 33.656\n",
            "Epoch: 213/500 - Train loss 2.921 - Valid Loss 33.579\n",
            "Epoch: 214/500 - Train loss 2.916 - Valid Loss 33.499\n",
            "Epoch: 215/500 - Train loss 2.911 - Valid Loss 33.416\n",
            "Epoch: 216/500 - Train loss 2.906 - Valid Loss 33.333\n",
            "Epoch: 217/500 - Train loss 2.900 - Valid Loss 33.249\n",
            "Epoch: 218/500 - Train loss 2.895 - Valid Loss 33.166\n",
            "Epoch: 219/500 - Train loss 2.890 - Valid Loss 33.083\n",
            "Epoch: 220/500 - Train loss 2.885 - Valid Loss 33.000\n",
            "Epoch: 221/500 - Train loss 2.880 - Valid Loss 32.920\n",
            "Epoch: 222/500 - Train loss 2.875 - Valid Loss 32.841\n",
            "Epoch: 223/500 - Train loss 2.870 - Valid Loss 32.765\n",
            "Epoch: 224/500 - Train loss 2.866 - Valid Loss 32.691\n",
            "Epoch: 225/500 - Train loss 2.861 - Valid Loss 32.619\n",
            "Epoch: 226/500 - Train loss 2.856 - Valid Loss 32.550\n",
            "Epoch: 227/500 - Train loss 2.851 - Valid Loss 32.484\n",
            "Epoch: 228/500 - Train loss 2.846 - Valid Loss 32.420\n",
            "Epoch: 229/500 - Train loss 2.842 - Valid Loss 32.359\n",
            "Epoch: 230/500 - Train loss 2.837 - Valid Loss 32.300\n",
            "Epoch: 231/500 - Train loss 2.832 - Valid Loss 32.243\n",
            "Epoch: 232/500 - Train loss 2.828 - Valid Loss 32.189\n",
            "Epoch: 233/500 - Train loss 2.823 - Valid Loss 32.137\n",
            "Epoch: 234/500 - Train loss 2.819 - Valid Loss 32.086\n",
            "Epoch: 235/500 - Train loss 2.814 - Valid Loss 32.037\n",
            "Epoch: 236/500 - Train loss 2.810 - Valid Loss 31.989\n",
            "Epoch: 237/500 - Train loss 2.805 - Valid Loss 31.942\n",
            "Epoch: 238/500 - Train loss 2.801 - Valid Loss 31.896\n",
            "Epoch: 239/500 - Train loss 2.796 - Valid Loss 31.851\n",
            "Epoch: 240/500 - Train loss 2.792 - Valid Loss 31.806\n",
            "Epoch: 241/500 - Train loss 2.787 - Valid Loss 31.760\n",
            "Epoch: 242/500 - Train loss 2.783 - Valid Loss 31.716\n",
            "Epoch: 243/500 - Train loss 2.779 - Valid Loss 31.670\n",
            "Epoch: 244/500 - Train loss 2.774 - Valid Loss 31.625\n",
            "Epoch: 245/500 - Train loss 2.770 - Valid Loss 31.579\n",
            "Epoch: 246/500 - Train loss 2.766 - Valid Loss 31.533\n",
            "Epoch: 247/500 - Train loss 2.762 - Valid Loss 31.486\n",
            "Epoch: 248/500 - Train loss 2.757 - Valid Loss 31.438\n",
            "Epoch: 249/500 - Train loss 2.753 - Valid Loss 31.390\n",
            "Epoch: 250/500 - Train loss 2.749 - Valid Loss 31.342\n",
            "Epoch: 251/500 - Train loss 2.745 - Valid Loss 31.293\n",
            "Epoch: 252/500 - Train loss 2.741 - Valid Loss 31.242\n",
            "Epoch: 253/500 - Train loss 2.737 - Valid Loss 31.192\n",
            "Epoch: 254/500 - Train loss 2.733 - Valid Loss 31.141\n",
            "Epoch: 255/500 - Train loss 2.729 - Valid Loss 31.090\n",
            "Epoch: 256/500 - Train loss 2.725 - Valid Loss 31.039\n",
            "Epoch: 257/500 - Train loss 2.721 - Valid Loss 30.987\n",
            "Epoch: 258/500 - Train loss 2.717 - Valid Loss 30.935\n",
            "Epoch: 259/500 - Train loss 2.713 - Valid Loss 30.883\n",
            "Epoch: 260/500 - Train loss 2.709 - Valid Loss 30.830\n",
            "Epoch: 261/500 - Train loss 2.705 - Valid Loss 30.778\n",
            "Epoch: 262/500 - Train loss 2.701 - Valid Loss 30.726\n",
            "Epoch: 263/500 - Train loss 2.697 - Valid Loss 30.674\n",
            "Epoch: 264/500 - Train loss 2.693 - Valid Loss 30.622\n",
            "Epoch: 265/500 - Train loss 2.690 - Valid Loss 30.571\n",
            "Epoch: 266/500 - Train loss 2.686 - Valid Loss 30.520\n",
            "Epoch: 267/500 - Train loss 2.682 - Valid Loss 30.469\n",
            "Epoch: 268/500 - Train loss 2.678 - Valid Loss 30.419\n",
            "Epoch: 269/500 - Train loss 2.675 - Valid Loss 30.369\n",
            "Epoch: 270/500 - Train loss 2.671 - Valid Loss 30.320\n",
            "Epoch: 271/500 - Train loss 2.667 - Valid Loss 30.271\n",
            "Epoch: 272/500 - Train loss 2.664 - Valid Loss 30.222\n",
            "Epoch: 273/500 - Train loss 2.660 - Valid Loss 30.174\n",
            "Epoch: 274/500 - Train loss 2.656 - Valid Loss 30.127\n",
            "Epoch: 275/500 - Train loss 2.653 - Valid Loss 30.080\n",
            "Epoch: 276/500 - Train loss 2.649 - Valid Loss 30.033\n",
            "Epoch: 277/500 - Train loss 2.646 - Valid Loss 29.986\n",
            "Epoch: 278/500 - Train loss 2.642 - Valid Loss 29.940\n",
            "Epoch: 279/500 - Train loss 2.639 - Valid Loss 29.894\n",
            "Epoch: 280/500 - Train loss 2.635 - Valid Loss 29.849\n",
            "Epoch: 281/500 - Train loss 2.632 - Valid Loss 29.803\n",
            "Epoch: 282/500 - Train loss 2.628 - Valid Loss 29.758\n",
            "Epoch: 283/500 - Train loss 2.625 - Valid Loss 29.713\n",
            "Epoch: 284/500 - Train loss 2.621 - Valid Loss 29.669\n",
            "Epoch: 285/500 - Train loss 2.618 - Valid Loss 29.624\n",
            "Epoch: 286/500 - Train loss 2.614 - Valid Loss 29.580\n",
            "Epoch: 287/500 - Train loss 2.611 - Valid Loss 29.536\n",
            "Epoch: 288/500 - Train loss 2.608 - Valid Loss 29.491\n",
            "Epoch: 289/500 - Train loss 2.604 - Valid Loss 29.447\n",
            "Epoch: 290/500 - Train loss 2.601 - Valid Loss 29.403\n",
            "Epoch: 291/500 - Train loss 2.598 - Valid Loss 29.360\n",
            "Epoch: 292/500 - Train loss 2.594 - Valid Loss 29.316\n",
            "Epoch: 293/500 - Train loss 2.591 - Valid Loss 29.272\n",
            "Epoch: 294/500 - Train loss 2.588 - Valid Loss 29.229\n",
            "Epoch: 295/500 - Train loss 2.585 - Valid Loss 29.185\n",
            "Epoch: 296/500 - Train loss 2.581 - Valid Loss 29.142\n",
            "Epoch: 297/500 - Train loss 2.578 - Valid Loss 29.098\n",
            "Epoch: 298/500 - Train loss 2.575 - Valid Loss 29.055\n",
            "Epoch: 299/500 - Train loss 2.572 - Valid Loss 29.012\n",
            "Epoch: 300/500 - Train loss 2.569 - Valid Loss 28.969\n",
            "Epoch: 301/500 - Train loss 2.565 - Valid Loss 28.926\n",
            "Epoch: 302/500 - Train loss 2.562 - Valid Loss 28.883\n",
            "Epoch: 303/500 - Train loss 2.559 - Valid Loss 28.841\n",
            "Epoch: 304/500 - Train loss 2.556 - Valid Loss 28.798\n",
            "Epoch: 305/500 - Train loss 2.553 - Valid Loss 28.756\n",
            "Epoch: 306/500 - Train loss 2.550 - Valid Loss 28.714\n",
            "Epoch: 307/500 - Train loss 2.547 - Valid Loss 28.672\n",
            "Epoch: 308/500 - Train loss 2.544 - Valid Loss 28.630\n",
            "Epoch: 309/500 - Train loss 2.541 - Valid Loss 28.589\n",
            "Epoch: 310/500 - Train loss 2.538 - Valid Loss 28.548\n",
            "Epoch: 311/500 - Train loss 2.535 - Valid Loss 28.506\n",
            "Epoch: 312/500 - Train loss 2.532 - Valid Loss 28.465\n",
            "Epoch: 313/500 - Train loss 2.529 - Valid Loss 28.425\n",
            "Epoch: 314/500 - Train loss 2.526 - Valid Loss 28.384\n",
            "Epoch: 315/500 - Train loss 2.523 - Valid Loss 28.344\n",
            "Epoch: 316/500 - Train loss 2.520 - Valid Loss 28.303\n",
            "Epoch: 317/500 - Train loss 2.517 - Valid Loss 28.263\n",
            "Epoch: 318/500 - Train loss 2.514 - Valid Loss 28.223\n",
            "Epoch: 319/500 - Train loss 2.511 - Valid Loss 28.184\n",
            "Epoch: 320/500 - Train loss 2.508 - Valid Loss 28.144\n",
            "Epoch: 321/500 - Train loss 2.505 - Valid Loss 28.105\n",
            "Epoch: 322/500 - Train loss 2.502 - Valid Loss 28.065\n",
            "Epoch: 323/500 - Train loss 2.499 - Valid Loss 28.026\n",
            "Epoch: 324/500 - Train loss 2.496 - Valid Loss 27.988\n",
            "Epoch: 325/500 - Train loss 2.493 - Valid Loss 27.949\n",
            "Epoch: 326/500 - Train loss 2.490 - Valid Loss 27.910\n",
            "Epoch: 327/500 - Train loss 2.488 - Valid Loss 27.872\n",
            "Epoch: 328/500 - Train loss 2.485 - Valid Loss 27.834\n",
            "Epoch: 329/500 - Train loss 2.482 - Valid Loss 27.796\n",
            "Epoch: 330/500 - Train loss 2.479 - Valid Loss 27.758\n",
            "Epoch: 331/500 - Train loss 2.476 - Valid Loss 27.720\n",
            "Epoch: 332/500 - Train loss 2.473 - Valid Loss 27.682\n",
            "Epoch: 333/500 - Train loss 2.471 - Valid Loss 27.645\n",
            "Epoch: 334/500 - Train loss 2.468 - Valid Loss 27.607\n",
            "Epoch: 335/500 - Train loss 2.465 - Valid Loss 27.569\n",
            "Epoch: 336/500 - Train loss 2.462 - Valid Loss 27.532\n",
            "Epoch: 337/500 - Train loss 2.460 - Valid Loss 27.495\n",
            "Epoch: 338/500 - Train loss 2.457 - Valid Loss 27.458\n",
            "Epoch: 339/500 - Train loss 2.454 - Valid Loss 27.422\n",
            "Epoch: 340/500 - Train loss 2.451 - Valid Loss 27.385\n",
            "Epoch: 341/500 - Train loss 2.449 - Valid Loss 27.348\n",
            "Epoch: 342/500 - Train loss 2.446 - Valid Loss 27.312\n",
            "Epoch: 343/500 - Train loss 2.443 - Valid Loss 27.276\n",
            "Epoch: 344/500 - Train loss 2.440 - Valid Loss 27.240\n",
            "Epoch: 345/500 - Train loss 2.438 - Valid Loss 27.204\n",
            "Epoch: 346/500 - Train loss 2.435 - Valid Loss 27.168\n",
            "Epoch: 347/500 - Train loss 2.432 - Valid Loss 27.132\n",
            "Epoch: 348/500 - Train loss 2.430 - Valid Loss 27.096\n",
            "Epoch: 349/500 - Train loss 2.427 - Valid Loss 27.061\n",
            "Epoch: 350/500 - Train loss 2.424 - Valid Loss 27.025\n",
            "Epoch: 351/500 - Train loss 2.421 - Valid Loss 26.990\n",
            "Epoch: 352/500 - Train loss 2.419 - Valid Loss 26.955\n",
            "Epoch: 353/500 - Train loss 2.416 - Valid Loss 26.920\n",
            "Epoch: 354/500 - Train loss 2.413 - Valid Loss 26.885\n",
            "Epoch: 355/500 - Train loss 2.411 - Valid Loss 26.851\n",
            "Epoch: 356/500 - Train loss 2.408 - Valid Loss 26.816\n",
            "Epoch: 357/500 - Train loss 2.406 - Valid Loss 26.782\n",
            "Epoch: 358/500 - Train loss 2.403 - Valid Loss 26.747\n",
            "Epoch: 359/500 - Train loss 2.400 - Valid Loss 26.713\n",
            "Epoch: 360/500 - Train loss 2.398 - Valid Loss 26.679\n",
            "Epoch: 361/500 - Train loss 2.395 - Valid Loss 26.645\n",
            "Epoch: 362/500 - Train loss 2.392 - Valid Loss 26.611\n",
            "Epoch: 363/500 - Train loss 2.390 - Valid Loss 26.578\n",
            "Epoch: 364/500 - Train loss 2.387 - Valid Loss 26.544\n",
            "Epoch: 365/500 - Train loss 2.385 - Valid Loss 26.511\n",
            "Epoch: 366/500 - Train loss 2.382 - Valid Loss 26.477\n",
            "Epoch: 367/500 - Train loss 2.379 - Valid Loss 26.444\n",
            "Epoch: 368/500 - Train loss 2.377 - Valid Loss 26.411\n",
            "Epoch: 369/500 - Train loss 2.374 - Valid Loss 26.378\n",
            "Epoch: 370/500 - Train loss 2.372 - Valid Loss 26.345\n",
            "Epoch: 371/500 - Train loss 2.369 - Valid Loss 26.312\n",
            "Epoch: 372/500 - Train loss 2.366 - Valid Loss 26.279\n",
            "Epoch: 373/500 - Train loss 2.364 - Valid Loss 26.247\n",
            "Epoch: 374/500 - Train loss 2.361 - Valid Loss 26.215\n",
            "Epoch: 375/500 - Train loss 2.359 - Valid Loss 26.182\n",
            "Epoch: 376/500 - Train loss 2.356 - Valid Loss 26.150\n",
            "Epoch: 377/500 - Train loss 2.354 - Valid Loss 26.118\n",
            "Epoch: 378/500 - Train loss 2.351 - Valid Loss 26.086\n",
            "Epoch: 379/500 - Train loss 2.348 - Valid Loss 26.054\n",
            "Epoch: 380/500 - Train loss 2.346 - Valid Loss 26.022\n",
            "Epoch: 381/500 - Train loss 2.343 - Valid Loss 25.990\n",
            "Epoch: 382/500 - Train loss 2.341 - Valid Loss 25.958\n",
            "Epoch: 383/500 - Train loss 2.338 - Valid Loss 25.927\n",
            "Epoch: 384/500 - Train loss 2.336 - Valid Loss 25.895\n",
            "Epoch: 385/500 - Train loss 2.333 - Valid Loss 25.864\n",
            "Epoch: 386/500 - Train loss 2.331 - Valid Loss 25.833\n",
            "Epoch: 387/500 - Train loss 2.328 - Valid Loss 25.802\n",
            "Epoch: 388/500 - Train loss 2.326 - Valid Loss 25.770\n",
            "Epoch: 389/500 - Train loss 2.323 - Valid Loss 25.740\n",
            "Epoch: 390/500 - Train loss 2.320 - Valid Loss 25.709\n",
            "Epoch: 391/500 - Train loss 2.318 - Valid Loss 25.678\n",
            "Epoch: 392/500 - Train loss 2.315 - Valid Loss 25.647\n",
            "Epoch: 393/500 - Train loss 2.313 - Valid Loss 25.616\n",
            "Epoch: 394/500 - Train loss 2.310 - Valid Loss 25.586\n",
            "Epoch: 395/500 - Train loss 2.308 - Valid Loss 25.556\n",
            "Epoch: 396/500 - Train loss 2.305 - Valid Loss 25.525\n",
            "Epoch: 397/500 - Train loss 2.303 - Valid Loss 25.495\n",
            "Epoch: 398/500 - Train loss 2.300 - Valid Loss 25.464\n",
            "Epoch: 399/500 - Train loss 2.298 - Valid Loss 25.434\n",
            "Epoch: 400/500 - Train loss 2.295 - Valid Loss 25.404\n",
            "Epoch: 401/500 - Train loss 2.293 - Valid Loss 25.374\n",
            "Epoch: 402/500 - Train loss 2.290 - Valid Loss 25.344\n",
            "Epoch: 403/500 - Train loss 2.288 - Valid Loss 25.315\n",
            "Epoch: 404/500 - Train loss 2.285 - Valid Loss 25.285\n",
            "Epoch: 405/500 - Train loss 2.283 - Valid Loss 25.255\n",
            "Epoch: 406/500 - Train loss 2.280 - Valid Loss 25.226\n",
            "Epoch: 407/500 - Train loss 2.278 - Valid Loss 25.196\n",
            "Epoch: 408/500 - Train loss 2.275 - Valid Loss 25.167\n",
            "Epoch: 409/500 - Train loss 2.273 - Valid Loss 25.137\n",
            "Epoch: 410/500 - Train loss 2.270 - Valid Loss 25.108\n",
            "Epoch: 411/500 - Train loss 2.267 - Valid Loss 25.079\n",
            "Epoch: 412/500 - Train loss 2.265 - Valid Loss 25.050\n",
            "Epoch: 413/500 - Train loss 2.262 - Valid Loss 25.020\n",
            "Epoch: 414/500 - Train loss 2.260 - Valid Loss 24.991\n",
            "Epoch: 415/500 - Train loss 2.257 - Valid Loss 24.962\n",
            "Epoch: 416/500 - Train loss 2.255 - Valid Loss 24.933\n",
            "Epoch: 417/500 - Train loss 2.252 - Valid Loss 24.905\n",
            "Epoch: 418/500 - Train loss 2.250 - Valid Loss 24.876\n",
            "Epoch: 419/500 - Train loss 2.247 - Valid Loss 24.847\n",
            "Epoch: 420/500 - Train loss 2.245 - Valid Loss 24.818\n",
            "Epoch: 421/500 - Train loss 2.242 - Valid Loss 24.790\n",
            "Epoch: 422/500 - Train loss 2.240 - Valid Loss 24.761\n",
            "Epoch: 423/500 - Train loss 2.237 - Valid Loss 24.733\n",
            "Epoch: 424/500 - Train loss 2.235 - Valid Loss 24.704\n",
            "Epoch: 425/500 - Train loss 2.232 - Valid Loss 24.676\n",
            "Epoch: 426/500 - Train loss 2.230 - Valid Loss 24.647\n",
            "Epoch: 427/500 - Train loss 2.227 - Valid Loss 24.619\n",
            "Epoch: 428/500 - Train loss 2.225 - Valid Loss 24.591\n",
            "Epoch: 429/500 - Train loss 2.222 - Valid Loss 24.563\n",
            "Epoch: 430/500 - Train loss 2.219 - Valid Loss 24.534\n",
            "Epoch: 431/500 - Train loss 2.217 - Valid Loss 24.506\n",
            "Epoch: 432/500 - Train loss 2.214 - Valid Loss 24.478\n",
            "Epoch: 433/500 - Train loss 2.212 - Valid Loss 24.450\n",
            "Epoch: 434/500 - Train loss 2.209 - Valid Loss 24.422\n",
            "Epoch: 435/500 - Train loss 2.207 - Valid Loss 24.394\n",
            "Epoch: 436/500 - Train loss 2.204 - Valid Loss 24.366\n",
            "Epoch: 437/500 - Train loss 2.202 - Valid Loss 24.338\n",
            "Epoch: 438/500 - Train loss 2.199 - Valid Loss 24.310\n",
            "Epoch: 439/500 - Train loss 2.197 - Valid Loss 24.282\n",
            "Epoch: 440/500 - Train loss 2.194 - Valid Loss 24.254\n",
            "Epoch: 441/500 - Train loss 2.191 - Valid Loss 24.227\n",
            "Epoch: 442/500 - Train loss 2.189 - Valid Loss 24.199\n",
            "Epoch: 443/500 - Train loss 2.186 - Valid Loss 24.171\n",
            "Epoch: 444/500 - Train loss 2.184 - Valid Loss 24.143\n",
            "Epoch: 445/500 - Train loss 2.181 - Valid Loss 24.116\n",
            "Epoch: 446/500 - Train loss 2.179 - Valid Loss 24.088\n",
            "Epoch: 447/500 - Train loss 2.176 - Valid Loss 24.060\n",
            "Epoch: 448/500 - Train loss 2.173 - Valid Loss 24.033\n",
            "Epoch: 449/500 - Train loss 2.171 - Valid Loss 24.005\n",
            "Epoch: 450/500 - Train loss 2.168 - Valid Loss 23.978\n",
            "Epoch: 451/500 - Train loss 2.166 - Valid Loss 23.950\n",
            "Epoch: 452/500 - Train loss 2.163 - Valid Loss 23.923\n",
            "Epoch: 453/500 - Train loss 2.160 - Valid Loss 23.895\n",
            "Epoch: 454/500 - Train loss 2.158 - Valid Loss 23.867\n",
            "Epoch: 455/500 - Train loss 2.155 - Valid Loss 23.840\n",
            "Epoch: 456/500 - Train loss 2.153 - Valid Loss 23.812\n",
            "Epoch: 457/500 - Train loss 2.150 - Valid Loss 23.785\n",
            "Epoch: 458/500 - Train loss 2.147 - Valid Loss 23.757\n",
            "Epoch: 459/500 - Train loss 2.145 - Valid Loss 23.730\n",
            "Epoch: 460/500 - Train loss 2.142 - Valid Loss 23.702\n",
            "Epoch: 461/500 - Train loss 2.140 - Valid Loss 23.675\n",
            "Epoch: 462/500 - Train loss 2.137 - Valid Loss 23.647\n",
            "Epoch: 463/500 - Train loss 2.134 - Valid Loss 23.619\n",
            "Epoch: 464/500 - Train loss 2.132 - Valid Loss 23.592\n",
            "Epoch: 465/500 - Train loss 2.129 - Valid Loss 23.565\n",
            "Epoch: 466/500 - Train loss 2.126 - Valid Loss 23.537\n",
            "Epoch: 467/500 - Train loss 2.124 - Valid Loss 23.509\n",
            "Epoch: 468/500 - Train loss 2.121 - Valid Loss 23.481\n",
            "Epoch: 469/500 - Train loss 2.118 - Valid Loss 23.454\n",
            "Epoch: 470/500 - Train loss 2.116 - Valid Loss 23.426\n",
            "Epoch: 471/500 - Train loss 2.113 - Valid Loss 23.399\n",
            "Epoch: 472/500 - Train loss 2.110 - Valid Loss 23.371\n",
            "Epoch: 473/500 - Train loss 2.107 - Valid Loss 23.343\n",
            "Epoch: 474/500 - Train loss 2.105 - Valid Loss 23.316\n",
            "Epoch: 475/500 - Train loss 2.102 - Valid Loss 23.288\n",
            "Epoch: 476/500 - Train loss 2.099 - Valid Loss 23.260\n",
            "Epoch: 477/500 - Train loss 2.097 - Valid Loss 23.232\n",
            "Epoch: 478/500 - Train loss 2.094 - Valid Loss 23.204\n",
            "Epoch: 479/500 - Train loss 2.091 - Valid Loss 23.176\n",
            "Epoch: 480/500 - Train loss 2.088 - Valid Loss 23.148\n",
            "Epoch: 481/500 - Train loss 2.086 - Valid Loss 23.120\n",
            "Epoch: 482/500 - Train loss 2.083 - Valid Loss 23.092\n",
            "Epoch: 483/500 - Train loss 2.080 - Valid Loss 23.063\n",
            "Epoch: 484/500 - Train loss 2.077 - Valid Loss 23.035\n",
            "Epoch: 485/500 - Train loss 2.074 - Valid Loss 23.007\n",
            "Epoch: 486/500 - Train loss 2.072 - Valid Loss 22.979\n",
            "Epoch: 487/500 - Train loss 2.069 - Valid Loss 22.950\n",
            "Epoch: 488/500 - Train loss 2.066 - Valid Loss 22.922\n",
            "Epoch: 489/500 - Train loss 2.063 - Valid Loss 22.893\n",
            "Epoch: 490/500 - Train loss 2.060 - Valid Loss 22.864\n",
            "Epoch: 491/500 - Train loss 2.057 - Valid Loss 22.835\n",
            "Epoch: 492/500 - Train loss 2.054 - Valid Loss 22.806\n",
            "Epoch: 493/500 - Train loss 2.052 - Valid Loss 22.778\n",
            "Epoch: 494/500 - Train loss 2.049 - Valid Loss 22.749\n",
            "Epoch: 495/500 - Train loss 2.046 - Valid Loss 22.719\n",
            "Epoch: 496/500 - Train loss 2.043 - Valid Loss 22.690\n",
            "Epoch: 497/500 - Train loss 2.040 - Valid Loss 22.661\n",
            "Epoch: 498/500 - Train loss 2.037 - Valid Loss 22.631\n",
            "Epoch: 499/500 - Train loss 2.034 - Valid Loss 22.602\n",
            "Epoch: 500/500 - Train loss 2.031 - Valid Loss 22.572\n"
          ]
        }
      ],
      "source": [
        "history2 = train(model2,\n",
        "                train_loader,\n",
        "                valid_loader,\n",
        "                model2_optimizer,\n",
        "                model2_criterion,\n",
        "                epochs=500\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyYR9z-qgdMq",
        "outputId": "178a36e1-ed14-4bda-e48d-e381384c9d64"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epoch_count = range(1, len(history2['loss']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history2['loss'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history2['val_loss'], label='valid')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_Z_hJ6Ig4Of",
        "outputId": "4b0c027b-d94f-41bf-a236-ad8e7c684b20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_test: 450\n",
            "y_hat: tensor([[434.6496]], grad_fn=<AddmmBackward0>)\n",
            "loss: 235.63580322265625\n"
          ]
        }
      ],
      "source": [
        "# Ensayo\n",
        "# x = 30\n",
        "# y_test = x * 15\n",
        "\n",
        "x_test = 30\n",
        "y_test = x_test * 15\n",
        "test_input = np.array([x_test])\n",
        "test_input = test_input.reshape((1, seq_length, input_size))\n",
        "test_input = torch.from_numpy(test_input.astype(np.float32))\n",
        "\n",
        "test_target = torch.from_numpy(np.array(y_test).astype(np.int32)).float().view(-1, 1)\n",
        "\n",
        "y_hat = model2(test_input)\n",
        "\n",
        "print(\"y_test:\", y_test)\n",
        "print(\"y_hat:\", y_hat)\n",
        "\n",
        "loss = model2_criterion(y_hat, test_target).item()\n",
        "print(\"loss:\", loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEI5TjSFWeY8"
      },
      "source": [
        "Se puede observar que para un problema tan simple como este no hay mucha diferencia entre utilizar una RNN o LSTM. La LSTM tiene muchos más parámetros que la RNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT8b9EfGyshD"
      },
      "source": [
        "### 3 - Multi-layer LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xVfTMScdFqR",
        "outputId": "ab320db5-0817-4250-b6fe-ff8fc7df0b8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Model3                                   [1, 1]                    --\n",
              "├─CustomLSTM: 1-1                        [1, 1, 64]                16,896\n",
              "├─CustomLSTM: 1-4                        --                        (recursive)\n",
              "│    └─Sigmoid: 2-1                      [1, 64]                   --\n",
              "│    └─Sigmoid: 2-2                      [1, 64]                   --\n",
              "├─CustomLSTM: 1-5                        --                        (recursive)\n",
              "│    └─ReLU: 2-3                         [1, 64]                   --\n",
              "├─CustomLSTM: 1-4                        --                        (recursive)\n",
              "│    └─Sigmoid: 2-4                      [1, 64]                   --\n",
              "├─CustomLSTM: 1-5                        --                        (recursive)\n",
              "│    └─ReLU: 2-5                         [1, 64]                   --\n",
              "├─CustomLSTM: 1-6                        [1, 1, 64]                33,024\n",
              "│    └─Sigmoid: 2-6                      [1, 64]                   --\n",
              "│    └─Sigmoid: 2-7                      [1, 64]                   --\n",
              "│    └─ReLU: 2-8                         [1, 64]                   --\n",
              "│    └─Sigmoid: 2-9                      [1, 64]                   --\n",
              "│    └─ReLU: 2-10                        [1, 64]                   --\n",
              "├─Linear: 1-7                            [1, 1]                    65\n",
              "==========================================================================================\n",
              "Total params: 49,985\n",
              "Trainable params: 49,985\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch_helpers import CustomLSTM\n",
        "\n",
        "# En esta oportunidad se utilizarán dos layer LSTM\n",
        "class Model3(nn.Module):\n",
        "    def __init__(self, input_size, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lstm1 = CustomLSTM(input_size=input_size, hidden_size=64, activation=nn.ReLU()) # LSTM layer\n",
        "        self.lstm2 = CustomLSTM(input_size=64, hidden_size=64, activation=nn.ReLU()) # LSTM layer\n",
        "        self.fc = nn.Linear(in_features=64, out_features=output_dim) #  # Fully connected layer\n",
        "        \n",
        "    def forward(self, x):\n",
        "        lstm_output, _ = self.lstm1(x)\n",
        "        lstm_output, _ = self.lstm2(lstm_output)\n",
        "        out = self.fc(lstm_output[:,-1,:]) # take last output (last seq)\n",
        "        return out\n",
        "\n",
        "model3 = Model3(input_size=input_size, output_dim=output_dim)\n",
        "\n",
        "# Crear el optimizador la una función de error\n",
        "model3_optimizer = torch.optim.Adam(model3.parameters(), lr=0.01)\n",
        "model3_criterion = nn.MSELoss()  # mean squared error\n",
        "\n",
        "summary(model3, input_size=(1, seq_length, input_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtoKCzXrei60",
        "outputId": "d968f5bb-d5ae-4ccb-af64-8d0d289865c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/500 - Train loss 21060.648 - Valid Loss 77298.312\n",
            "Epoch: 2/500 - Train loss 21046.730 - Valid Loss 77250.477\n",
            "Epoch: 3/500 - Train loss 21032.021 - Valid Loss 77168.922\n",
            "Epoch: 4/500 - Train loss 21010.311 - Valid Loss 77025.742\n",
            "Epoch: 5/500 - Train loss 20976.109 - Valid Loss 76770.383\n",
            "Epoch: 6/500 - Train loss 20920.223 - Valid Loss 76333.898\n",
            "Epoch: 7/500 - Train loss 20830.010 - Valid Loss 75630.602\n",
            "Epoch: 8/500 - Train loss 20688.035 - Valid Loss 74578.234\n",
            "Epoch: 9/500 - Train loss 20472.715 - Valid Loss 73123.422\n",
            "Epoch: 10/500 - Train loss 20161.223 - Valid Loss 71247.359\n",
            "Epoch: 11/500 - Train loss 19733.873 - Valid Loss 68939.000\n",
            "Epoch: 12/500 - Train loss 19177.111 - Valid Loss 66161.914\n",
            "Epoch: 13/500 - Train loss 18481.977 - Valid Loss 62845.211\n",
            "Epoch: 14/500 - Train loss 17639.088 - Valid Loss 58900.336\n",
            "Epoch: 15/500 - Train loss 16639.480 - Valid Loss 54279.516\n",
            "Epoch: 16/500 - Train loss 15471.961 - Valid Loss 48960.656\n",
            "Epoch: 17/500 - Train loss 14127.237 - Valid Loss 42968.281\n",
            "Epoch: 18/500 - Train loss 12603.189 - Valid Loss 36391.785\n",
            "Epoch: 19/500 - Train loss 10910.635 - Valid Loss 29394.631\n",
            "Epoch: 20/500 - Train loss 9077.313 - Valid Loss 22227.475\n",
            "Epoch: 21/500 - Train loss 7153.472 - Valid Loss 15244.207\n",
            "Epoch: 22/500 - Train loss 5217.514 - Valid Loss 8915.374\n",
            "Epoch: 23/500 - Train loss 3381.643 - Valid Loss 3832.783\n",
            "Epoch: 24/500 - Train loss 1795.471 - Valid Loss 686.404\n",
            "Epoch: 25/500 - Train loss 643.045 - Valid Loss 147.207\n",
            "Epoch: 26/500 - Train loss 117.157 - Valid Loss 2543.587\n",
            "Epoch: 27/500 - Train loss 340.068 - Valid Loss 7107.215\n",
            "Epoch: 28/500 - Train loss 1183.024 - Valid Loss 11791.677\n",
            "Epoch: 29/500 - Train loss 2180.765 - Valid Loss 14517.026\n",
            "Epoch: 30/500 - Train loss 2811.367 - Valid Loss 14559.041\n",
            "Epoch: 31/500 - Train loss 2861.127 - Valid Loss 12468.322\n",
            "Epoch: 32/500 - Train loss 2432.353 - Valid Loss 9283.971\n",
            "Epoch: 33/500 - Train loss 1760.585 - Valid Loss 5974.452\n",
            "Epoch: 34/500 - Train loss 1073.147 - Valid Loss 3206.052\n",
            "Epoch: 35/500 - Train loss 525.974 - Valid Loss 1299.333\n",
            "Epoch: 36/500 - Train loss 190.165 - Valid Loss 284.313\n",
            "Epoch: 37/500 - Train loss 65.552 - Valid Loss 0.791\n",
            "Epoch: 38/500 - Train loss 106.382 - Valid Loss 203.501\n",
            "Epoch: 39/500 - Train loss 247.994 - Valid Loss 644.344\n",
            "Epoch: 40/500 - Train loss 427.183 - Valid Loss 1120.795\n",
            "Epoch: 41/500 - Train loss 593.732 - Valid Loss 1494.392\n",
            "Epoch: 42/500 - Train loss 714.408 - Valid Loss 1690.009\n",
            "Epoch: 43/500 - Train loss 772.307 - Valid Loss 1686.108\n",
            "Epoch: 44/500 - Train loss 764.093 - Valid Loss 1502.496\n",
            "Epoch: 45/500 - Train loss 696.862 - Valid Loss 1188.376\n",
            "Epoch: 46/500 - Train loss 585.014 - Valid Loss 811.190\n",
            "Epoch: 47/500 - Train loss 447.133 - Valid Loss 439.768\n",
            "Epoch: 48/500 - Train loss 304.438 - Valid Loss 152.187\n",
            "Epoch: 49/500 - Train loss 179.489 - Valid Loss 9.532\n",
            "Epoch: 50/500 - Train loss 89.902 - Valid Loss 41.334\n",
            "Epoch: 51/500 - Train loss 46.193 - Valid Loss 238.458\n",
            "Epoch: 52/500 - Train loss 49.153 - Valid Loss 548.325\n",
            "Epoch: 53/500 - Train loss 88.476 - Valid Loss 883.574\n",
            "Epoch: 54/500 - Train loss 144.325 - Valid Loss 1154.586\n",
            "Epoch: 55/500 - Train loss 194.761 - Valid Loss 1298.220\n",
            "Epoch: 56/500 - Train loss 223.435 - Valid Loss 1290.978\n",
            "Epoch: 57/500 - Train loss 223.382 - Valid Loss 1149.254\n",
            "Epoch: 58/500 - Train loss 197.302 - Valid Loss 918.164\n",
            "Epoch: 59/500 - Train loss 154.867 - Valid Loss 654.087\n",
            "Epoch: 60/500 - Train loss 108.433 - Valid Loss 407.827\n",
            "Epoch: 61/500 - Train loss 68.909 - Valid Loss 213.545\n",
            "Epoch: 62/500 - Train loss 43.089 - Valid Loss 85.297\n",
            "Epoch: 63/500 - Train loss 32.867 - Valid Loss 20.315\n",
            "Epoch: 64/500 - Train loss 36.032 - Valid Loss 0.361\n",
            "Epoch: 65/500 - Train loss 47.439 - Valid Loss 7.114\n",
            "Epoch: 66/500 - Train loss 61.552 - Valid Loss 23.124\n",
            "Epoch: 67/500 - Train loss 73.625 - Valid Loss 35.514\n",
            "Epoch: 68/500 - Train loss 80.389 - Valid Loss 37.760\n",
            "Epoch: 69/500 - Train loss 80.441 - Valid Loss 29.658\n",
            "Epoch: 70/500 - Train loss 74.222 - Valid Loss 15.883\n",
            "Epoch: 71/500 - Train loss 63.575 - Valid Loss 3.706\n",
            "Epoch: 72/500 - Train loss 51.129 - Valid Loss 0.429\n",
            "Epoch: 73/500 - Train loss 39.594 - Valid Loss 11.078\n",
            "Epoch: 74/500 - Train loss 31.112 - Valid Loss 36.865\n",
            "Epoch: 75/500 - Train loss 26.803 - Valid Loss 74.755\n",
            "Epoch: 76/500 - Train loss 26.610 - Valid Loss 118.232\n",
            "Epoch: 77/500 - Train loss 29.441 - Valid Loss 159.038\n",
            "Epoch: 78/500 - Train loss 33.588 - Valid Loss 189.374\n",
            "Epoch: 79/500 - Train loss 37.273 - Valid Loss 203.873\n",
            "Epoch: 80/500 - Train loss 39.153 - Valid Loss 200.787\n",
            "Epoch: 81/500 - Train loss 38.644 - Valid Loss 182.056\n",
            "Epoch: 82/500 - Train loss 35.966 - Valid Loss 152.389\n",
            "Epoch: 83/500 - Train loss 31.944 - Valid Loss 117.755\n",
            "Epoch: 84/500 - Train loss 27.660 - Valid Loss 83.806\n",
            "Epoch: 85/500 - Train loss 24.093 - Valid Loss 54.708\n",
            "Epoch: 86/500 - Train loss 21.852 - Valid Loss 32.601\n",
            "Epoch: 87/500 - Train loss 21.071 - Valid Loss 17.705\n",
            "Epoch: 88/500 - Train loss 21.465 - Valid Loss 8.870\n",
            "Epoch: 89/500 - Train loss 22.486 - Valid Loss 4.329\n",
            "Epoch: 90/500 - Train loss 23.525 - Valid Loss 2.382\n",
            "Epoch: 91/500 - Train loss 24.093 - Valid Loss 1.866\n",
            "Epoch: 92/500 - Train loss 23.930 - Valid Loss 2.318\n",
            "Epoch: 93/500 - Train loss 23.036 - Valid Loss 3.866\n",
            "Epoch: 94/500 - Train loss 21.626 - Valid Loss 6.929\n",
            "Epoch: 95/500 - Train loss 20.033 - Valid Loss 11.863\n",
            "Epoch: 96/500 - Train loss 18.593 - Valid Loss 18.666\n",
            "Epoch: 97/500 - Train loss 17.551 - Valid Loss 26.830\n",
            "Epoch: 98/500 - Train loss 16.998 - Valid Loss 35.389\n",
            "Epoch: 99/500 - Train loss 16.873 - Valid Loss 43.125\n",
            "Epoch: 100/500 - Train loss 17.003 - Valid Loss 48.864\n",
            "Epoch: 101/500 - Train loss 17.171 - Valid Loss 51.762\n",
            "Epoch: 102/500 - Train loss 17.191 - Valid Loss 51.495\n",
            "Epoch: 103/500 - Train loss 16.958 - Valid Loss 48.302\n",
            "Epoch: 104/500 - Train loss 16.470 - Valid Loss 42.878\n",
            "Epoch: 105/500 - Train loss 15.808 - Valid Loss 36.171\n",
            "Epoch: 106/500 - Train loss 15.099 - Valid Loss 29.155\n",
            "Epoch: 107/500 - Train loss 14.462 - Valid Loss 22.629\n",
            "Epoch: 108/500 - Train loss 13.979 - Valid Loss 17.119\n",
            "Epoch: 109/500 - Train loss 13.671 - Valid Loss 12.853\n",
            "Epoch: 110/500 - Train loss 13.501 - Valid Loss 9.821\n",
            "Epoch: 111/500 - Train loss 13.402 - Valid Loss 7.876\n",
            "Epoch: 112/500 - Train loss 13.296 - Valid Loss 6.828\n",
            "Epoch: 113/500 - Train loss 13.127 - Valid Loss 6.511\n",
            "Epoch: 114/500 - Train loss 12.868 - Valid Loss 6.809\n",
            "Epoch: 115/500 - Train loss 12.532 - Valid Loss 7.642\n",
            "Epoch: 116/500 - Train loss 12.153 - Valid Loss 8.930\n",
            "Epoch: 117/500 - Train loss 11.777 - Valid Loss 10.560\n",
            "Epoch: 118/500 - Train loss 11.443 - Valid Loss 12.362\n",
            "Epoch: 119/500 - Train loss 11.172 - Valid Loss 14.117\n",
            "Epoch: 120/500 - Train loss 10.960 - Valid Loss 15.590\n",
            "Epoch: 121/500 - Train loss 10.790 - Valid Loss 16.572\n",
            "Epoch: 122/500 - Train loss 10.633 - Valid Loss 16.924\n",
            "Epoch: 123/500 - Train loss 10.464 - Valid Loss 16.605\n",
            "Epoch: 124/500 - Train loss 10.268 - Valid Loss 15.676\n",
            "Epoch: 125/500 - Train loss 10.043 - Valid Loss 14.278\n",
            "Epoch: 126/500 - Train loss 9.799 - Valid Loss 12.602\n",
            "Epoch: 127/500 - Train loss 9.553 - Valid Loss 10.843\n",
            "Epoch: 128/500 - Train loss 9.321 - Valid Loss 9.169\n",
            "Epoch: 129/500 - Train loss 9.112 - Valid Loss 7.700\n",
            "Epoch: 130/500 - Train loss 8.928 - Valid Loss 6.504\n",
            "Epoch: 131/500 - Train loss 8.764 - Valid Loss 5.600\n",
            "Epoch: 132/500 - Train loss 8.608 - Valid Loss 4.979\n",
            "Epoch: 133/500 - Train loss 8.451 - Valid Loss 4.611\n",
            "Epoch: 134/500 - Train loss 8.288 - Valid Loss 4.460\n",
            "Epoch: 135/500 - Train loss 8.115 - Valid Loss 4.487\n",
            "Epoch: 136/500 - Train loss 7.937 - Valid Loss 4.651\n",
            "Epoch: 137/500 - Train loss 7.759 - Valid Loss 4.904\n",
            "Epoch: 138/500 - Train loss 7.588 - Valid Loss 5.196\n",
            "Epoch: 139/500 - Train loss 7.426 - Valid Loss 5.470\n",
            "Epoch: 140/500 - Train loss 7.276 - Valid Loss 5.675\n",
            "Epoch: 141/500 - Train loss 7.135 - Valid Loss 5.767\n",
            "Epoch: 142/500 - Train loss 6.998 - Valid Loss 5.719\n",
            "Epoch: 143/500 - Train loss 6.864 - Valid Loss 5.525\n",
            "Epoch: 144/500 - Train loss 6.728 - Valid Loss 5.201\n",
            "Epoch: 145/500 - Train loss 6.590 - Valid Loss 4.778\n",
            "Epoch: 146/500 - Train loss 6.452 - Valid Loss 4.296\n",
            "Epoch: 147/500 - Train loss 6.317 - Valid Loss 3.799\n",
            "Epoch: 148/500 - Train loss 6.185 - Valid Loss 3.324\n",
            "Epoch: 149/500 - Train loss 6.059 - Valid Loss 2.899\n",
            "Epoch: 150/500 - Train loss 5.938 - Valid Loss 2.541\n",
            "Epoch: 151/500 - Train loss 5.822 - Valid Loss 2.257\n",
            "Epoch: 152/500 - Train loss 5.708 - Valid Loss 2.044\n",
            "Epoch: 153/500 - Train loss 5.597 - Valid Loss 1.896\n",
            "Epoch: 154/500 - Train loss 5.486 - Valid Loss 1.803\n",
            "Epoch: 155/500 - Train loss 5.377 - Valid Loss 1.752\n",
            "Epoch: 156/500 - Train loss 5.268 - Valid Loss 1.730\n",
            "Epoch: 157/500 - Train loss 5.162 - Valid Loss 1.724\n",
            "Epoch: 158/500 - Train loss 5.059 - Valid Loss 1.721\n",
            "Epoch: 159/500 - Train loss 4.959 - Valid Loss 1.707\n",
            "Epoch: 160/500 - Train loss 4.863 - Valid Loss 1.674\n",
            "Epoch: 161/500 - Train loss 4.769 - Valid Loss 1.615\n",
            "Epoch: 162/500 - Train loss 4.677 - Valid Loss 1.530\n",
            "Epoch: 163/500 - Train loss 4.587 - Valid Loss 1.420\n",
            "Epoch: 164/500 - Train loss 4.498 - Valid Loss 1.292\n",
            "Epoch: 165/500 - Train loss 4.411 - Valid Loss 1.155\n",
            "Epoch: 166/500 - Train loss 4.326 - Valid Loss 1.017\n",
            "Epoch: 167/500 - Train loss 4.243 - Valid Loss 0.886\n",
            "Epoch: 168/500 - Train loss 4.161 - Valid Loss 0.769\n",
            "Epoch: 169/500 - Train loss 4.083 - Valid Loss 0.668\n",
            "Epoch: 170/500 - Train loss 4.006 - Valid Loss 0.585\n",
            "Epoch: 171/500 - Train loss 3.931 - Valid Loss 0.519\n",
            "Epoch: 172/500 - Train loss 3.858 - Valid Loss 0.468\n",
            "Epoch: 173/500 - Train loss 3.786 - Valid Loss 0.429\n",
            "Epoch: 174/500 - Train loss 3.716 - Valid Loss 0.400\n",
            "Epoch: 175/500 - Train loss 3.647 - Valid Loss 0.377\n",
            "Epoch: 176/500 - Train loss 3.580 - Valid Loss 0.357\n",
            "Epoch: 177/500 - Train loss 3.515 - Valid Loss 0.339\n",
            "Epoch: 178/500 - Train loss 3.451 - Valid Loss 0.321\n",
            "Epoch: 179/500 - Train loss 3.389 - Valid Loss 0.301\n",
            "Epoch: 180/500 - Train loss 3.329 - Valid Loss 0.280\n",
            "Epoch: 181/500 - Train loss 3.270 - Valid Loss 0.257\n",
            "Epoch: 182/500 - Train loss 3.212 - Valid Loss 0.234\n",
            "Epoch: 183/500 - Train loss 3.156 - Valid Loss 0.213\n",
            "Epoch: 184/500 - Train loss 3.100 - Valid Loss 0.193\n",
            "Epoch: 185/500 - Train loss 3.047 - Valid Loss 0.178\n",
            "Epoch: 186/500 - Train loss 2.994 - Valid Loss 0.167\n",
            "Epoch: 187/500 - Train loss 2.943 - Valid Loss 0.161\n",
            "Epoch: 188/500 - Train loss 2.893 - Valid Loss 0.159\n",
            "Epoch: 189/500 - Train loss 2.845 - Valid Loss 0.160\n",
            "Epoch: 190/500 - Train loss 2.797 - Valid Loss 0.165\n",
            "Epoch: 191/500 - Train loss 2.751 - Valid Loss 0.171\n",
            "Epoch: 192/500 - Train loss 2.706 - Valid Loss 0.179\n",
            "Epoch: 193/500 - Train loss 2.662 - Valid Loss 0.188\n",
            "Epoch: 194/500 - Train loss 2.619 - Valid Loss 0.198\n",
            "Epoch: 195/500 - Train loss 2.577 - Valid Loss 0.210\n",
            "Epoch: 196/500 - Train loss 2.537 - Valid Loss 0.222\n",
            "Epoch: 197/500 - Train loss 2.497 - Valid Loss 0.236\n",
            "Epoch: 198/500 - Train loss 2.458 - Valid Loss 0.253\n",
            "Epoch: 199/500 - Train loss 2.420 - Valid Loss 0.272\n",
            "Epoch: 200/500 - Train loss 2.384 - Valid Loss 0.293\n",
            "Epoch: 201/500 - Train loss 2.348 - Valid Loss 0.318\n",
            "Epoch: 202/500 - Train loss 2.313 - Valid Loss 0.345\n",
            "Epoch: 203/500 - Train loss 2.279 - Valid Loss 0.375\n",
            "Epoch: 204/500 - Train loss 2.246 - Valid Loss 0.406\n",
            "Epoch: 205/500 - Train loss 2.213 - Valid Loss 0.440\n",
            "Epoch: 206/500 - Train loss 2.182 - Valid Loss 0.474\n",
            "Epoch: 207/500 - Train loss 2.151 - Valid Loss 0.509\n",
            "Epoch: 208/500 - Train loss 2.121 - Valid Loss 0.544\n",
            "Epoch: 209/500 - Train loss 2.092 - Valid Loss 0.578\n",
            "Epoch: 210/500 - Train loss 2.063 - Valid Loss 0.612\n",
            "Epoch: 211/500 - Train loss 2.036 - Valid Loss 0.646\n",
            "Epoch: 212/500 - Train loss 2.009 - Valid Loss 0.680\n",
            "Epoch: 213/500 - Train loss 1.983 - Valid Loss 0.714\n",
            "Epoch: 214/500 - Train loss 1.957 - Valid Loss 0.749\n",
            "Epoch: 215/500 - Train loss 1.932 - Valid Loss 0.786\n",
            "Epoch: 216/500 - Train loss 1.908 - Valid Loss 0.825\n",
            "Epoch: 217/500 - Train loss 1.884 - Valid Loss 0.865\n",
            "Epoch: 218/500 - Train loss 1.861 - Valid Loss 0.907\n",
            "Epoch: 219/500 - Train loss 1.839 - Valid Loss 0.952\n",
            "Epoch: 220/500 - Train loss 1.817 - Valid Loss 0.997\n",
            "Epoch: 221/500 - Train loss 1.796 - Valid Loss 1.044\n",
            "Epoch: 222/500 - Train loss 1.775 - Valid Loss 1.092\n",
            "Epoch: 223/500 - Train loss 1.755 - Valid Loss 1.140\n",
            "Epoch: 224/500 - Train loss 1.735 - Valid Loss 1.188\n",
            "Epoch: 225/500 - Train loss 1.716 - Valid Loss 1.235\n",
            "Epoch: 226/500 - Train loss 1.698 - Valid Loss 1.282\n",
            "Epoch: 227/500 - Train loss 1.679 - Valid Loss 1.328\n",
            "Epoch: 228/500 - Train loss 1.662 - Valid Loss 1.373\n",
            "Epoch: 229/500 - Train loss 1.645 - Valid Loss 1.418\n",
            "Epoch: 230/500 - Train loss 1.628 - Valid Loss 1.463\n",
            "Epoch: 231/500 - Train loss 1.612 - Valid Loss 1.508\n",
            "Epoch: 232/500 - Train loss 1.596 - Valid Loss 1.554\n",
            "Epoch: 233/500 - Train loss 1.580 - Valid Loss 1.601\n",
            "Epoch: 234/500 - Train loss 1.565 - Valid Loss 1.648\n",
            "Epoch: 235/500 - Train loss 1.551 - Valid Loss 1.696\n",
            "Epoch: 236/500 - Train loss 1.537 - Valid Loss 1.746\n",
            "Epoch: 237/500 - Train loss 1.523 - Valid Loss 1.796\n",
            "Epoch: 238/500 - Train loss 1.509 - Valid Loss 1.846\n",
            "Epoch: 239/500 - Train loss 1.496 - Valid Loss 1.897\n",
            "Epoch: 240/500 - Train loss 1.483 - Valid Loss 1.947\n",
            "Epoch: 241/500 - Train loss 1.471 - Valid Loss 1.997\n",
            "Epoch: 242/500 - Train loss 1.459 - Valid Loss 2.047\n",
            "Epoch: 243/500 - Train loss 1.447 - Valid Loss 2.096\n",
            "Epoch: 244/500 - Train loss 1.435 - Valid Loss 2.144\n",
            "Epoch: 245/500 - Train loss 1.424 - Valid Loss 2.192\n",
            "Epoch: 246/500 - Train loss 1.413 - Valid Loss 2.239\n",
            "Epoch: 247/500 - Train loss 1.403 - Valid Loss 2.286\n",
            "Epoch: 248/500 - Train loss 1.392 - Valid Loss 2.332\n",
            "Epoch: 249/500 - Train loss 1.382 - Valid Loss 2.379\n",
            "Epoch: 250/500 - Train loss 1.373 - Valid Loss 2.426\n",
            "Epoch: 251/500 - Train loss 1.363 - Valid Loss 2.473\n",
            "Epoch: 252/500 - Train loss 1.354 - Valid Loss 2.521\n",
            "Epoch: 253/500 - Train loss 1.345 - Valid Loss 2.569\n",
            "Epoch: 254/500 - Train loss 1.336 - Valid Loss 2.616\n",
            "Epoch: 255/500 - Train loss 1.327 - Valid Loss 2.664\n",
            "Epoch: 256/500 - Train loss 1.319 - Valid Loss 2.712\n",
            "Epoch: 257/500 - Train loss 1.311 - Valid Loss 2.759\n",
            "Epoch: 258/500 - Train loss 1.303 - Valid Loss 2.805\n",
            "Epoch: 259/500 - Train loss 1.295 - Valid Loss 2.852\n",
            "Epoch: 260/500 - Train loss 1.287 - Valid Loss 2.897\n",
            "Epoch: 261/500 - Train loss 1.280 - Valid Loss 2.942\n",
            "Epoch: 262/500 - Train loss 1.273 - Valid Loss 2.987\n",
            "Epoch: 263/500 - Train loss 1.266 - Valid Loss 3.031\n",
            "Epoch: 264/500 - Train loss 1.259 - Valid Loss 3.074\n",
            "Epoch: 265/500 - Train loss 1.252 - Valid Loss 3.118\n",
            "Epoch: 266/500 - Train loss 1.246 - Valid Loss 3.161\n",
            "Epoch: 267/500 - Train loss 1.240 - Valid Loss 3.204\n",
            "Epoch: 268/500 - Train loss 1.234 - Valid Loss 3.246\n",
            "Epoch: 269/500 - Train loss 1.227 - Valid Loss 3.289\n",
            "Epoch: 270/500 - Train loss 1.222 - Valid Loss 3.332\n",
            "Epoch: 271/500 - Train loss 1.216 - Valid Loss 3.374\n",
            "Epoch: 272/500 - Train loss 1.210 - Valid Loss 3.416\n",
            "Epoch: 273/500 - Train loss 1.205 - Valid Loss 3.458\n",
            "Epoch: 274/500 - Train loss 1.199 - Valid Loss 3.499\n",
            "Epoch: 275/500 - Train loss 1.194 - Valid Loss 3.540\n",
            "Epoch: 276/500 - Train loss 1.189 - Valid Loss 3.580\n",
            "Epoch: 277/500 - Train loss 1.184 - Valid Loss 3.620\n",
            "Epoch: 278/500 - Train loss 1.179 - Valid Loss 3.659\n",
            "Epoch: 279/500 - Train loss 1.175 - Valid Loss 3.697\n",
            "Epoch: 280/500 - Train loss 1.170 - Valid Loss 3.736\n",
            "Epoch: 281/500 - Train loss 1.165 - Valid Loss 3.773\n",
            "Epoch: 282/500 - Train loss 1.161 - Valid Loss 3.811\n",
            "Epoch: 283/500 - Train loss 1.157 - Valid Loss 3.848\n",
            "Epoch: 284/500 - Train loss 1.152 - Valid Loss 3.885\n",
            "Epoch: 285/500 - Train loss 1.148 - Valid Loss 3.921\n",
            "Epoch: 286/500 - Train loss 1.144 - Valid Loss 3.958\n",
            "Epoch: 287/500 - Train loss 1.140 - Valid Loss 3.993\n",
            "Epoch: 288/500 - Train loss 1.136 - Valid Loss 4.029\n",
            "Epoch: 289/500 - Train loss 1.132 - Valid Loss 4.064\n",
            "Epoch: 290/500 - Train loss 1.129 - Valid Loss 4.099\n",
            "Epoch: 291/500 - Train loss 1.125 - Valid Loss 4.133\n",
            "Epoch: 292/500 - Train loss 1.121 - Valid Loss 4.167\n",
            "Epoch: 293/500 - Train loss 1.118 - Valid Loss 4.201\n",
            "Epoch: 294/500 - Train loss 1.114 - Valid Loss 4.233\n",
            "Epoch: 295/500 - Train loss 1.111 - Valid Loss 4.266\n",
            "Epoch: 296/500 - Train loss 1.108 - Valid Loss 4.298\n",
            "Epoch: 297/500 - Train loss 1.104 - Valid Loss 4.330\n",
            "Epoch: 298/500 - Train loss 1.101 - Valid Loss 4.361\n",
            "Epoch: 299/500 - Train loss 1.098 - Valid Loss 4.391\n",
            "Epoch: 300/500 - Train loss 1.095 - Valid Loss 4.422\n",
            "Epoch: 301/500 - Train loss 1.092 - Valid Loss 4.452\n",
            "Epoch: 302/500 - Train loss 1.089 - Valid Loss 4.482\n",
            "Epoch: 303/500 - Train loss 1.086 - Valid Loss 4.512\n",
            "Epoch: 304/500 - Train loss 1.083 - Valid Loss 4.541\n",
            "Epoch: 305/500 - Train loss 1.080 - Valid Loss 4.569\n",
            "Epoch: 306/500 - Train loss 1.077 - Valid Loss 4.598\n",
            "Epoch: 307/500 - Train loss 1.075 - Valid Loss 4.626\n",
            "Epoch: 308/500 - Train loss 1.072 - Valid Loss 4.653\n",
            "Epoch: 309/500 - Train loss 1.069 - Valid Loss 4.680\n",
            "Epoch: 310/500 - Train loss 1.067 - Valid Loss 4.707\n",
            "Epoch: 311/500 - Train loss 1.064 - Valid Loss 4.733\n",
            "Epoch: 312/500 - Train loss 1.062 - Valid Loss 4.759\n",
            "Epoch: 313/500 - Train loss 1.059 - Valid Loss 4.785\n",
            "Epoch: 314/500 - Train loss 1.057 - Valid Loss 4.810\n",
            "Epoch: 315/500 - Train loss 1.054 - Valid Loss 4.835\n",
            "Epoch: 316/500 - Train loss 1.052 - Valid Loss 4.859\n",
            "Epoch: 317/500 - Train loss 1.049 - Valid Loss 4.884\n",
            "Epoch: 318/500 - Train loss 1.047 - Valid Loss 4.908\n",
            "Epoch: 319/500 - Train loss 1.045 - Valid Loss 4.931\n",
            "Epoch: 320/500 - Train loss 1.042 - Valid Loss 4.954\n",
            "Epoch: 321/500 - Train loss 1.040 - Valid Loss 4.977\n",
            "Epoch: 322/500 - Train loss 1.038 - Valid Loss 5.000\n",
            "Epoch: 323/500 - Train loss 1.035 - Valid Loss 5.022\n",
            "Epoch: 324/500 - Train loss 1.033 - Valid Loss 5.044\n",
            "Epoch: 325/500 - Train loss 1.031 - Valid Loss 5.065\n",
            "Epoch: 326/500 - Train loss 1.029 - Valid Loss 5.086\n",
            "Epoch: 327/500 - Train loss 1.027 - Valid Loss 5.107\n",
            "Epoch: 328/500 - Train loss 1.025 - Valid Loss 5.128\n",
            "Epoch: 329/500 - Train loss 1.023 - Valid Loss 5.148\n",
            "Epoch: 330/500 - Train loss 1.020 - Valid Loss 5.168\n",
            "Epoch: 331/500 - Train loss 1.018 - Valid Loss 5.187\n",
            "Epoch: 332/500 - Train loss 1.016 - Valid Loss 5.206\n",
            "Epoch: 333/500 - Train loss 1.014 - Valid Loss 5.225\n",
            "Epoch: 334/500 - Train loss 1.012 - Valid Loss 5.244\n",
            "Epoch: 335/500 - Train loss 1.010 - Valid Loss 5.262\n",
            "Epoch: 336/500 - Train loss 1.008 - Valid Loss 5.281\n",
            "Epoch: 337/500 - Train loss 1.006 - Valid Loss 5.298\n",
            "Epoch: 338/500 - Train loss 1.004 - Valid Loss 5.316\n",
            "Epoch: 339/500 - Train loss 1.002 - Valid Loss 5.333\n",
            "Epoch: 340/500 - Train loss 1.000 - Valid Loss 5.350\n",
            "Epoch: 341/500 - Train loss 0.999 - Valid Loss 5.366\n",
            "Epoch: 342/500 - Train loss 0.997 - Valid Loss 5.383\n",
            "Epoch: 343/500 - Train loss 0.995 - Valid Loss 5.399\n",
            "Epoch: 344/500 - Train loss 0.993 - Valid Loss 5.415\n",
            "Epoch: 345/500 - Train loss 0.991 - Valid Loss 5.430\n",
            "Epoch: 346/500 - Train loss 0.989 - Valid Loss 5.446\n",
            "Epoch: 347/500 - Train loss 0.987 - Valid Loss 5.461\n",
            "Epoch: 348/500 - Train loss 0.985 - Valid Loss 5.475\n",
            "Epoch: 349/500 - Train loss 0.984 - Valid Loss 5.490\n",
            "Epoch: 350/500 - Train loss 0.982 - Valid Loss 5.504\n",
            "Epoch: 351/500 - Train loss 0.980 - Valid Loss 5.518\n",
            "Epoch: 352/500 - Train loss 0.978 - Valid Loss 5.532\n",
            "Epoch: 353/500 - Train loss 0.976 - Valid Loss 5.546\n",
            "Epoch: 354/500 - Train loss 0.975 - Valid Loss 5.559\n",
            "Epoch: 355/500 - Train loss 0.973 - Valid Loss 5.572\n",
            "Epoch: 356/500 - Train loss 0.971 - Valid Loss 5.585\n",
            "Epoch: 357/500 - Train loss 0.969 - Valid Loss 5.598\n",
            "Epoch: 358/500 - Train loss 0.967 - Valid Loss 5.610\n",
            "Epoch: 359/500 - Train loss 0.966 - Valid Loss 5.622\n",
            "Epoch: 360/500 - Train loss 0.964 - Valid Loss 5.634\n",
            "Epoch: 361/500 - Train loss 0.962 - Valid Loss 5.646\n",
            "Epoch: 362/500 - Train loss 0.960 - Valid Loss 5.658\n",
            "Epoch: 363/500 - Train loss 0.959 - Valid Loss 5.669\n",
            "Epoch: 364/500 - Train loss 0.957 - Valid Loss 5.680\n",
            "Epoch: 365/500 - Train loss 0.955 - Valid Loss 5.691\n",
            "Epoch: 366/500 - Train loss 0.953 - Valid Loss 5.702\n",
            "Epoch: 367/500 - Train loss 0.952 - Valid Loss 5.713\n",
            "Epoch: 368/500 - Train loss 0.950 - Valid Loss 5.723\n",
            "Epoch: 369/500 - Train loss 0.948 - Valid Loss 5.733\n",
            "Epoch: 370/500 - Train loss 0.947 - Valid Loss 5.743\n",
            "Epoch: 371/500 - Train loss 0.945 - Valid Loss 5.753\n",
            "Epoch: 372/500 - Train loss 0.943 - Valid Loss 5.763\n",
            "Epoch: 373/500 - Train loss 0.941 - Valid Loss 5.772\n",
            "Epoch: 374/500 - Train loss 0.940 - Valid Loss 5.781\n",
            "Epoch: 375/500 - Train loss 0.938 - Valid Loss 5.790\n",
            "Epoch: 376/500 - Train loss 0.936 - Valid Loss 5.799\n",
            "Epoch: 377/500 - Train loss 0.935 - Valid Loss 5.808\n",
            "Epoch: 378/500 - Train loss 0.933 - Valid Loss 5.817\n",
            "Epoch: 379/500 - Train loss 0.931 - Valid Loss 5.825\n",
            "Epoch: 380/500 - Train loss 0.930 - Valid Loss 5.834\n",
            "Epoch: 381/500 - Train loss 0.928 - Valid Loss 5.842\n",
            "Epoch: 382/500 - Train loss 0.926 - Valid Loss 5.850\n",
            "Epoch: 383/500 - Train loss 0.925 - Valid Loss 5.858\n",
            "Epoch: 384/500 - Train loss 0.923 - Valid Loss 5.865\n",
            "Epoch: 385/500 - Train loss 0.921 - Valid Loss 5.873\n",
            "Epoch: 386/500 - Train loss 0.920 - Valid Loss 5.880\n",
            "Epoch: 387/500 - Train loss 0.918 - Valid Loss 5.887\n",
            "Epoch: 388/500 - Train loss 0.916 - Valid Loss 5.894\n",
            "Epoch: 389/500 - Train loss 0.915 - Valid Loss 5.901\n",
            "Epoch: 390/500 - Train loss 0.913 - Valid Loss 5.908\n",
            "Epoch: 391/500 - Train loss 0.911 - Valid Loss 5.915\n",
            "Epoch: 392/500 - Train loss 0.910 - Valid Loss 5.922\n",
            "Epoch: 393/500 - Train loss 0.908 - Valid Loss 5.928\n",
            "Epoch: 394/500 - Train loss 0.906 - Valid Loss 5.934\n",
            "Epoch: 395/500 - Train loss 0.904 - Valid Loss 5.940\n",
            "Epoch: 396/500 - Train loss 0.903 - Valid Loss 5.947\n",
            "Epoch: 397/500 - Train loss 0.901 - Valid Loss 5.952\n",
            "Epoch: 398/500 - Train loss 0.899 - Valid Loss 5.958\n",
            "Epoch: 399/500 - Train loss 0.898 - Valid Loss 5.964\n",
            "Epoch: 400/500 - Train loss 0.896 - Valid Loss 5.970\n",
            "Epoch: 401/500 - Train loss 0.894 - Valid Loss 5.975\n",
            "Epoch: 402/500 - Train loss 0.893 - Valid Loss 5.980\n",
            "Epoch: 403/500 - Train loss 0.891 - Valid Loss 5.986\n",
            "Epoch: 404/500 - Train loss 0.889 - Valid Loss 5.991\n",
            "Epoch: 405/500 - Train loss 0.888 - Valid Loss 5.996\n",
            "Epoch: 406/500 - Train loss 0.886 - Valid Loss 6.001\n",
            "Epoch: 407/500 - Train loss 0.884 - Valid Loss 6.006\n",
            "Epoch: 408/500 - Train loss 0.883 - Valid Loss 6.010\n",
            "Epoch: 409/500 - Train loss 0.881 - Valid Loss 6.015\n",
            "Epoch: 410/500 - Train loss 0.879 - Valid Loss 6.020\n",
            "Epoch: 411/500 - Train loss 0.878 - Valid Loss 6.024\n",
            "Epoch: 412/500 - Train loss 0.876 - Valid Loss 6.028\n",
            "Epoch: 413/500 - Train loss 0.875 - Valid Loss 6.033\n",
            "Epoch: 414/500 - Train loss 0.873 - Valid Loss 6.037\n",
            "Epoch: 415/500 - Train loss 0.871 - Valid Loss 6.041\n",
            "Epoch: 416/500 - Train loss 0.869 - Valid Loss 6.045\n",
            "Epoch: 417/500 - Train loss 0.868 - Valid Loss 6.049\n",
            "Epoch: 418/500 - Train loss 0.866 - Valid Loss 6.053\n",
            "Epoch: 419/500 - Train loss 0.865 - Valid Loss 6.057\n",
            "Epoch: 420/500 - Train loss 0.863 - Valid Loss 6.060\n",
            "Epoch: 421/500 - Train loss 0.861 - Valid Loss 6.064\n",
            "Epoch: 422/500 - Train loss 0.860 - Valid Loss 6.068\n",
            "Epoch: 423/500 - Train loss 0.858 - Valid Loss 6.071\n",
            "Epoch: 424/500 - Train loss 0.856 - Valid Loss 6.074\n",
            "Epoch: 425/500 - Train loss 0.855 - Valid Loss 6.078\n",
            "Epoch: 426/500 - Train loss 0.853 - Valid Loss 6.081\n",
            "Epoch: 427/500 - Train loss 0.851 - Valid Loss 6.084\n",
            "Epoch: 428/500 - Train loss 0.850 - Valid Loss 6.087\n",
            "Epoch: 429/500 - Train loss 0.848 - Valid Loss 6.090\n",
            "Epoch: 430/500 - Train loss 0.846 - Valid Loss 6.093\n",
            "Epoch: 431/500 - Train loss 0.844 - Valid Loss 6.096\n",
            "Epoch: 432/500 - Train loss 0.843 - Valid Loss 6.099\n",
            "Epoch: 433/500 - Train loss 0.841 - Valid Loss 6.102\n",
            "Epoch: 434/500 - Train loss 0.839 - Valid Loss 6.104\n",
            "Epoch: 435/500 - Train loss 0.838 - Valid Loss 6.107\n",
            "Epoch: 436/500 - Train loss 0.836 - Valid Loss 6.110\n",
            "Epoch: 437/500 - Train loss 0.834 - Valid Loss 6.112\n",
            "Epoch: 438/500 - Train loss 0.833 - Valid Loss 6.115\n",
            "Epoch: 439/500 - Train loss 0.831 - Valid Loss 6.117\n",
            "Epoch: 440/500 - Train loss 0.829 - Valid Loss 6.120\n",
            "Epoch: 441/500 - Train loss 0.828 - Valid Loss 6.122\n",
            "Epoch: 442/500 - Train loss 0.826 - Valid Loss 6.124\n",
            "Epoch: 443/500 - Train loss 0.824 - Valid Loss 6.126\n",
            "Epoch: 444/500 - Train loss 0.823 - Valid Loss 6.128\n",
            "Epoch: 445/500 - Train loss 0.821 - Valid Loss 6.131\n",
            "Epoch: 446/500 - Train loss 0.819 - Valid Loss 6.132\n",
            "Epoch: 447/500 - Train loss 0.818 - Valid Loss 6.135\n",
            "Epoch: 448/500 - Train loss 0.816 - Valid Loss 6.137\n",
            "Epoch: 449/500 - Train loss 0.814 - Valid Loss 6.138\n",
            "Epoch: 450/500 - Train loss 0.813 - Valid Loss 6.140\n",
            "Epoch: 451/500 - Train loss 0.811 - Valid Loss 6.142\n",
            "Epoch: 452/500 - Train loss 0.809 - Valid Loss 6.144\n",
            "Epoch: 453/500 - Train loss 0.808 - Valid Loss 6.146\n",
            "Epoch: 454/500 - Train loss 0.806 - Valid Loss 6.147\n",
            "Epoch: 455/500 - Train loss 0.804 - Valid Loss 6.149\n",
            "Epoch: 456/500 - Train loss 0.803 - Valid Loss 6.151\n",
            "Epoch: 457/500 - Train loss 0.801 - Valid Loss 6.152\n",
            "Epoch: 458/500 - Train loss 0.799 - Valid Loss 6.154\n",
            "Epoch: 459/500 - Train loss 0.798 - Valid Loss 6.155\n",
            "Epoch: 460/500 - Train loss 0.796 - Valid Loss 6.157\n",
            "Epoch: 461/500 - Train loss 0.794 - Valid Loss 6.158\n",
            "Epoch: 462/500 - Train loss 0.793 - Valid Loss 6.159\n",
            "Epoch: 463/500 - Train loss 0.791 - Valid Loss 6.161\n",
            "Epoch: 464/500 - Train loss 0.789 - Valid Loss 6.162\n",
            "Epoch: 465/500 - Train loss 0.788 - Valid Loss 6.163\n",
            "Epoch: 466/500 - Train loss 0.786 - Valid Loss 6.165\n",
            "Epoch: 467/500 - Train loss 0.784 - Valid Loss 6.166\n",
            "Epoch: 468/500 - Train loss 0.782 - Valid Loss 6.167\n",
            "Epoch: 469/500 - Train loss 0.781 - Valid Loss 6.168\n",
            "Epoch: 470/500 - Train loss 0.779 - Valid Loss 6.169\n",
            "Epoch: 471/500 - Train loss 0.777 - Valid Loss 6.170\n",
            "Epoch: 472/500 - Train loss 0.776 - Valid Loss 6.171\n",
            "Epoch: 473/500 - Train loss 0.774 - Valid Loss 6.173\n",
            "Epoch: 474/500 - Train loss 0.772 - Valid Loss 6.173\n",
            "Epoch: 475/500 - Train loss 0.771 - Valid Loss 6.174\n",
            "Epoch: 476/500 - Train loss 0.769 - Valid Loss 6.175\n",
            "Epoch: 477/500 - Train loss 0.767 - Valid Loss 6.176\n",
            "Epoch: 478/500 - Train loss 0.766 - Valid Loss 6.177\n",
            "Epoch: 479/500 - Train loss 0.764 - Valid Loss 6.178\n",
            "Epoch: 480/500 - Train loss 0.762 - Valid Loss 6.179\n",
            "Epoch: 481/500 - Train loss 0.761 - Valid Loss 6.179\n",
            "Epoch: 482/500 - Train loss 0.759 - Valid Loss 6.180\n",
            "Epoch: 483/500 - Train loss 0.757 - Valid Loss 6.181\n",
            "Epoch: 484/500 - Train loss 0.756 - Valid Loss 6.182\n",
            "Epoch: 485/500 - Train loss 0.754 - Valid Loss 6.182\n",
            "Epoch: 486/500 - Train loss 0.752 - Valid Loss 6.183\n",
            "Epoch: 487/500 - Train loss 0.751 - Valid Loss 6.184\n",
            "Epoch: 488/500 - Train loss 0.749 - Valid Loss 6.184\n",
            "Epoch: 489/500 - Train loss 0.747 - Valid Loss 6.185\n",
            "Epoch: 490/500 - Train loss 0.745 - Valid Loss 6.186\n",
            "Epoch: 491/500 - Train loss 0.744 - Valid Loss 6.186\n",
            "Epoch: 492/500 - Train loss 0.742 - Valid Loss 6.187\n",
            "Epoch: 493/500 - Train loss 0.740 - Valid Loss 6.187\n",
            "Epoch: 494/500 - Train loss 0.739 - Valid Loss 6.188\n",
            "Epoch: 495/500 - Train loss 0.737 - Valid Loss 6.188\n",
            "Epoch: 496/500 - Train loss 0.735 - Valid Loss 6.189\n",
            "Epoch: 497/500 - Train loss 0.734 - Valid Loss 6.189\n",
            "Epoch: 498/500 - Train loss 0.732 - Valid Loss 6.189\n",
            "Epoch: 499/500 - Train loss 0.730 - Valid Loss 6.190\n",
            "Epoch: 500/500 - Train loss 0.729 - Valid Loss 6.190\n"
          ]
        }
      ],
      "source": [
        "history3 = train(model3,\n",
        "                train_loader,\n",
        "                valid_loader,\n",
        "                model3_optimizer,\n",
        "                model3_criterion,\n",
        "                epochs=500\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KOSVDSBeo1A",
        "outputId": "376ebf2b-4ca7-494a-869e-b7531314b41f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epoch_count = range(1, len(history3['loss']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history3['loss'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history3['val_loss'], label='valid')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FveVOv2xzfkC",
        "outputId": "7d9f8d81-e544-4049-f14e-1bc1679c08ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_test: 450\n",
            "y_hat: tensor([[437.8927]], grad_fn=<AddmmBackward0>)\n",
            "loss: 146.5874481201172\n"
          ]
        }
      ],
      "source": [
        "# Ensayo\n",
        "# x = 30\n",
        "# y_test = x * 15\n",
        "\n",
        "x_test = 30\n",
        "y_test = x_test * 15\n",
        "test_input = np.array([x_test])\n",
        "test_input = test_input.reshape((1, seq_length, input_size))\n",
        "test_input = torch.from_numpy(test_input.astype(np.float32))\n",
        "\n",
        "test_target = torch.from_numpy(np.array(y_test).astype(np.int32)).float().view(-1, 1)\n",
        "\n",
        "y_hat = model3(test_input)\n",
        "\n",
        "print(\"y_test:\", y_test)\n",
        "print(\"y_hat:\", y_hat)\n",
        "\n",
        "loss = model3_criterion(y_hat, test_target).item()\n",
        "print(\"loss:\", loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd1g5MZfz5qB"
      },
      "source": [
        "### 4 - Conclusión\n",
        "El resultado alcanzado es bueno pero podría mejorarse agregando más layer LSTM o más layer fully connected."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "4a - one-to-one.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
