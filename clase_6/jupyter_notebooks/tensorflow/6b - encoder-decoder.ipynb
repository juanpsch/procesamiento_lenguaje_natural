{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfa39F4lsLf3"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## LSTM encoder-decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqO0PRcFsPTe"
   },
   "source": [
    "### 1 - Datos\n",
    "El objecto es utilizar una serie de sucuencias númericas (datos sintéticos) para poner a prueba el uso de las redes LSTM. Este ejemplo se inspiró en otro artículo, lo tienen como referencia en el siguiente link:\\\n",
    "[LINK](https://stackabuse.com/solving-sequence-problems-with-lstm-in-keras-part-2/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cq3YXak9sGHd"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, SimpleRNN\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-9aNLZBDtA5J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datos X (len=60): [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200, 205, 210, 215, 220, 225, 230, 235, 240, 245, 250, 255, 260, 265, 270, 275, 280, 285, 290, 295, 300]\n",
      "datos y (len=60): [20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200, 205, 210, 215, 220, 225, 230, 235, 240, 245, 250, 255, 260, 265, 270, 275, 280, 285, 290, 295, 300, 305, 310, 315]\n"
     ]
    }
   ],
   "source": [
    "# Generar datos sintéticos\n",
    "X = list()\n",
    "y = list()\n",
    "\n",
    "# En ambos casos \"X\" e \"y\" son vectores de números de 5 en 5\n",
    "X = [x for x in range(5, 301, 5)]\n",
    "y = [x+15 for x in X]\n",
    "\n",
    "print(f\"datos X (len={len(X)}):\", X)\n",
    "print(f\"datos y (len={len(y)}):\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5ACkrI0GtEAM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datos X[0:2]: [[[ 5]\n",
      "  [10]\n",
      "  [15]]\n",
      "\n",
      " [[20]\n",
      "  [25]\n",
      "  [30]]]\n",
      "datos y[0:2]: [[[20]\n",
      "  [25]\n",
      "  [30]]\n",
      "\n",
      " [[35]\n",
      "  [40]\n",
      "  [45]]]\n"
     ]
    }
   ],
   "source": [
    "# Se desea agrupar los datos de a 3 elementos\n",
    "X = np.array(X).reshape(len(X)//3, 3, 1)\n",
    "y = np.array(y).reshape(len(y)//3, 3, 1)\n",
    "print(\"datos X[0:2]:\", X[0:2])\n",
    "print(\"datos y[0:2]:\", y[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ajykLcJ8tFfN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (20, 3, 1)\n",
      "y shape: (20, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Verificamos que la secuencia entrada es igual a la secuencia de salida\n",
    "# en cuanto a dimensiones\n",
    "# Tendremos:\n",
    "#  --> veinte grupos de datos (rows) (20)\n",
    "#  --> cada grupo compuesto por tres elementos (3)\n",
    "#  --> cada elemento representado en una sola dimensión (1)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZz9Zsvy5ilc"
   },
   "source": [
    "### 2 - Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nCTu6NElI1ge"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   5,  10,  15,  20,  25,  30,  35,  40,  45,  50,  55,  60,\n",
       "        65,  70,  75,  80,  85,  90,  95, 100, 105, 110, 115, 120, 125,\n",
       "       130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190,\n",
       "       195, 200, 205, 210, 215, 220, 225, 230, 235, 240, 245, 250, 255,\n",
       "       260, 265, 270, 275, 280, 285, 290, 295, 300, 305, 310, 315])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "# Armar el \"corpus\" de números\n",
    "data = np.append(X, y)\n",
    "\n",
    "# Identificar el vocabulario del corpus (todos los números únicos)\n",
    "labels = list(np.unique(data))\n",
    "\n",
    "# Al vocabulario (labels) agregarle el token de inicio de secuencia\n",
    "# Se utiliza el número \"0\" para el <sos>, aprovechando que el \"0\"\n",
    "# no se encuentra en el vocabulario\n",
    "# En este ejemplo todavía no vamos a usar un token especial de <eos>\n",
    "# ya que siempre queremos inferir una secuencia de tamaño fijo \n",
    "# a la salida del decoder\n",
    "labels = [0] + labels # <sos> + vocabulario\n",
    "\n",
    "# LabelEncoder transforma el dato al token correspondiente\n",
    "# Ahora cada número cumple el rol de un término de un corpus\n",
    "# y tendrá su índice asociado después de pasar por una tokenización\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(labels)\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "J86H4qb6NEQp"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Preparar datos para consumir por la layers LSTM\n",
    "# Por cada dato de X e Y se genera su contraparte oneHotEncoding\n",
    "# X1 equivale a X, es la secuencia de entrada\n",
    "# X2 es una secuencia equivalente a y pero sin el último elemento y \n",
    "# teniendo al token <sos> como primer elemento. Es la secuencia de \"estado anterior\"\n",
    "# target equivale a Y como OneHotEncoding, la predicción completa con el último elemento\n",
    "# a la salida del decoder\n",
    "\n",
    "def get_dataset(X, Y, label_encoder):\n",
    "\n",
    "    cardinality = len(label_encoder.classes_)\n",
    "    print(\"Number of features/cardinality:\", cardinality)\n",
    "\n",
    "    X1, X2, target = list(), list(), list()\n",
    "    for x, y in zip(X, Y):\n",
    "        input = list(label_encoder.transform(x.reshape(-1)))\n",
    "        output = list(label_encoder.transform(y.reshape(-1)))\n",
    "        # Crear la entrada del \"último estado\" de salida\n",
    "        # que es la salida sin el último elemento, que es el que el modelo\n",
    "        # debe predecir\n",
    "        output_in = [0] + output[:-1]\n",
    "\n",
    "        # transformar\n",
    "        input_encoded = to_categorical(input, num_classes=cardinality)\n",
    "        output_encoded = to_categorical(output, num_classes=cardinality)\n",
    "        output_in_encoded = to_categorical(output_in, num_classes=cardinality)\n",
    "        \n",
    "        # almacenar\n",
    "        X1.append(input_encoded)\n",
    "        X2.append(output_in_encoded)\n",
    "        target.append(output_encoded)\n",
    "    return np.array(X1), np.array(X2), np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pO2sS3ntkeEf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features/cardinality: 64\n"
     ]
    }
   ],
   "source": [
    "X1, X2, target = get_dataset(X, y, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qu4pTKAm8UWQ"
   },
   "source": [
    "El oneHotEncoding tiene una diemsión de -> vocabulario + tokens_especiales:\n",
    "- 63 números únicos (vocab)\n",
    "- 1 token especial ( \\<sos> como id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XXEI1Rfkgngt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 shape: (20, 3, 64)\n",
      "X2 shape: (20, 3, 64)\n",
      "target shape: (20, 3, 64)\n",
      "Number of input_features 64\n",
      "Number of output_features 64\n"
     ]
    }
   ],
   "source": [
    "# El vector de salida tiene 3 dimensiones:\n",
    "# primera dimensión es la cantidad de \"rows\" del dataset\n",
    "# segunda dimensión es el tamaño de la sequencia de entrada/salida\n",
    "# tercera dimensión es la dimensionalidad del vector oneHotEncoding (cardinalidad)\n",
    "\n",
    "print(\"X1 shape:\", X1.shape)\n",
    "print(\"X2 shape:\", X2.shape)\n",
    "print(\"target shape:\", target.shape)\n",
    "\n",
    "in_features = X1.shape[-1]\n",
    "output_features = target.shape[-1]\n",
    "print(\"Number of input_features\", in_features)\n",
    "print(\"Number of output_features\", output_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vKbhjtIwPgM"
   },
   "source": [
    "### 3 - Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "t_urD1qO2kOx"
   },
   "outputs": [],
   "source": [
    "# El código a continuación se puede utilizar para cualquier encoder-decoder\n",
    "# que se desee construir con LSTM en el futuro\n",
    "# y es posible cambiar la layer LSTM por otra (GRU, CNN, Attention, etc)\n",
    "# Fuente:\n",
    "# https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
    "# https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# returns train, inference_encoder and inference_decoder models\n",
    "def define_models(n_input, n_output, n_units):\n",
    "    '''\n",
    "    Args:\n",
    "        n_input: The cardinality of the input sequence, e.g. number of features, words, or characters for each time step.\n",
    "        n_output: The cardinality of the output sequence, e.g. number of features, words, or characters for each time step.\n",
    "        n_units: Size of recurrent layers to use in the encoder and decoder models, e.g. 128 or 256.\n",
    "    output:\n",
    "        train: Model that can be trained given source, target, and shifted target sequences.\n",
    "        inference_encoder: Encoder model used when making a prediction for a new source sequence.\n",
    "        inference_decoder Decoder model use when making a prediction for a new source sequence.\n",
    "    '''\n",
    "    # define training encoder\n",
    "    encoder_inputs = Input(shape=(None, n_input))\n",
    "    encoder = LSTM(n_units, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # define training decoder\n",
    "    decoder_inputs = Input(shape=(None, n_output))\n",
    "    decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(n_output, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    # define inference encoder\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_units,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    # return all models\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uHtV5z_wGOwj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None, 64)]           0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None, 64)]           0         []                            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 128),                98816     ['input_1[0][0]']             \n",
      "                              (None, 128),                                                        \n",
      "                              (None, 128)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 128),          98816     ['input_2[0][0]',             \n",
      "                              (None, 128),                           'lstm[0][1]',                \n",
      "                              (None, 128)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 64)             8256      ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 205888 (804.25 KB)\n",
      "Trainable params: 205888 (804.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, encoder_model, decoder_model = define_models(in_features, output_features, n_units=128)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"Adam\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8PlXsXeuGCT"
   },
   "source": [
    "Conclusiones hasta ahora sobre el modelo:\n",
    "- Nunca se especificó en la layer de entrada cuantos elementos recibirá el sistema, es por eso que el modelo se creó para aceptar una cantidad dinámica de batch y size de elementos de 64 dimensiones --> None, None, 64\n",
    "- El primer None corresponde al batch dinámico\n",
    "- El segundo None corresponde al la cantidad de elementos dinámico\n",
    "\n",
    "¿Cómo sabe cuantos elementos deberá esperar el sistema?\n",
    "- En este caso siempre entregaremos 3 elementos al encoder y esperaremos 3 elementos del decoder.\n",
    "- En un siguiente notebook de seq2seq utilizaremos tokens especiales para ello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2ljAyiBbG10U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# Modelo completo (encoder+decoder) para poder entrenar\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "s1Wc1pnhIKJ6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# Modelo sólo encoder\n",
    "from keras.utils import plot_model\n",
    "plot_model(encoder_model, to_file='encoder_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "L_xanat4INez"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# Modelo sólo decoder (para realizar inferencia)\n",
    "from keras.utils import plot_model\n",
    "plot_model(decoder_model, to_file='decoder_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VnlIx1Vezjwc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 [==============================] - 5s 352ms/step - loss: 4.1670 - val_loss: 4.1588\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.1419 - val_loss: 4.1661\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.1218 - val_loss: 4.1733\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.1023 - val_loss: 4.1808\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.0820 - val_loss: 4.1890\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.0614 - val_loss: 4.1981\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.0401 - val_loss: 4.2079\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.0161 - val_loss: 4.2184\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.9896 - val_loss: 4.2306\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.9612 - val_loss: 4.2441\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.9278 - val_loss: 4.2612\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.8912 - val_loss: 4.2831\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.8456 - val_loss: 4.3109\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.7907 - val_loss: 4.3469\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.7212 - val_loss: 4.3962\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.6302 - val_loss: 4.4655\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.5145 - val_loss: 4.5679\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.3699 - val_loss: 4.7341\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.1573 - val_loss: 4.9961\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.9373 - val_loss: 5.3967\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.6979 - val_loss: 5.8464\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.4503 - val_loss: 6.2120\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.1950 - val_loss: 6.4925\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.9154 - val_loss: 6.7858\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.6771 - val_loss: 7.1294\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.4631 - val_loss: 7.5009\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2576 - val_loss: 7.8352\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0893 - val_loss: 8.0734\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.9469 - val_loss: 8.2421\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8263 - val_loss: 8.4065\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7281 - val_loss: 8.6279\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6427 - val_loss: 8.8182\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5741 - val_loss: 8.9573\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5153 - val_loss: 9.0821\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4633 - val_loss: 9.1219\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4205 - val_loss: 9.1343\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3843 - val_loss: 9.1436\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3510 - val_loss: 9.1716\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3235 - val_loss: 9.2044\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2982 - val_loss: 9.2496\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2759 - val_loss: 9.2643\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2560 - val_loss: 9.2712\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2390 - val_loss: 9.2896\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2245 - val_loss: 9.3248\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2107 - val_loss: 9.3737\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1983 - val_loss: 9.4043\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1867 - val_loss: 9.4117\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1757 - val_loss: 9.4222\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1662 - val_loss: 9.4115\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1570 - val_loss: 9.3882\n",
      "Epoch 51/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1491 - val_loss: 9.3719\n",
      "Epoch 52/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1409 - val_loss: 9.3856\n",
      "Epoch 53/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1341 - val_loss: 9.4100\n",
      "Epoch 54/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1276 - val_loss: 9.4329\n",
      "Epoch 55/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1219 - val_loss: 9.4294\n",
      "Epoch 56/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1174 - val_loss: 9.4368\n",
      "Epoch 57/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1112 - val_loss: 9.4409\n",
      "Epoch 58/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1064 - val_loss: 9.4606\n",
      "Epoch 59/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1020 - val_loss: 9.4828\n",
      "Epoch 60/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0972 - val_loss: 9.4958\n",
      "Epoch 61/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0926 - val_loss: 9.5079\n",
      "Epoch 62/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0888 - val_loss: 9.5245\n",
      "Epoch 63/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0850 - val_loss: 9.5353\n",
      "Epoch 64/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0817 - val_loss: 9.5440\n",
      "Epoch 65/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0786 - val_loss: 9.5626\n",
      "Epoch 66/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0752 - val_loss: 9.5778\n",
      "Epoch 67/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0724 - val_loss: 9.5850\n",
      "Epoch 68/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0697 - val_loss: 9.5812\n",
      "Epoch 69/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0671 - val_loss: 9.5812\n",
      "Epoch 70/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0648 - val_loss: 9.5887\n",
      "Epoch 71/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0625 - val_loss: 9.5942\n",
      "Epoch 72/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0604 - val_loss: 9.5995\n",
      "Epoch 73/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0584 - val_loss: 9.6116\n",
      "Epoch 74/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0565 - val_loss: 9.6261\n",
      "Epoch 75/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0547 - val_loss: 9.6479\n",
      "Epoch 76/150\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0530 - val_loss: 9.6637\n",
      "Epoch 77/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0514 - val_loss: 9.6698\n",
      "Epoch 78/150\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0498 - val_loss: 9.6767\n",
      "Epoch 79/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0483 - val_loss: 9.6819\n",
      "Epoch 80/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0469 - val_loss: 9.6911\n",
      "Epoch 81/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0456 - val_loss: 9.6974\n",
      "Epoch 82/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0443 - val_loss: 9.6997\n",
      "Epoch 83/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0430 - val_loss: 9.6961\n",
      "Epoch 84/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0419 - val_loss: 9.6947\n",
      "Epoch 85/150\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0408 - val_loss: 9.6966\n",
      "Epoch 86/150\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0397 - val_loss: 9.7056\n",
      "Epoch 87/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0387 - val_loss: 9.7131\n",
      "Epoch 88/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0377 - val_loss: 9.7221\n",
      "Epoch 89/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0366 - val_loss: 9.7265\n",
      "Epoch 90/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0358 - val_loss: 9.7326\n",
      "Epoch 91/150\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0348 - val_loss: 9.7391\n",
      "Epoch 92/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0341 - val_loss: 9.7461\n",
      "Epoch 93/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0333 - val_loss: 9.7528\n",
      "Epoch 94/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0325 - val_loss: 9.7601\n",
      "Epoch 95/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0318 - val_loss: 9.7675\n",
      "Epoch 96/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0310 - val_loss: 9.7746\n",
      "Epoch 97/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0303 - val_loss: 9.7833\n",
      "Epoch 98/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0296 - val_loss: 9.7927\n",
      "Epoch 99/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0290 - val_loss: 9.8002\n",
      "Epoch 100/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0284 - val_loss: 9.8047\n",
      "Epoch 101/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0278 - val_loss: 9.8079\n",
      "Epoch 102/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0272 - val_loss: 9.8126\n",
      "Epoch 103/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0266 - val_loss: 9.8186\n",
      "Epoch 104/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0260 - val_loss: 9.8237\n",
      "Epoch 105/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0255 - val_loss: 9.8287\n",
      "Epoch 106/150\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0250 - val_loss: 9.8358\n",
      "Epoch 107/150\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0244 - val_loss: 9.8441\n",
      "Epoch 108/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0239 - val_loss: 9.8520\n",
      "Epoch 109/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0234 - val_loss: 9.8593\n",
      "Epoch 110/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0229 - val_loss: 9.8662\n",
      "Epoch 111/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0224 - val_loss: 9.8693\n",
      "Epoch 112/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0219 - val_loss: 9.8732\n",
      "Epoch 113/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0215 - val_loss: 9.8743\n",
      "Epoch 114/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0211 - val_loss: 9.8757\n",
      "Epoch 115/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0206 - val_loss: 9.8764\n",
      "Epoch 116/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0202 - val_loss: 9.8754\n",
      "Epoch 117/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0198 - val_loss: 9.8733\n",
      "Epoch 118/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0195 - val_loss: 9.8718\n",
      "Epoch 119/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0191 - val_loss: 9.8720\n",
      "Epoch 120/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0188 - val_loss: 9.8731\n",
      "Epoch 121/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0185 - val_loss: 9.8749\n",
      "Epoch 122/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0181 - val_loss: 9.8788\n",
      "Epoch 123/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0179 - val_loss: 9.8844\n",
      "Epoch 124/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0175 - val_loss: 9.8908\n",
      "Epoch 125/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0172 - val_loss: 9.8968\n",
      "Epoch 126/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0169 - val_loss: 9.9013\n",
      "Epoch 127/150\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0166 - val_loss: 9.9042\n",
      "Epoch 128/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 9.9090\n",
      "Epoch 129/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0161 - val_loss: 9.9133\n",
      "Epoch 130/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0159 - val_loss: 9.9167\n",
      "Epoch 131/150\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0156 - val_loss: 9.9198\n",
      "Epoch 132/150\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0153 - val_loss: 9.9220\n",
      "Epoch 133/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0151 - val_loss: 9.9229\n",
      "Epoch 134/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0149 - val_loss: 9.9232\n",
      "Epoch 135/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 9.9239\n",
      "Epoch 136/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 9.9266\n",
      "Epoch 137/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 9.9309\n",
      "Epoch 138/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0140 - val_loss: 9.9352\n",
      "Epoch 139/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 9.9377\n",
      "Epoch 140/150\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 9.9399\n",
      "Epoch 141/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0133 - val_loss: 9.9409\n",
      "Epoch 142/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 9.9399\n",
      "Epoch 143/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 9.9410\n",
      "Epoch 144/150\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 9.9414\n",
      "Epoch 145/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0126 - val_loss: 9.9425\n",
      "Epoch 146/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 9.9437\n",
      "Epoch 147/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 9.9431\n",
      "Epoch 148/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0120 - val_loss: 9.9443\n",
      "Epoch 149/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0118 - val_loss: 9.9471\n",
      "Epoch 150/150\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0117 - val_loss: 9.9505\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit([X1, X2], target, epochs=150, validation_split=0.2, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "OVz1uug_zu2J"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entrenamiento\n",
    "epoch_count = range(1, len(hist.history['loss']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['loss'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['val_loss'], label='valid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La performance medida en términos de la loss empeora conforme se avanza con el entrenamiento\n",
    "Esto es esperable porque en el conjunto de validación se testea sobre token que nunca se usaron en el entrenamiento.\n",
    "Este análisis no tiene mucho valor para este ejemplo didáctico que se enfoca solamente en cómo construir las arquitecturas de encoder y decoder para modelos de secuencia a secuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "71XeCtfYmOFx"
   },
   "outputs": [],
   "source": [
    "# con esta función pasamos del índice del token al término original\n",
    "def one_hot_decode(encoded_seq, label_encoder):\n",
    "    idx = [np.argmax(vector) for vector in encoded_seq]\n",
    "    return label_encoder.inverse_transform(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "lR1gKJN2m2Fw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test: [35, 40, 45]\n",
      "Number of features/cardinality: 64\n",
      "X1_test shape: (1, 3, 64)\n",
      "X2_test shape: (1, 3, 64)\n",
      "target_test shape: (1, 3, 64)\n"
     ]
    }
   ],
   "source": [
    "# Ensayo\n",
    "x_test = [20, 25, 30]\n",
    "y_test = [x+15 for x in x_test]\n",
    "\n",
    "print(\"y_test:\", y_test)\n",
    "\n",
    "# Transformar los datos a oneHotEncoding\n",
    "X1_test, X2_test, target_test = get_dataset(np.array([x_test]), np.array([y_test]), label_encoder)\n",
    "\n",
    "print(\"X1_test shape:\", X1_test.shape)\n",
    "print(\"X2_test shape:\", X2_test.shape)\n",
    "print(\"target_test shape:\", target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "kluBZJGMm3LF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 40, 45])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cuando quiera por ejemplo recuperar target_test a y_test utilizo:\n",
    "one_hot_decode(target_test[0], label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "C4_UQshIzw7o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 475ms/step\n",
      "target_seq shape: (1, 1, 64)\n",
      "Qué recibe como elemento anterior: [0]\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "Qué saca como elemento nuevo o prediccion: [35]\n",
      "Qué recibe como elemento anterior: [35]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Qué saca como elemento nuevo o prediccion: [40]\n",
      "Qué recibe como elemento anterior: [40]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Qué saca como elemento nuevo o prediccion: [45]\n",
      "y_test: [35, 40, 45]\n",
      "y_hat: [35 40 45]\n"
     ]
    }
   ],
   "source": [
    "cardinality = len(label_encoder.classes_)\n",
    "\n",
    "# encode\n",
    "# Se transforma la sequencia de entrada a los estados \"h\" y \"c\" de la LSTM\n",
    "# para enviar la primera vez al decoder\n",
    "state = encoder_model.predict(X1_test)\n",
    "# start of sequence input --> la primera secuencia de salida-entrada (output_in)\n",
    "# comienza con el ID cero (el ID seleccionado para <sos>)\n",
    "output_in = to_categorical(0, num_classes=cardinality)\n",
    "target_seq = np.array(output_in).reshape(1, 1, cardinality)\n",
    "print(\"target_seq shape:\", target_seq.shape)\n",
    "\n",
    "# Vector de predicción\n",
    "output = list()\n",
    "\n",
    "# Aquí empieza la parte auto-regresiva de la inferencia\n",
    "for t in range(3):\n",
    "    # Predicción del próximo elemento\n",
    "    print(\"Qué recibe como elemento anterior:\", one_hot_decode(target_seq[0], label_encoder))\n",
    "    y_hat, h, c = decoder_model.predict([target_seq] + state)\n",
    "    \n",
    "    # Almacenar la predicción\n",
    "    output.append(y_hat[0])\n",
    "    print(\"Qué saca como elemento nuevo o prediccion:\", one_hot_decode(y_hat[0], label_encoder))\n",
    "    # Actualizar los estados dada la última prediccion\n",
    "    state = [h, c]\n",
    "    \n",
    "    # Actualizar secuencia de entrada con la salida (re-alimentacion)\n",
    "    target_seq = y_hat\n",
    "\n",
    "print(\"y_test:\", y_test)\n",
    "print(\"y_hat:\", one_hot_decode(output, label_encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "M7MD_XS2oKUj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.011852435767650604"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podría si quisiera usar el \"evaluate\" de Keras pero ahí si necesitaré\n",
    "# de X2:\n",
    "model.evaluate([X1_test, X2_test], [target_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkOjSJweqdF8"
   },
   "source": [
    "### 4 - Conclusión\n",
    "A primera vista parece muy compleja la estructura del encoder-decoder, pero funciona igual en cualquier disciplina de deeplearning:\n",
    "- En visión para transferencia de estilo, generación de imagenes, etc.\n",
    "- En NLP desde LSTM hasta Attention y transformers\n",
    "\n",
    "Hay que pensar el encoder como el generador del \"espacio latente\". Luego el decoder necesita el espacio latente que representa a la setencia de entrada, la realimentación de los valores de salida del decoder y los estados internos de la LSTM para pasar a la siguiente inferencia hasta concluir la secuencia de salida."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
